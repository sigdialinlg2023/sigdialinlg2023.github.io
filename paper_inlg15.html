

<!-- venue -->
<!-- Venue na webu sigdialu participating -->
<!-- nahradit fotku a zmergovat logo -->
<!DOCTYPE html>
<html lang="en">

<head>
  
<script type="text/javascript" src="static/js/views/zoom_links.js"></script>


  <!-- Required meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  <!-- External Javascript libs_ext  -->
  <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct"
    crossorigin="anonymous"></script>
  <!-- <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.14.0-beta3/dist/js/bootstrap-select.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
    integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
    integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script> -->


  <!-- Library libs_ext -->
  <script src="static/js/libs_ext/typeahead.bundle.js"></script>


  <!--    Internal Libs -->
  <script src="static/js/data/api.js"></script>

  
  <script>
    var auth0_domain = "ufal-cuni.eu.auth0.com";
    var auth0_client_id = "R6G028fWc6YPC89JqBds3RaPO4SgZPkO";
  </script>
  <script src="https://cdn.auth0.com/js/auth0-spa-js/2.0/auth0-spa-js.production.js">
  </script>
  <script src="static/js/modules/auth0protect.js"></script>
  

  <!-- External CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
    integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">


  <!-- External Fonts (no google for china) -->
  <link href="static/css/Lato.css" rel="stylesheet" />
  <!-- <link href="static/css/Exo.css" rel="stylesheet" /> -->
  <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap"
    rel="stylesheet">
  <link href="static/css/Cuprum.css" rel="stylesheet" />
  <link rel="stylesheet" href="static/css/main.css" />
  <!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
  <link rel="stylesheet" href="static/css/fa_solid.css" />
  <link rel="stylesheet" href="static/css/lazy_load.css" />
  <link rel="stylesheet" href="static/css/typeahead.css" />

  <title>Program SIGdial &amp; INLG 2023: Fine-Tuning GPT-3 for Synthetic Danish News Generation</title>
  
<meta name="citation_title" content="Fine-Tuning GPT-3 for Synthetic Danish News Generation" />

<meta name="citation_author" content="Mina Almasi" />

<meta name="citation_author" content="Anton Schiønning" />

<meta name="citation_publication_date" content="September 2023" />
<meta name="citation_conference_title" content="Visit Sigdial &amp; Inlg 2023" />
<meta name="citation_inbook_title" content="Proceedings of SIGdial 2023 &amp; Proceedings of INLG 2023" />
<meta name="citation_abstract" content="While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model&#39;s performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context." />



</head>

<body>
  <!-- NAV -->
  <!-- TODO TBD program -->
  
  
  
  
  

  <nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto" id="main-nav">
    <div class="container">
      <a class="navbar-brand" href="index.html">
        <img class="logo" src="static/images/program.png" height="auto"
          width="170px" />
      </a>
      
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="index.html">News</a>
          </li>

          
            
            

          
            
            





          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown"
              aria-haspopup="true" aria-expanded="false">
              For participants
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="registration.html">Registration</a>
              <a class="dropdown-item" href="venue.html">Venue</a>
              <a class="dropdown-item" href="onlinepresence.html">Online Presence</a>
              <a class="dropdown-item" href="local.html">Local information</a>
              <a class="dropdown-item" href="presenters.html">For presenters</a>
            </div>
          </li>

          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown"
              aria-haspopup="true" aria-expanded="false">
              Program
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="calendar.html">Schedule</a>
              <a class="dropdown-item" href="speakers.html">Keynotes</a>
              <!--                    <a class="dropdown-item" href="panels.html">Panel</a>-->
              <!--                    <a class="dropdown-item" href="accepted_papers.html">Accepted Papers</a>-->
              <a class="dropdown-item" href="papers.html">Papers</a>
              <a class="dropdown-item" href="awards.html">Awards</a>
              <a class="dropdown-item" href="workshops.html">Workshops</a>
              <!--                    <a class="dropdown-item" href="tutorials.html">Tutorials</a>-->
              <!--                    <a class="dropdown-item" href="hackathons.html">Hackathon</a>-->
              <!--                    <a class="dropdown-item" href="genchal.html">GenChal</a>-->
            </div>
          </li>



          <li class="nav-item ">
            <a class="nav-link" href="help.html">FAQ</a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="organizers.html">Organizers</a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="sponsors.html">Sponsors</a>
          </li>

          <!-- <li class="nav-item "> -->
          <!--     <a class="nav-link" href="workshops.html">Workshops</a> -->
          <!-- </li> -->

          <li class="nav-item ">
            <a class="nav-link" href="https://2023.sigdial.org/">SIGdial</a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="https://inlg2023.github.io/">INLG</a>
          </li>
        </ul>

        <button id="btn-login" class="btn-info btn-sm btn-login" onclick="login()">Log in</button>
        <button id="btn-logout" class="btn-danger btn-sm btn-login" onclick="logout()">Log out</button>
      </div>
    </div>
  </nav>
  

  
  <!-- User Overrides -->
   
  <div class="container">
    <!-- Tabs -->
    <div class="tabs">
       
    </div>

    <!-- Content -->
    <div class="content">
      <div id="error-message" class="error-message"></div>
      

<!-- Title -->
<!-- <div class="public-content"> -->
<div class="pp-card m-3">
    <div class="card-header">
        <h2 class="card-title main-title text-center">
            Fine-Tuning GPT-3 for Synthetic Danish News Generation
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Mina Almasi" class="text-muted"><i>Mina Almasi</i></a>,
            
            <a href="papers.html?filter=authors&search=Anton Schiønning" class="text-muted"><i>Anton Schiønning</i></a>
            
        </h3>
        <div class="text-center p-3">
            
            <p>
                <a class="card-link" target="_blank" href="static/papers/inlg/15_Paper.pdf"> Paper </a>
            </p>
            

            In Sessions:
            
            <!-- {&#39;UID&#39;: &#39;inlgoralsession3&#39;, &#39;title&#39;: &#39;INLG Oral Session 3: Leveraging Large Language Models for NLG&#39;, &#39;chair&#39;: &#39;Tom Williams&#39;, &#39;start&#39;: &#39;2023-09-14T10:30:00+02:00&#39;, &#39;room&#39;: &#39;Sun II&#39;, &#39;category&#39;: &#39;time&#39;, &#39;discord&#39;: &#39;https://discord.com/channels/###inlgoralsession3###&#39;, &#39;zoom&#39;: &#39;https://zoom.us/j/###Sun II###&#39;, &#39;end&#39;: &#39;2023-09-14T12:10:00+02:00&#39;, &#39;calendarId&#39;: &#39;inlgoral&#39;, &#39;contents&#39;: [{&#39;conference&#39;: &#39;inlg&#39;, &#39;original_id&#39;: &#39;15&#39;, &#39;UID&#39;: &#39;inlg15&#39;, &#39;title&#39;: &#39;Fine-Tuning GPT-3 for Synthetic Danish News Generation&#39;, &#39;authors&#39;: [&#39;Mina Almasi&#39;, &#39;Anton Schiønning&#39;], &#39;order&#39;: &#39;0&#39;, &#39;session&#39;: &#39;inlgoralsession3&#39;, &#39;abstract&#39;: &#34;While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model&#39;s performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.&#34;, &#39;paper&#39;: &#39;static/papers/inlg/15_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/INLG2023/15.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T10:30:00+02:00&#39;}, {&#39;conference&#39;: &#39;inlg&#39;, &#39;original_id&#39;: &#39;56&#39;, &#39;UID&#39;: &#39;inlg56&#39;, &#39;title&#39;: &#34;ChatGPT&#39;s Information Seeking Strategy: Insights From the 20-Questions Game&#34;, &#39;authors&#39;: [&#39;Leonardo Bertolazzi&#39;, &#39;Davide Mazzaccara&#39;, &#39;Filippo Merlo&#39;, &#39;Raffaella Bernardi&#39;], &#39;order&#39;: &#39;0&#39;, &#39;session&#39;: &#39;inlgoralsession3&#39;, &#39;abstract&#39;: &#34;Large Language Models, and ChatGPT in particular, have recently grabbed the attention of the community and the media. Having reached high language proficiency, attention has been shifting toward its reasoning capabilities. In this paper, our main aim is to evaluate ChatGPT&#39;s question generation in a task where language production should be driven by an implicit reasoning process. To this end, we employ the 20-Questions game, traditionally used within the Cognitive Science community to inspect the information seeking-strategy&#39;s development.  This task requires a series of interconnected skills: asking informative questions, stepwise updating the hypothesis space, and stopping asking questions when enough information has been collected. We build hierarchical hypothesis spaces, exploiting feature norms collected from humans vs. ChatGPT itself, and we inspect the efficiency and informativeness of ChatGPT&#39;s strategy. Our results show that ChatGPT&#39;s performance gets closer to an optimal agent only when prompted to explicitly list the updated space stepwise.&#34;, &#39;paper&#39;: &#39;static/papers/inlg/56_Paper.pdf&#39;, &#39;notes&#39;: &#39;Best Paper Nominee&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T10:30:00+02:00&#39;}, {&#39;conference&#39;: &#39;inlg&#39;, &#39;original_id&#39;: &#39;99&#39;, &#39;UID&#39;: &#39;inlg99&#39;, &#39;title&#39;: &#39;Memories for Virtual AI Characters&#39;, &#39;authors&#39;: [&#39;Fabian Landwehr&#39;, &#39;Erika Varis Doggett&#39;, &#39;Romann M. Weber&#39;], &#39;order&#39;: &#39;0&#39;, &#39;session&#39;: &#39;inlgoralsession3&#39;, &#39;abstract&#39;: &#39;In this paper, we present a system for augmenting virtual AI characters with long-term memory, enabling them to remember facts about themselves, their world, and past experiences. We propose a memory-creation pipeline that converts raw text into condensed memories and a memory-retrieval system that utilizes these memories to generate character responses. Using a fact-checking pipeline based on GPT-4, our evaluation demonstrates that the character responses are grounded in the retrieved memories and maintain factual accuracy. We discuss the implications of our system for creating engaging and consistent virtual characters and highlight areas for future research, including large language model (LLM) guardrailing and virtual character personality development.&#39;, &#39;paper&#39;: &#39;static/papers/inlg/99_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/INLG2023/99.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T10:30:00+02:00&#39;}, {&#39;conference&#39;: &#39;inlg&#39;, &#39;original_id&#39;: &#39;107&#39;, &#39;UID&#39;: &#39;inlg107&#39;, &#39;title&#39;: &#39;Metric-Based in-Context Learning: A Case Study in Text Simplification&#39;, &#39;authors&#39;: [&#39;Subhadra Vadlamannati&#39;, &#39;Gözde Şahin&#39;], &#39;order&#39;: &#39;0&#39;, &#39;session&#39;: &#39;inlgoralsession3&#39;, &#39;abstract&#39;: &#39;In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behavior of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.&#39;, &#39;paper&#39;: &#39;static/papers/inlg/107_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T10:30:00+02:00&#39;}], &#39;name&#39;: &#39;INLG Oral Session 3: Leveraging Large Language Models for NLG&#39;, &#39;start_time&#39;: datetime.datetime(2023, 9, 14, 10, 30, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))), &#39;end_time&#39;: datetime.datetime(2023, 9, 14, 12, 10, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))), &#39;location&#39;: &#39;#inlgoralsession3&#39;, &#39;day&#39;: &#39;Thursday&#39;} - <br /> -->
            <p>
                INLG Oral Session 3: Leveraging Large Language Models for NLG: (Thursday, 10:30 CEST, Sun II
                <span class="gated-content">
                    , <a href="https://zoom.us/j/###Sun II###" target="_blank"
                        class="card-link">Watch on Zoom</a> 
                    , <a href="https://discord.com/channels/###inlgoralsession3###" target="_blank"
                        class="card-link discord-link">Chat on Discord </a>
                </span>
                )
            </p>
            

            
            
            <a href="static/posters/INLG2023/15.pdf" target="_blank" class="card-link">
                <p>Poster </p>
                <img src="static/posters/thumbnails/inlg15.png" alt="Fine-Tuning GPT-3 for Synthetic Danish News Generation">
            </a>
            
            
            <br />
            
        </div>
    </div>
</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model&#39;s performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.
            </div>
        </div>
        <p></p>
    </div>
</div>
<!-- </div> -->


<script type="text/javascript">
    window.addEventListener("load", updateLinks(), "false" );
</script>

    </div>
  </div>
  
  

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag("js", new Date());
    gtag("config", "UA-");
  </script>

  <!-- Footer -->
  <footer class="footer bg-light p-4">
    <div class="container">
      <div class="gated-content" style="display: none;">
        <p class="float-left">
          Logged in as <b><span id="ipt-user-email"></span></b>.</p>
      </div>
      <p class="float-right"><a href="#">Back to Top</a></p>
      <p class="text-center">© 2023 SIGDIAL-INLG 2023 Organizers</p>
    </div>
  </footer>

  <!-- Code for hash tags -->
  <script type="text/javascript">
    $(document).ready(function () {
      if (window.location.hash !== "") {
        $(`a[href="${window.location.hash}"]`).tab("show");
      }

      $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
        const hash = $(e.target).attr("href");
        if (hash.substr(0, 1) === "#") {
          const position = $(window).scrollTop();
          window.location.replace(`#${hash.substr(1)}`);
          $(window).scrollTop(position);
        }
      });
    });
  </script>
  <!--    <script src="static/js/modules/lazyLoad.js"></script>-->
  
</body>

</html>