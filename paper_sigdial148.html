

<!-- venue -->
<!-- Venue na webu sigdialu participating -->
<!-- nahradit fotku a zmergovat logo -->
<!DOCTYPE html>
<html lang="en">

<head>
  
<script type="text/javascript" src="static/js/views/zoom_links.js"></script>


  <!-- Required meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  <!-- External Javascript libs_ext  -->
  <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct"
    crossorigin="anonymous"></script>
  <!-- <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.14.0-beta3/dist/js/bootstrap-select.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
    integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
    integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script> -->


  <!-- Library libs_ext -->
  <script src="static/js/libs_ext/typeahead.bundle.js"></script>


  <!--    Internal Libs -->
  <script src="static/js/data/api.js"></script>

  
  <script>
    var auth0_domain = "ufal-cuni.eu.auth0.com";
    var auth0_client_id = "R6G028fWc6YPC89JqBds3RaPO4SgZPkO";
  </script>
  <script src="https://cdn.auth0.com/js/auth0-spa-js/2.0/auth0-spa-js.production.js">
  </script>
  <script src="static/js/modules/auth0protect.js"></script>
  

  <!-- External CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
    integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">


  <!-- External Fonts (no google for china) -->
  <link href="static/css/Lato.css" rel="stylesheet" />
  <!-- <link href="static/css/Exo.css" rel="stylesheet" /> -->
  <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap"
    rel="stylesheet">
  <link href="static/css/Cuprum.css" rel="stylesheet" />
  <link rel="stylesheet" href="static/css/main.css" />
  <!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
  <link rel="stylesheet" href="static/css/fa_solid.css" />
  <link rel="stylesheet" href="static/css/lazy_load.css" />
  <link rel="stylesheet" href="static/css/typeahead.css" />

  <title>Program SIGdial &amp; INLG 2023: CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation</title>
  
<meta name="citation_title" content="CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation" />

<meta name="citation_author" content="Chao-Wei Huang" />

<meta name="citation_author" content="Chen-Yu Hsu" />

<meta name="citation_author" content="Tsu-Yuan Hsu" />

<meta name="citation_author" content="Chen-An Li" />

<meta name="citation_author" content="Yun-Nung Chen" />

<meta name="citation_publication_date" content="September 2023" />
<meta name="citation_conference_title" content="Visit Sigdial &amp; Inlg 2023" />
<meta name="citation_inbook_title" content="Proceedings of SIGdial 2023 &amp; Proceedings of INLG 2023" />
<meta name="citation_abstract" content="Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER" />



</head>

<body>
  <!-- NAV -->
  <!-- TODO TBD program -->
  
  
  
  
  

  <nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto" id="main-nav">
    <div class="container">
      <a class="navbar-brand" href="index.html">
        <img class="logo" src="static/images/program.png" height="auto"
          width="170px" />
      </a>
      
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="index.html">News</a>
          </li>

          
            
            

          
            
            





          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown"
              aria-haspopup="true" aria-expanded="false">
              For participants
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="registration.html">Registration</a>
              <a class="dropdown-item" href="venue.html">Venue</a>
              <a class="dropdown-item" href="onlinepresence.html">Online Presence</a>
              <a class="dropdown-item" href="local.html">Local information</a>
              <a class="dropdown-item" href="presenters.html">For presenters</a>
            </div>
          </li>

          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown"
              aria-haspopup="true" aria-expanded="false">
              Program
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="calendar.html">Schedule</a>
              <a class="dropdown-item" href="speakers.html">Keynotes</a>
              <!--                    <a class="dropdown-item" href="panels.html">Panel</a>-->
              <!--                    <a class="dropdown-item" href="accepted_papers.html">Accepted Papers</a>-->
              <a class="dropdown-item" href="papers.html">Papers</a>
              <a class="dropdown-item" href="awards.html">Awards</a>
              <a class="dropdown-item" href="workshops.html">Workshops</a>
              <!--                    <a class="dropdown-item" href="tutorials.html">Tutorials</a>-->
              <!--                    <a class="dropdown-item" href="hackathons.html">Hackathon</a>-->
              <!--                    <a class="dropdown-item" href="genchal.html">GenChal</a>-->
            </div>
          </li>



          <li class="nav-item ">
            <a class="nav-link" href="help.html">FAQ</a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="organizers.html">Organizers</a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="sponsors.html">Sponsors</a>
          </li>

          <!-- <li class="nav-item "> -->
          <!--     <a class="nav-link" href="workshops.html">Workshops</a> -->
          <!-- </li> -->

          <li class="nav-item ">
            <a class="nav-link" href="https://2023.sigdial.org/">SIGdial</a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="https://inlg2023.github.io/">INLG</a>
          </li>
        </ul>

        <button id="btn-login" class="btn-info btn-sm btn-login" onclick="login()">Log in</button>
        <button id="btn-logout" class="btn-danger btn-sm btn-login" onclick="logout()">Log out</button>
      </div>
    </div>
  </nav>
  

  
  <!-- User Overrides -->
   
  <div class="container">
    <!-- Tabs -->
    <div class="tabs">
       
    </div>

    <!-- Content -->
    <div class="content">
      <div id="error-message" class="error-message"></div>
      

<!-- Title -->
<!-- <div class="public-content"> -->
<div class="pp-card m-3">
    <div class="card-header">
        <h2 class="card-title main-title text-center">
            CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Chao-Wei Huang" class="text-muted"><i>Chao-Wei Huang</i></a>,
            
            <a href="papers.html?filter=authors&search=Chen-Yu Hsu" class="text-muted"><i>Chen-Yu Hsu</i></a>,
            
            <a href="papers.html?filter=authors&search=Tsu-Yuan Hsu" class="text-muted"><i>Tsu-Yuan Hsu</i></a>,
            
            <a href="papers.html?filter=authors&search=Chen-An Li" class="text-muted"><i>Chen-An Li</i></a>,
            
            <a href="papers.html?filter=authors&search=Yun-Nung Chen" class="text-muted"><i>Yun-Nung Chen</i></a>
            
        </h3>
        <div class="text-center p-3">
            
            <p>
                <a class="card-link" target="_blank" href="static/papers/sigdial/148_Paper.pdf"> Paper </a>
            </p>
            

            In Sessions:
            
            <!-- {&#39;UID&#39;: &#39;sigdialpostersession2&#39;, &#39;title&#39;: &#39;Sigdial Poster Session 2&#39;, &#39;chair&#39;: &#39;Kazunori Komatani&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;, &#39;room&#39;: &#39;Foyer&#39;, &#39;category&#39;: &#39;time&#39;, &#39;discord&#39;: &#39;https://discord.com/channels/###sigdialpostersession2###&#39;, &#39;zoom&#39;: None, &#39;end&#39;: &#39;2023-09-14T15:40:00+02:00&#39;, &#39;calendarId&#39;: &#39;sigdialposter&#39;, &#39;contents&#39;: [{&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;104&#39;, &#39;UID&#39;: &#39;sigdial104&#39;, &#39;title&#39;: &#39;UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation&#39;, &#39;authors&#39;: [&#39;Mai Omura&#39;, &#39;Hiroshi Matsuda&#39;, &#39;Masayuki Asahara&#39;, &#39;Aya Wakasa&#39;], &#39;order&#39;: &#39;1&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/104_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/SIGDIAL2023/104.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;154&#39;, &#39;UID&#39;: &#39;sigdial154&#39;, &#39;title&#39;: &#39;Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation&#39;, &#39;authors&#39;: [&#39;Zulipiye Yusupujiang&#39;, &#39;Jonathan Ginzburg&#39;], &#39;order&#39;: &#39;10&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/154_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;153&#39;, &#39;UID&#39;: &#39;sigdial153&#39;, &#39;title&#39;: &#39;A New Dataset for Causality Identification in Argumentative Texts&#39;, &#39;authors&#39;: [&#39;Khalid Al Khatib&#39;, &#39;Michael Völske&#39;, &#39;Anh Le&#39;, &#39;Shahbaz Syed&#39;, &#39;Martin Potthast&#39;, &#39;Benno Stein&#39;], &#39;order&#39;: &#39;9&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/153_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;125&#39;, &#39;UID&#39;: &#39;sigdial125&#39;, &#39;title&#39;: &#39;Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking&#39;, &#39;authors&#39;: [&#39;Angela Ramirez&#39;, &#39;Kartik Agarwal&#39;, &#39;Juraj Juraska&#39;, &#39;Utkarsh Garg&#39;, &#39;Marilyn Walker&#39;], &#39;order&#39;: &#39;5&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/125_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/SIGDIAL2023/125.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;117&#39;, &#39;UID&#39;: &#39;sigdial117&#39;, &#39;title&#39;: &#39;Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant&#39;, &#39;authors&#39;: [&#39;Abari Bhattacharya&#39;, &#39;Abhinav Kumar&#39;, &#39;Barbara Di Eugenio&#39;, &#39;Roderick Tabalba&#39;, &#39;Jillian Aurisano&#39;, &#39;Veronica Grosso&#39;, &#39;Andrew Johnson&#39;, &#39;Jason Leigh&#39;, &#39;Moira Zellner&#39;], &#39;order&#39;: &#39;2&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/117_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/SIGDIAL2023/117.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;148&#39;, &#39;UID&#39;: &#39;sigdial148&#39;, &#39;title&#39;: &#39;CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation&#39;, &#39;authors&#39;: [&#39;Chao-Wei Huang&#39;, &#39;Chen-Yu Hsu&#39;, &#39;Tsu-Yuan Hsu&#39;, &#39;Chen-An Li&#39;, &#39;Yun-Nung Chen&#39;], &#39;order&#39;: &#39;8&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/148_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;123&#39;, &#39;UID&#39;: &#39;sigdial123&#39;, &#39;title&#39;: &#39;Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models&#39;, &#39;authors&#39;: [&#39;Minh-Quoc Nghiem&#39;, &#39;Nichola Roberts&#39;, &#39;Dmitry Sityaev&#39;], &#39;order&#39;: &#39;4&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#34;This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent&#39;s opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.&#34;, &#39;paper&#39;: &#39;static/papers/sigdial/123_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;146&#39;, &#39;UID&#39;: &#39;sigdial146&#39;, &#39;title&#39;: &#39;Synthesising Personality With Neural Speech Synthesis&#39;, &#39;authors&#39;: [&#39;Shilin Gao&#39;, &#39;Matthew P. Aylett&#39;, &#39;David A. Braude&#39;, &#39;Catherine Lai&#39;], &#39;order&#39;: &#39;7&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/146_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;121&#39;, &#39;UID&#39;: &#39;sigdial121&#39;, &#39;title&#39;: &#39;Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation&#39;, &#39;authors&#39;: [&#39;Gonçalo Raposo&#39;, &#39;Luisa Coheur&#39;, &#39;Bruno Martins&#39;], &#39;order&#39;: &#39;3&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#34;Task-oriented dialogue systems need to generate appropriate responses to help fulfill users&#39; requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.&#34;, &#39;paper&#39;: &#39;static/papers/sigdial/121_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/SIGDIAL2023/121.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;132&#39;, &#39;UID&#39;: &#39;sigdial132&#39;, &#39;title&#39;: &#39;Bootstrapping a Conversational Guide for Colonoscopy Prep&#39;, &#39;authors&#39;: [&#39;Pulkit Arya&#39;, &#39;Madeleine Bloomquist&#39;, &#39;SUBHANKAR CHAKRABORTY&#39;, &#39;Andrew Perrault&#39;, &#39;William Schuler&#39;, &#39;Eric Fosler-Lussier&#39;, &#39;Michael White&#39;], &#39;order&#39;: &#39;6&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#34;Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models&#39; ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.&#34;, &#39;paper&#39;: &#39;static/papers/sigdial/132_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;155&#39;, &#39;UID&#39;: &#39;sigdial155&#39;, &#39;title&#39;: &#34;Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User&#39;s Task Success Ability&#34;, &#39;authors&#39;: [&#39;Ryu Hirai&#39;, &#39;Ao Guo&#39;, &#39;Ryuichiro Higashinaka&#39;], &#39;order&#39;: &#39;11&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#34;While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user&#39;s task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.&#34;, &#39;paper&#39;: &#39;static/papers/sigdial/155_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/SIGDIAL2023/155.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;70&#39;, &#39;UID&#39;: &#39;sigdial70&#39;, &#39;title&#39;: &#39;An Open-Domain Avatar Chatbot by Exploiting a Large Language Model&#39;, &#39;authors&#39;: [&#39;Takato Yamazaki&#39;, &#39;Tomoya Mizumoto&#39;, &#39;Katsumasa Yoshikawa&#39;, &#39;Masaya Ohagi&#39;, &#39;Toshiki Kawamoto&#39;, &#39;Toshinori Sato&#39;], &#39;order&#39;: &#39;0&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.&#39;, &#39;paper&#39;: &#39;static/papers/sigdial/70_Paper.pdf&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;D&amp;D1&#39;, &#39;UID&#39;: &#39;sigdialD&amp;D1&#39;, &#39;title&#39;: &#39;Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do&#39;, &#39;authors&#39;: [&#39;Utku Norman&#39;, &#39;Tanvi Dinkar&#39;, &#39;Barbara Bruno&#39;, &#39;Chloé Clavel&#39;], &#39;order&#39;: &#39;12&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;&#39;, &#39;paper&#39;: &#39;&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;D&amp;D2&#39;, &#39;UID&#39;: &#39;sigdialD&amp;D2&#39;, &#39;title&#39;: &#39;The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies&#39;, &#39;authors&#39;: [&#39;Marian Marchal&#39;, &#39;Saarland University&#39;, &#39;Merel C.J. Scholman&#39;, &#39;Vera Demberg&#39;], &#39;order&#39;: &#39;13&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;&#39;, &#39;paper&#39;: &#39;&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}, {&#39;conference&#39;: &#39;sigdial&#39;, &#39;original_id&#39;: &#39;D&amp;D3&#39;, &#39;UID&#39;: &#39;sigdialD&amp;D3&#39;, &#39;title&#39;: &#39;Bullshit, Pragmatic Deception, and Natural Language Processing&#39;, &#39;authors&#39;: [&#39;Oliver Deck&#39;], &#39;order&#39;: &#39;14&#39;, &#39;session&#39;: &#39;sigdialpostersession2&#39;, &#39;abstract&#39;: &#39;&#39;, &#39;paper&#39;: &#39;&#39;, &#39;notes&#39;: &#39;&#39;, &#39;poster&#39;: &#39;static/posters/SIGDIAL2023/D&amp;D_Deck.pdf&#39;, &#39;full_video&#39;: &#39;&#39;, &#39;start&#39;: &#39;2023-09-14T14:00:00+02:00&#39;}], &#39;name&#39;: &#39;Sigdial Poster Session 2&#39;, &#39;start_time&#39;: datetime.datetime(2023, 9, 14, 14, 0, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))), &#39;end_time&#39;: datetime.datetime(2023, 9, 14, 15, 40, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))), &#39;location&#39;: &#39;#sigdialpostersession2&#39;, &#39;day&#39;: &#39;Thursday&#39;} - <br /> -->
            <p>
                Sigdial Poster Session 2: (Thursday, 14:00 CEST, Foyer
                <span class="gated-content">
                    
                    , <a href="https://discord.com/channels/###sigdialpostersession2###" target="_blank"
                        class="card-link discord-link">Chat on Discord </a>
                </span>
                )
            </p>
            

            
            
            
            <br />
            
        </div>
    </div>
</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER
            </div>
        </div>
        <p></p>
    </div>
</div>
<!-- </div> -->


<script type="text/javascript">
    window.addEventListener("load", updateLinks(), "false" );
</script>

    </div>
  </div>
  
  

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag("js", new Date());
    gtag("config", "UA-");
  </script>

  <!-- Footer -->
  <footer class="footer bg-light p-4">
    <div class="container">
      <div class="gated-content" style="display: none;">
        <p class="float-left">
          Logged in as <b><span id="ipt-user-email"></span></b>.</p>
      </div>
      <p class="float-right"><a href="#">Back to Top</a></p>
      <p class="text-center">© 2023 SIGDIAL-INLG 2023 Organizers</p>
    </div>
  </footer>

  <!-- Code for hash tags -->
  <script type="text/javascript">
    $(document).ready(function () {
      if (window.location.hash !== "") {
        $(`a[href="${window.location.hash}"]`).tab("show");
      }

      $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
        const hash = $(e.target).attr("href");
        if (hash.substr(0, 1) === "#") {
          const position = $(window).scrollTop();
          window.location.replace(`#${hash.substr(1)}`);
          $(window).scrollTop(position);
        }
      });
    });
  </script>
  <!--    <script src="static/js/modules/lazyLoad.js"></script>-->
  
</body>

</html>