[{"UID":"sigdial163","abstract":"Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,\"Is the WIFI reliable?\" or \"Does the restaurant have a good atmosphere?\"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.","authors":["Chao Zhao","Spandana Gella","Seokhwan Kim","Di Jin","Devamanyu Hazarika","Alexandros Papangelis","Behnam Hedayatnia","Mahdi Namazifar","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"163","paper":"static/papers/sigdial/163_Paper.pdf","poster":"","session":"sigdialoralsession3","sessions":[{"UID":"sigdialoralsession3","calendarId":"sigdialoral","category":"time","chair":"Frederic Bechet","contents":[{"UID":"sigdial79","abstract":"Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.","authors":["Qingyang Wu","James Gung","Raphael Shu","Yi Zhang"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"79","paper":"static/papers/sigdial/79_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:30:00+02:00","title":"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"},{"UID":"sigdial15","abstract":"With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.","authors":["Ekaterina Svikhnushina","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"15","paper":"static/papers/sigdial/15_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:50:00+02:00","title":"Approximating Online Human Evaluation of Social Chatbots With Prompting"},{"UID":"sigdial12","abstract":"Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.","authors":["Ayaka Ueyama","Yoshinobu Kano"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"12","paper":"static/papers/sigdial/12_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:10:00+02:00","title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution"},{"UID":"sigdial129","abstract":"Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce &#92;textsc{Syndicom} - a method for improving commonsense in dialogue response generation. &#92;textsc{Syndicom} consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.  <p>&#92;textsc{Syndicom} is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. &#92;textsc{Syndicom} achieves a relative improvement of 53&#92;% over ChatGPT on ROUGE-1, and human evaluators prefer &#92;textsc{Syndicom} over ChatGPT 57&#92;% of the time. We will publicly release the code and the full dataset.","authors":["Christopher Richardson","Larry Heck"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"129","paper":"static/papers/sigdial/129_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:30:00+02:00","title":"Syndicom: Improving Conversational Commonsense With Error-Injection and Natural Language Feedback"},{"UID":"sigdial163","abstract":"Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,\"Is the WIFI reliable?\" or \"Does the restaurant have a good atmosphere?\"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.","authors":["Chao Zhao","Spandana Gella","Seokhwan Kim","Di Jin","Devamanyu Hazarika","Alexandros Papangelis","Behnam Hedayatnia","Mahdi Namazifar","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"163","paper":"static/papers/sigdial/163_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:50:00+02:00","title":"\"What Do Others Think?\": Task-Oriented Conversational Modeling With Subjective Knowledge"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#sigdialoralsession3","name":"Sigdial Oral Session 3: Dialogue modeling and evaluation","room":"Sun I","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"Sigdial Oral Session 3: Dialogue modeling and evaluation","zoom":"https://zoom.us/j/###Sun I###"}],"title":"\"What Do Others Think?\": Task-Oriented Conversational Modeling With Subjective Knowledge"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"sigdial91","abstract":"Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners' topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.","authors":["Grace Lawley","Peter A. Heeman","Jill K. Dolata","Eric Fombonne","Steven Bedrick"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"91","paper":"static/papers/sigdial/91_Paper.pdf","poster":"static/posters/SIGDIAL2023/91.pdf","session":"sigdialoralsession1","sessions":[{"UID":"sigdialoralsession1","calendarId":"sigdialoral","category":"time","chair":"Gabriel Skantze","contents":[{"UID":"sigdial86","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs.  Despite their prevalence, there currently lacks an accurate survey of dialogue noise,  nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise.  Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise.  Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","authors":["Derek Chen","Zhou Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"86","paper":"static/papers/sigdial/86_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Sources of Noise in Dialogue and How to Deal With Them"},{"UID":"sigdial14","abstract":"Discourse relations have different patterns of marking across different languages.  As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment.  The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.","authors":["Frances Yung","Merel Scholman","Ekaterina Lapshinova-Koltunski","Christina Pollkl\u00e4sener","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"14","paper":"static/papers/sigdial/14_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:05:00+02:00","title":"Investigating Explicitation of Discourse Connectives in Translation Using Automatic Annotations"},{"UID":"sigdial43","abstract":"Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.","authors":["Yang Janet Liu","Tatsuya Aoyama","Amir Zeldes"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"43","paper":"static/papers/sigdial/43_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:25:00+02:00","title":"What's Hard in English RST Parsing? Predictive Models for Error Analysis"},{"UID":"sigdial80","abstract":"Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86&#92;% of the evaluated tasks were improved from a conversational suitability point of view.","authors":["Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"80","paper":"static/papers/sigdial/80_Paper.pdf","poster":"static/posters/SIGDIAL2023/80.pdf","session":"sigdialoralsession1","start":"2023-09-13T11:45:00+02:00","title":"Grounded Complex Task Segmentation for Conversational Assistants"},{"UID":"sigdial91","abstract":"Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners' topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.","authors":["Grace Lawley","Peter A. Heeman","Jill K. Dolata","Eric Fombonne","Steven Bedrick"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"91","paper":"static/papers/sigdial/91_Paper.pdf","poster":"static/posters/SIGDIAL2023/91.pdf","session":"sigdialoralsession1","start":"2023-09-13T12:05:00+02:00","title":"A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#sigdialoralsession1","name":"Sigdial Oral Session 1: Analysis of discourse and dialogue","room":"Sun I","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"Sigdial Oral Session 1: Analysis of discourse and dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples"},{"UID":"inlg71","abstract":"Prior art investigating task-oriented dialog and automatic generation of such dialogs have focused on single-user dialogs between a single user and an agent. However, there is limited study on adapting such AI agents to multi-user conversations (involving multiple users and an agent). Multi-user conversations are richer than single-user conversations containing social banter and collaborative decision making. The most significant challenge impeding such studies is the lack of suitable multi-user task-oriented dialogs with annotations of user belief states and system actions. One potential solution is multi-user dialog generation from single-user data. Many single-user dialogs datasets already contain dialog state information (intents, slots), thus making them suitable candidates. In this work, we propose a novel approach for expanding single-user task-oriented dialogs (e.g. MultiWOZ) to multi-user dialogs in a zero-shot setting.","authors":["Shiv Surya","Yohan Jo","Arijit Biswas","Alexandros Potamianos"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"71","paper":"static/papers/inlg/71_Paper.pdf","poster":"","session":"inlgoralsession5","sessions":[{"UID":"inlgoralsession5","calendarId":"inlgoral","category":"time","chair":"Dimitra Gkatzia","contents":[{"UID":"inlg16","abstract":"In this work, we investigate Data Augmentation methods to improve the performance of state-of-the-art models for four different downstream tasks. Specifically, we propose Generative Adversarial Network using Language Models (GAN-LM) approach that combines a deep generative model with a pre-trained language model to produce diverse augmentations. We compare the GAN-LM to various conventional methods in non-contextual- and contextual-levels on four public datasets: ZESHEL for zero-shot entity linking, TREC for question classification, STS-B for sentence pairs semantic textual similarity (STS), and mSTS for multilingual sentence pairs STS. Additionally, we subsample these datasets to study the impact of such augmentations in low-resource settings where limited amounts of training data is available. Compared to the state-of-the-art methods in downstream tasks, we mostly achieve the best performance using GAN-LM approach. Finally, we investigate the way of combining the GAN-LM with other augmentation methods to complement our proposed approach. The developed code for reproducibility is included in the supplementary material.","authors":["Dae Yon Hwang","Yaroslav Nechaev","Cyprien de Lichy","Renxian Zhang"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"16","paper":"static/papers/inlg/16_Paper.pdf","poster":"static/posters/INLG2023/16.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"GAN-LM: Generative Adversarial Network Using Language Models for Downstream Applications"},{"UID":"inlg24","abstract":"Good figure captions help paper readers understand complex scientific figures. Unfortunately, even published papers often have poorly written captions. Automatic caption generation could aid paper writers by providing good starting captions that can be refined for better quality. Prior work often treated figure caption generation as a vision-to-language task. In this paper, we show that it can be more effectively tackled as a text summarization task in scientific documents. We fine-tuned PEGASUS, a pre-trained abstractive summarization model, to specifically summarize figure-referencing paragraphs (e.g., \"Figure 3 shows...\") into figure captions. Experiments on large-scale arXiv figures show that our method outperforms prior vision methods in both automatic and human evaluations. We further conducted an in-depth investigation focused on two key challenges: (i) the common presence of low-quality author-written captions and (ii) the lack of clear standards for good captions. Our code and data are available at: https://github.com/Crowd-AI-Lab/Generating-Figure-Captions-as-a-Text-Summarization-Task.","authors":["Chieh-Yang Huang","Ting-Yao Hsu","Ryan Rossi","Ani Nenkova","Sungchul Kim","Gromit Yeuk-Yin Chan","Eunyee Koh","C Lee Giles","Ting-Hao Huang"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"24","paper":"static/papers/inlg/24_Paper.pdf","poster":"static/posters/INLG2023/24.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Summaries as Captions: Generating Figure Captions for Scientific Documents With Automated Text Summarization"},{"UID":"inlg47","abstract":"An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often specifies claims with details, whereas it adds less evidence than humans do. Moreover, its capabilities generalize well to other domains, such as instructional texts.","authors":["Gabriella Skitalinskaya","Maximilian Splieth\u00f6ver","Henning Wachsmuth"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"47","paper":"static/papers/inlg/47_Paper.pdf","poster":"static/posters/INLG2023/47.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Claim Optimization in Computational Argumentation"},{"UID":"inlg71","abstract":"Prior art investigating task-oriented dialog and automatic generation of such dialogs have focused on single-user dialogs between a single user and an agent. However, there is limited study on adapting such AI agents to multi-user conversations (involving multiple users and an agent). Multi-user conversations are richer than single-user conversations containing social banter and collaborative decision making. The most significant challenge impeding such studies is the lack of suitable multi-user task-oriented dialogs with annotations of user belief states and system actions. One potential solution is multi-user dialog generation from single-user data. Many single-user dialogs datasets already contain dialog state information (intents, slots), thus making them suitable candidates. In this work, we propose a novel approach for expanding single-user task-oriented dialogs (e.g. MultiWOZ) to multi-user dialogs in a zero-shot setting.","authors":["Shiv Surya","Yohan Jo","Arijit Biswas","Alexandros Potamianos"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"71","paper":"static/papers/inlg/71_Paper.pdf","poster":"","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"A Zero-Shot Approach for Multi-User Task-Oriented Dialog Generation"}],"day":"Friday","discord":"https://discord.com/channels/###inlgoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#inlgoralsession5","name":"INLG Oral Session 5: NLG for real-world applications","room":"Sun II","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"INLG Oral Session 5: NLG for real-world applications","zoom":"https://zoom.us/j/###Sun II###"}],"title":"A Zero-Shot Approach for Multi-User Task-Oriented Dialog Generation"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial15","abstract":"With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.","authors":["Ekaterina Svikhnushina","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"15","paper":"static/papers/sigdial/15_Paper.pdf","poster":"","session":"sigdialoralsession3","sessions":[{"UID":"sigdialoralsession3","calendarId":"sigdialoral","category":"time","chair":"Frederic Bechet","contents":[{"UID":"sigdial79","abstract":"Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.","authors":["Qingyang Wu","James Gung","Raphael Shu","Yi Zhang"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"79","paper":"static/papers/sigdial/79_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:30:00+02:00","title":"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"},{"UID":"sigdial15","abstract":"With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.","authors":["Ekaterina Svikhnushina","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"15","paper":"static/papers/sigdial/15_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:50:00+02:00","title":"Approximating Online Human Evaluation of Social Chatbots With Prompting"},{"UID":"sigdial12","abstract":"Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.","authors":["Ayaka Ueyama","Yoshinobu Kano"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"12","paper":"static/papers/sigdial/12_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:10:00+02:00","title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution"},{"UID":"sigdial129","abstract":"Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce &#92;textsc{Syndicom} - a method for improving commonsense in dialogue response generation. &#92;textsc{Syndicom} consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.  <p>&#92;textsc{Syndicom} is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. &#92;textsc{Syndicom} achieves a relative improvement of 53&#92;% over ChatGPT on ROUGE-1, and human evaluators prefer &#92;textsc{Syndicom} over ChatGPT 57&#92;% of the time. We will publicly release the code and the full dataset.","authors":["Christopher Richardson","Larry Heck"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"129","paper":"static/papers/sigdial/129_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:30:00+02:00","title":"Syndicom: Improving Conversational Commonsense With Error-Injection and Natural Language Feedback"},{"UID":"sigdial163","abstract":"Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,\"Is the WIFI reliable?\" or \"Does the restaurant have a good atmosphere?\"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.","authors":["Chao Zhao","Spandana Gella","Seokhwan Kim","Di Jin","Devamanyu Hazarika","Alexandros Papangelis","Behnam Hedayatnia","Mahdi Namazifar","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"163","paper":"static/papers/sigdial/163_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:50:00+02:00","title":"\"What Do Others Think?\": Task-Oriented Conversational Modeling With Subjective Knowledge"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#sigdialoralsession3","name":"Sigdial Oral Session 3: Dialogue modeling and evaluation","room":"Sun I","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"Sigdial Oral Session 3: Dialogue modeling and evaluation","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Approximating Online Human Evaluation of Social Chatbots With Prompting"},{"UID":"sigdial25","abstract":"Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples.","authors":["Vojt\u011bch Hude\u010dek","Ondrej Du\u0161ek"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"25","paper":"static/papers/sigdial/25_Paper.pdf","poster":"static/posters/SIGDIAL2023/25.pdf","session":"sigdialoralsession2","sessions":[{"UID":"sigdialoralsession2","calendarId":"sigdialoral","category":"time","chair":"Dilek Hakkani-Tur","contents":[{"UID":"sigdial106","abstract":"Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses.  However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.","authors":["Sarah E. Finch","Ellie S. Paek","Jinho D. Choi"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"106","paper":"static/papers/sigdial/106_Paper.pdf","poster":"static/posters/SIGDIAL2023/106.pdf","session":"sigdialoralsession2","start":"2023-09-13T15:40:00+02:00","title":"Leveraging Large Language Models for Automated Dialogue Analysis"},{"UID":"sigdial25","abstract":"Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples.","authors":["Vojt\u011bch Hude\u010dek","Ondrej Du\u0161ek"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"25","paper":"static/papers/sigdial/25_Paper.pdf","poster":"static/posters/SIGDIAL2023/25.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:00:00+02:00","title":"Are Large Language Models All You Need for Task-Oriented Dialogue?"},{"UID":"sigdial109","abstract":"This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The 'reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A 'story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.","authors":["Angus Addlesee","Weronika Siei\u0144ska","Nancie Gunson","Daniel Hernandez Garcia","Christian Dondrup","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"109","paper":"static/papers/sigdial/109_Paper.pdf","poster":"static/posters/SIGDIAL2023/109.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:20:00+02:00","title":"Multi-Party Goal Tracking With LLMs: Comparing Pre-Training, Fine-Tuning, and Prompt Engineering"},{"UID":"sigdial156","abstract":"This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.","authors":["Lidiia Ostyakova","Veronika Smilga","Kseniia Petukhova","Maria Molchanova","Daniel Kornev"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"156","paper":"static/papers/sigdial/156_Paper.pdf","poster":"static/posters/SIGDIAL2023/156.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:40:00+02:00","title":"ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations With Speech Functions"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession2###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#sigdialoralsession2","name":"Sigdial Oral Session 2: LLM for dialogue","room":"Sun I","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"Sigdial Oral Session 2: LLM for dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Are Large Language Models All You Need for Task-Oriented Dialogue?"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg83","abstract":"Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.","authors":["Judith Sieker","Oliver Bott","Torgrim Solstad","Sina Zarrie\u00df"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"83","paper":"static/papers/inlg/83_Paper.pdf","poster":"static/posters/INLG2023/83.pdf","session":"inlgoralsession4","sessions":[{"UID":"inlgoralsession4","calendarId":"inlgoral","category":"time","chair":"Albert Gatt","contents":[{"UID":"inlg30","abstract":"In recent years, many NLP studies have focused solely on performance improvement. In this work, we focus on the linguistic and scientific aspects of NLP. We use the task of generating referring expressions in context (REG-in-context) as a case study and start our analysis from GREC, a comprehensive set of shared tasks in English that addressed this topic over a decade ago. We ask what the performance of models would be if we assessed them (1) on more realistic datasets, and (2) using more advanced methods. We test the models using different evaluation metrics and feature selection experiments. We conclude that GREC can no longer be regarded as offering a reliable assessment of models' ability to mimic human reference production, because the results are highly impacted by the choice of corpus and evaluation metrics. Our results also suggest that pre-trained language models are less dependent on the choice of corpus than classic Machine Learning models, and therefore make more robust class predictions.","authors":["Fahime Same","Guanyi Chen","Kees van Deemter"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"30","paper":"static/papers/inlg/30_Paper.pdf","poster":"static/posters/INLG2023/30.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Models of Reference Production: How Do They Withstand the Test of Time?"},{"UID":"inlg57","abstract":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","authors":["Miriam Ansch\u00fctz","Diego Miguel Lozano","Georg Groh"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"57","paper":"static/papers/inlg/57_Paper.pdf","poster":"static/posters/INLG2023/57.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"This Is Not Correct! Negation-Aware Evaluation of Language Generation Systems"},{"UID":"inlg83","abstract":"Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.","authors":["Judith Sieker","Oliver Bott","Torgrim Solstad","Sina Zarrie\u00df"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"83","paper":"static/papers/inlg/83_Paper.pdf","poster":"static/posters/INLG2023/83.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models"},{"UID":"inlg115","abstract":"Language-capable robots must be able to efficiently and naturally communicate about objects in the environment. A key part of communication is Referring Form Selection (RFS): the process of selecting a form like it, that, or the N to use when referring to an object. Recent cognitive status-informed computational RFS models have been evaluated in terms of goodness-of-fit to human data. But it is as yet unclear whether these models actually select referring forms that are any more natural than baseline alternatives, regardless of goodness-of-fit. Through a human subject study designed to assess this question, we show that even though cognitive status-informed referring selection models achieve good fit to human data, they do not (yet) produce concrete benefits in terms of naturality. On the other hand, our results show that human utterances also had high variability in perceived naturality, demonstrating the challenges of evaluating RFS naturality.","authors":["Gabriel Del Castillo","Grace Clark","Zhao Han","Tom Williams"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"115","paper":"static/papers/inlg/115_Paper.pdf","poster":"static/posters/INLG2023/115.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Exploring the Naturalness of Cognitive Status-Informed Referring Form Selection Models"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession4###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#inlgoralsession4","name":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","room":"Sun II","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Bullshit, Pragmatic Deception, and Natural Language Processing"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial156","abstract":"This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.","authors":["Lidiia Ostyakova","Veronika Smilga","Kseniia Petukhova","Maria Molchanova","Daniel Kornev"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"156","paper":"static/papers/sigdial/156_Paper.pdf","poster":"static/posters/SIGDIAL2023/156.pdf","session":"sigdialoralsession2","sessions":[{"UID":"sigdialoralsession2","calendarId":"sigdialoral","category":"time","chair":"Dilek Hakkani-Tur","contents":[{"UID":"sigdial106","abstract":"Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses.  However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.","authors":["Sarah E. Finch","Ellie S. Paek","Jinho D. Choi"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"106","paper":"static/papers/sigdial/106_Paper.pdf","poster":"static/posters/SIGDIAL2023/106.pdf","session":"sigdialoralsession2","start":"2023-09-13T15:40:00+02:00","title":"Leveraging Large Language Models for Automated Dialogue Analysis"},{"UID":"sigdial25","abstract":"Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples.","authors":["Vojt\u011bch Hude\u010dek","Ondrej Du\u0161ek"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"25","paper":"static/papers/sigdial/25_Paper.pdf","poster":"static/posters/SIGDIAL2023/25.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:00:00+02:00","title":"Are Large Language Models All You Need for Task-Oriented Dialogue?"},{"UID":"sigdial109","abstract":"This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The 'reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A 'story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.","authors":["Angus Addlesee","Weronika Siei\u0144ska","Nancie Gunson","Daniel Hernandez Garcia","Christian Dondrup","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"109","paper":"static/papers/sigdial/109_Paper.pdf","poster":"static/posters/SIGDIAL2023/109.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:20:00+02:00","title":"Multi-Party Goal Tracking With LLMs: Comparing Pre-Training, Fine-Tuning, and Prompt Engineering"},{"UID":"sigdial156","abstract":"This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.","authors":["Lidiia Ostyakova","Veronika Smilga","Kseniia Petukhova","Maria Molchanova","Daniel Kornev"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"156","paper":"static/papers/sigdial/156_Paper.pdf","poster":"static/posters/SIGDIAL2023/156.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:40:00+02:00","title":"ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations With Speech Functions"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession2###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#sigdialoralsession2","name":"Sigdial Oral Session 2: LLM for dialogue","room":"Sun I","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"Sigdial Oral Session 2: LLM for dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations With Speech Functions"},{"UID":"inlg56","abstract":"Large Language Models, and ChatGPT in particular, have recently grabbed the attention of the community and the media. Having reached high language proficiency, attention has been shifting toward its reasoning capabilities. In this paper, our main aim is to evaluate ChatGPT's question generation in a task where language production should be driven by an implicit reasoning process. To this end, we employ the 20-Questions game, traditionally used within the Cognitive Science community to inspect the information seeking-strategy's development.  This task requires a series of interconnected skills: asking informative questions, stepwise updating the hypothesis space, and stopping asking questions when enough information has been collected. We build hierarchical hypothesis spaces, exploiting feature norms collected from humans vs. ChatGPT itself, and we inspect the efficiency and informativeness of ChatGPT's strategy. Our results show that ChatGPT's performance gets closer to an optimal agent only when prompted to explicitly list the updated space stepwise.","authors":["Leonardo Bertolazzi","Davide Mazzaccara","Filippo Merlo","Raffaella Bernardi"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"56","paper":"static/papers/inlg/56_Paper.pdf","poster":"","session":"inlgoralsession3","sessions":[{"UID":"inlgoralsession3","calendarId":"inlgoral","category":"time","chair":"Tom Williams","contents":[{"UID":"inlg15","abstract":"While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model's performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.","authors":["Mina Almasi","Anton Schi\u00f8nning"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"15","paper":"static/papers/inlg/15_Paper.pdf","poster":"static/posters/INLG2023/15.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Fine-Tuning GPT-3 for Synthetic Danish News Generation"},{"UID":"inlg56","abstract":"Large Language Models, and ChatGPT in particular, have recently grabbed the attention of the community and the media. Having reached high language proficiency, attention has been shifting toward its reasoning capabilities. In this paper, our main aim is to evaluate ChatGPT's question generation in a task where language production should be driven by an implicit reasoning process. To this end, we employ the 20-Questions game, traditionally used within the Cognitive Science community to inspect the information seeking-strategy's development.  This task requires a series of interconnected skills: asking informative questions, stepwise updating the hypothesis space, and stopping asking questions when enough information has been collected. We build hierarchical hypothesis spaces, exploiting feature norms collected from humans vs. ChatGPT itself, and we inspect the efficiency and informativeness of ChatGPT's strategy. Our results show that ChatGPT's performance gets closer to an optimal agent only when prompted to explicitly list the updated space stepwise.","authors":["Leonardo Bertolazzi","Davide Mazzaccara","Filippo Merlo","Raffaella Bernardi"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"56","paper":"static/papers/inlg/56_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"ChatGPT's Information Seeking Strategy: Insights From the 20-Questions Game"},{"UID":"inlg99","abstract":"In this paper, we present a system for augmenting virtual AI characters with long-term memory, enabling them to remember facts about themselves, their world, and past experiences. We propose a memory-creation pipeline that converts raw text into condensed memories and a memory-retrieval system that utilizes these memories to generate character responses. Using a fact-checking pipeline based on GPT-4, our evaluation demonstrates that the character responses are grounded in the retrieved memories and maintain factual accuracy. We discuss the implications of our system for creating engaging and consistent virtual characters and highlight areas for future research, including large language model (LLM) guardrailing and virtual character personality development.","authors":["Fabian Landwehr","Erika Varis Doggett","Romann M. Weber"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"99","paper":"static/papers/inlg/99_Paper.pdf","poster":"static/posters/INLG2023/99.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Memories for Virtual AI Characters"},{"UID":"inlg107","abstract":"In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behavior of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.","authors":["Subhadra Vadlamannati","G\u00f6zde \u015eahin"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"107","paper":"static/papers/inlg/107_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Metric-Based in-Context Learning: A Case Study in Text Simplification"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#inlgoralsession3","name":"INLG Oral Session 3: Leveraging Large Language Models for NLG","room":"Sun II","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"INLG Oral Session 3: Leveraging Large Language Models for NLG","zoom":"https://zoom.us/j/###Sun II###"}],"title":"ChatGPT's Information Seeking Strategy: Insights From the 20-Questions Game"},{"UID":"inlg47","abstract":"An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often specifies claims with details, whereas it adds less evidence than humans do. Moreover, its capabilities generalize well to other domains, such as instructional texts.","authors":["Gabriella Skitalinskaya","Maximilian Splieth\u00f6ver","Henning Wachsmuth"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"47","paper":"static/papers/inlg/47_Paper.pdf","poster":"static/posters/INLG2023/47.pdf","session":"inlgoralsession5","sessions":[{"UID":"inlgoralsession5","calendarId":"inlgoral","category":"time","chair":"Dimitra Gkatzia","contents":[{"UID":"inlg16","abstract":"In this work, we investigate Data Augmentation methods to improve the performance of state-of-the-art models for four different downstream tasks. Specifically, we propose Generative Adversarial Network using Language Models (GAN-LM) approach that combines a deep generative model with a pre-trained language model to produce diverse augmentations. We compare the GAN-LM to various conventional methods in non-contextual- and contextual-levels on four public datasets: ZESHEL for zero-shot entity linking, TREC for question classification, STS-B for sentence pairs semantic textual similarity (STS), and mSTS for multilingual sentence pairs STS. Additionally, we subsample these datasets to study the impact of such augmentations in low-resource settings where limited amounts of training data is available. Compared to the state-of-the-art methods in downstream tasks, we mostly achieve the best performance using GAN-LM approach. Finally, we investigate the way of combining the GAN-LM with other augmentation methods to complement our proposed approach. The developed code for reproducibility is included in the supplementary material.","authors":["Dae Yon Hwang","Yaroslav Nechaev","Cyprien de Lichy","Renxian Zhang"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"16","paper":"static/papers/inlg/16_Paper.pdf","poster":"static/posters/INLG2023/16.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"GAN-LM: Generative Adversarial Network Using Language Models for Downstream Applications"},{"UID":"inlg24","abstract":"Good figure captions help paper readers understand complex scientific figures. Unfortunately, even published papers often have poorly written captions. Automatic caption generation could aid paper writers by providing good starting captions that can be refined for better quality. Prior work often treated figure caption generation as a vision-to-language task. In this paper, we show that it can be more effectively tackled as a text summarization task in scientific documents. We fine-tuned PEGASUS, a pre-trained abstractive summarization model, to specifically summarize figure-referencing paragraphs (e.g., \"Figure 3 shows...\") into figure captions. Experiments on large-scale arXiv figures show that our method outperforms prior vision methods in both automatic and human evaluations. We further conducted an in-depth investigation focused on two key challenges: (i) the common presence of low-quality author-written captions and (ii) the lack of clear standards for good captions. Our code and data are available at: https://github.com/Crowd-AI-Lab/Generating-Figure-Captions-as-a-Text-Summarization-Task.","authors":["Chieh-Yang Huang","Ting-Yao Hsu","Ryan Rossi","Ani Nenkova","Sungchul Kim","Gromit Yeuk-Yin Chan","Eunyee Koh","C Lee Giles","Ting-Hao Huang"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"24","paper":"static/papers/inlg/24_Paper.pdf","poster":"static/posters/INLG2023/24.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Summaries as Captions: Generating Figure Captions for Scientific Documents With Automated Text Summarization"},{"UID":"inlg47","abstract":"An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often specifies claims with details, whereas it adds less evidence than humans do. Moreover, its capabilities generalize well to other domains, such as instructional texts.","authors":["Gabriella Skitalinskaya","Maximilian Splieth\u00f6ver","Henning Wachsmuth"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"47","paper":"static/papers/inlg/47_Paper.pdf","poster":"static/posters/INLG2023/47.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Claim Optimization in Computational Argumentation"},{"UID":"inlg71","abstract":"Prior art investigating task-oriented dialog and automatic generation of such dialogs have focused on single-user dialogs between a single user and an agent. However, there is limited study on adapting such AI agents to multi-user conversations (involving multiple users and an agent). Multi-user conversations are richer than single-user conversations containing social banter and collaborative decision making. The most significant challenge impeding such studies is the lack of suitable multi-user task-oriented dialogs with annotations of user belief states and system actions. One potential solution is multi-user dialog generation from single-user data. Many single-user dialogs datasets already contain dialog state information (intents, slots), thus making them suitable candidates. In this work, we propose a novel approach for expanding single-user task-oriented dialogs (e.g. MultiWOZ) to multi-user dialogs in a zero-shot setting.","authors":["Shiv Surya","Yohan Jo","Arijit Biswas","Alexandros Potamianos"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"71","paper":"static/papers/inlg/71_Paper.pdf","poster":"","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"A Zero-Shot Approach for Multi-User Task-Oriented Dialog Generation"}],"day":"Friday","discord":"https://discord.com/channels/###inlgoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#inlgoralsession5","name":"INLG Oral Session 5: NLG for real-world applications","room":"Sun II","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"INLG Oral Session 5: NLG for real-world applications","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Claim Optimization in Computational Argumentation"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"},{"UID":"sigdial79","abstract":"Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.","authors":["Qingyang Wu","James Gung","Raphael Shu","Yi Zhang"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"79","paper":"static/papers/sigdial/79_Paper.pdf","poster":"","session":"sigdialoralsession3","sessions":[{"UID":"sigdialoralsession3","calendarId":"sigdialoral","category":"time","chair":"Frederic Bechet","contents":[{"UID":"sigdial79","abstract":"Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.","authors":["Qingyang Wu","James Gung","Raphael Shu","Yi Zhang"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"79","paper":"static/papers/sigdial/79_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:30:00+02:00","title":"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"},{"UID":"sigdial15","abstract":"With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.","authors":["Ekaterina Svikhnushina","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"15","paper":"static/papers/sigdial/15_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:50:00+02:00","title":"Approximating Online Human Evaluation of Social Chatbots With Prompting"},{"UID":"sigdial12","abstract":"Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.","authors":["Ayaka Ueyama","Yoshinobu Kano"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"12","paper":"static/papers/sigdial/12_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:10:00+02:00","title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution"},{"UID":"sigdial129","abstract":"Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce &#92;textsc{Syndicom} - a method for improving commonsense in dialogue response generation. &#92;textsc{Syndicom} consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.  <p>&#92;textsc{Syndicom} is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. &#92;textsc{Syndicom} achieves a relative improvement of 53&#92;% over ChatGPT on ROUGE-1, and human evaluators prefer &#92;textsc{Syndicom} over ChatGPT 57&#92;% of the time. We will publicly release the code and the full dataset.","authors":["Christopher Richardson","Larry Heck"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"129","paper":"static/papers/sigdial/129_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:30:00+02:00","title":"Syndicom: Improving Conversational Commonsense With Error-Injection and Natural Language Feedback"},{"UID":"sigdial163","abstract":"Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,\"Is the WIFI reliable?\" or \"Does the restaurant have a good atmosphere?\"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.","authors":["Chao Zhao","Spandana Gella","Seokhwan Kim","Di Jin","Devamanyu Hazarika","Alexandros Papangelis","Behnam Hedayatnia","Mahdi Namazifar","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"163","paper":"static/papers/sigdial/163_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:50:00+02:00","title":"\"What Do Others Think?\": Task-Oriented Conversational Modeling With Subjective Knowledge"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#sigdialoralsession3","name":"Sigdial Oral Session 3: Dialogue modeling and evaluation","room":"Sun I","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"Sigdial Oral Session 3: Dialogue modeling and evaluation","zoom":"https://zoom.us/j/###Sun I###"}],"title":"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial12","abstract":"Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.","authors":["Ayaka Ueyama","Yoshinobu Kano"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"12","paper":"static/papers/sigdial/12_Paper.pdf","poster":"","session":"sigdialoralsession3","sessions":[{"UID":"sigdialoralsession3","calendarId":"sigdialoral","category":"time","chair":"Frederic Bechet","contents":[{"UID":"sigdial79","abstract":"Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.","authors":["Qingyang Wu","James Gung","Raphael Shu","Yi Zhang"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"79","paper":"static/papers/sigdial/79_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:30:00+02:00","title":"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"},{"UID":"sigdial15","abstract":"With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.","authors":["Ekaterina Svikhnushina","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"15","paper":"static/papers/sigdial/15_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:50:00+02:00","title":"Approximating Online Human Evaluation of Social Chatbots With Prompting"},{"UID":"sigdial12","abstract":"Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.","authors":["Ayaka Ueyama","Yoshinobu Kano"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"12","paper":"static/papers/sigdial/12_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:10:00+02:00","title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution"},{"UID":"sigdial129","abstract":"Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce &#92;textsc{Syndicom} - a method for improving commonsense in dialogue response generation. &#92;textsc{Syndicom} consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.  <p>&#92;textsc{Syndicom} is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. &#92;textsc{Syndicom} achieves a relative improvement of 53&#92;% over ChatGPT on ROUGE-1, and human evaluators prefer &#92;textsc{Syndicom} over ChatGPT 57&#92;% of the time. We will publicly release the code and the full dataset.","authors":["Christopher Richardson","Larry Heck"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"129","paper":"static/papers/sigdial/129_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:30:00+02:00","title":"Syndicom: Improving Conversational Commonsense With Error-Injection and Natural Language Feedback"},{"UID":"sigdial163","abstract":"Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,\"Is the WIFI reliable?\" or \"Does the restaurant have a good atmosphere?\"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.","authors":["Chao Zhao","Spandana Gella","Seokhwan Kim","Di Jin","Devamanyu Hazarika","Alexandros Papangelis","Behnam Hedayatnia","Mahdi Namazifar","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"163","paper":"static/papers/sigdial/163_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:50:00+02:00","title":"\"What Do Others Think?\": Task-Oriented Conversational Modeling With Subjective Knowledge"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#sigdialoralsession3","name":"Sigdial Oral Session 3: Dialogue modeling and evaluation","room":"Sun I","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"Sigdial Oral Session 3: Dialogue modeling and evaluation","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution"},{"UID":"sigdial27","abstract":"AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains \u22481.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.","authors":["Anuradha Welivita","Chun-Hung Yeh","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"27","paper":"static/papers/sigdial/27_Paper.pdf","poster":"static/posters/SIGDIAL2023/27.pdf","session":"sigdialoralsession5","sessions":[{"UID":"sigdialoralsession5","calendarId":"sigdialoral","category":"time","chair":"Mike White","contents":[{"UID":"sigdial29","abstract":"Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These \"self-imposed filter bubbles\" (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand.  <p>To address this issue, we develop a strategy for overcoming users' SFB within the course of the interaction. By continuously modeling the user's position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users' SFBs and promoting a more reflective and comprehensive discussion of the topic.","authors":["Annalena Aicher","Daniel Kornmueller","Yuki Matsuda","Stefan Ultes","Wolfgang Minker","Keiichi Yasumoto"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"29","paper":"static/papers/sigdial/29_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Towards Breaking the Self-Imposed Filter Bubble in Argumentative Dialogues"},{"UID":"sigdial81","abstract":"There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The \"openness\" of the dialogue is expected to be  maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to \"just chat about anything\" results in a very narrow form of dialogue, which we refer to as the \"open-domain paradox\". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.","authors":["Gabriel Skantze","A. Seza Do\u011fru\u00f6z"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"81","paper":"static/papers/sigdial/81_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:50:00+02:00","title":"The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue"},{"UID":"sigdial130","abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models' performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics' unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.","authors":["Sarik Ghazarian","Behnam Hedayatnia","Di Jin","Sijia Liu","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"130","paper":"static/papers/sigdial/130_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:10:00+02:00","title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems"},{"UID":"sigdial27","abstract":"AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains \u22481.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.","authors":["Anuradha Welivita","Chun-Hung Yeh","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"27","paper":"static/papers/sigdial/27_Paper.pdf","poster":"static/posters/SIGDIAL2023/27.pdf","session":"sigdialoralsession5","start":"2023-09-15T12:30:00+02:00","title":"Empathetic Response Generation for Distress Support"},{"UID":"sigdial73","abstract":"Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.","authors":["Yahui Fu","Koji Inoue","Chenhui Chu","Tatsuya Kawahara"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"73","paper":"static/papers/sigdial/73_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:50:00+02:00","title":"Reasoning Before Responding: Integrating Commonsense-Based Causality Explanation for Empathetic Response Generation"}],"day":"Friday","discord":"https://discord.com/channels/###sigdialoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#sigdialoralsession5","name":"Sigdial Oral Session 5: Topics in open-domain dialogue","room":"Sun I","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"Sigdial Oral Session 5: Topics in open-domain dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Empathetic Response Generation for Distress Support"},{"UID":"inlg97","abstract":"Neural data-to-text systems lack the control and factual accuracy required to generate useful and insightful summaries of multidimensional data. We propose a solution in the form of data views, where each view describes an entity and its attributes along specific dimensions. A sequence of views can then be used as a high-level schema for document planning, with the neural model handling the complexities of micro-planning and surface realization. We show that our view-based system retains factual accuracy while offering high-level control of output that can be tailored based on user preference or other norms within the domain.","authors":["Craig Thomson","Clement Rebuffel","Ehud Reiter","Laure Soulier","Somayajulu Sripada","patrick Gallinari"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"97","paper":"static/papers/inlg/97_Paper.pdf","poster":"static/posters/INLG2023/97.pdf","session":"inlgoralsession1","sessions":[{"UID":"inlgoralsession1","calendarId":"inlgoral","category":"time","chair":"Ching-Chi-Chen","contents":[{"UID":"inlg12","abstract":"Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data and aids in the development of countermeasures. Many prior works---and some recently deployed defenses---focus on ``verbatim memorization'', defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense that _perfectly_ prevents all verbatim memorization.  And yet, we demonstrate that this ``perfect'' filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified ``style-transfer'' prompts---and in some cases even the non-modified original prompts---to extract memorized information. We conclude by discussing potential alternative definitions and why defining memorization is a difficult yet crucial open question for neural language models.","authors":["Daphne Ippolito","Florian Tramer","Milad Nasr","Chiyuan Zhang","Matthew Jagielski","Katherine Lee","Christopher Choquette Choo","Nicholas Carlini"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"12","paper":"static/papers/inlg/12_Paper.pdf","poster":"static/posters/INLG2023/12.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Preventing Generation of Verbatim Memorization in Language Models Gives a False Sense of Privacy"},{"UID":"inlg34","abstract":"Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.","authors":["Tahsina Hashem","Weiqing Wang","Derry Tanti Wijaya","Mohammed Eunus Ali","Yuan-Fang Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"34","paper":"static/papers/inlg/34_Paper.pdf","poster":"static/posters/INLG2023/34.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Generating Faithful Text From a Knowledge Graph With Noisy Reference Text"},{"UID":"inlg58","abstract":"Automatically summarizing radiology reports into a concise impression can reduce the manual burden of clinicians and improve the consistency of reporting. Previous work aimed to enhance content selection and factuality through guided abstractive summarization. However, two key issues persist. First, current methods heavily rely on domain-specific resources to extract the guidance signal, limiting their transferability to domains and languages where those resources are unavailable. Second, while automatic metrics like ROUGE show progress, we lack a good understanding of the errors and failure modes in this task. To bridge these gaps, we first propose a domain-agnostic guidance signal in form of variable-length extractive summaries. Our empirical results on two English benchmarks demonstrate that this guidance signal improves upon unguided summarization while being competitive with domain-specific methods. Additionally, we run an expert evaluation of four systems according to a taxonomy of 11 fine-grained errors. We find that the most pressing differences between automatic summaries and those of radiologists relate to content selection including omissions (up to 52%) and additions (up to 57%). We hypothesize that latent reporting factors and corpus-level inconsistencies may limit models to reliably learn content selection from the available data, presenting promising directions for future work.","authors":["Jan Trienes","Paul Youssef","J\u00f6rg Schl\u00f6tterer","Christin Seifert"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"58","paper":"static/papers/inlg/58_Paper.pdf","poster":"static/posters/INLG2023/58.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Guidance in Radiology Report Summarization: An Empirical Evaluation and Error Analysis"},{"UID":"inlg97","abstract":"Neural data-to-text systems lack the control and factual accuracy required to generate useful and insightful summaries of multidimensional data. We propose a solution in the form of data views, where each view describes an entity and its attributes along specific dimensions. A sequence of views can then be used as a high-level schema for document planning, with the neural model handling the complexities of micro-planning and surface realization. We show that our view-based system retains factual accuracy while offering high-level control of output that can be tailored based on user preference or other norms within the domain.","authors":["Craig Thomson","Clement Rebuffel","Ehud Reiter","Laure Soulier","Somayajulu Sripada","patrick Gallinari"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"97","paper":"static/papers/inlg/97_Paper.pdf","poster":"static/posters/INLG2023/97.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Enhancing Factualness and Controllability of Data-to-Text Generation via Data Views and Constraints"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#inlgoralsession1","name":"INLG Oral Session 1: Trustworthiness of NLG systems","room":"Sun II","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"INLG Oral Session 1: Trustworthiness of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Enhancing Factualness and Controllability of Data-to-Text Generation via Data Views and Constraints"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"inlg44","abstract":"Research in Multi-document Summarization (MDS) mostly focuses on the English language and depends on large MDS datasets that are not available for other languages. Some of these approaches concatenate the source documents, resulting in overlong model inputs. Existing transformer architectures are unable to process such long inputs entirely, omitting documents in the summarization process. Other solutions address this issue by implementing multi-stage approaches that also require changes in the model architecture. In this paper, we introduce various sampling approaches based on information entropy that allow us to perform MDS in a single stage. These approaches also consider all source documents without using MDS training data nor changing the model's architecture. Besides, we build a MDS test set of German news articles to assess the performance of our methods on abstractive multi-document summaries. Experimental results show that our entropy-based approaches outperform previous state-of-the-art on German MDS, while still remaining primarily abstractive. We release our code and MDS test set to encourage further research in German abstractive MDS.","authors":["Laura Mascarell","Ribin Chalumattu","Julien Heitmann"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"44","paper":"static/papers/inlg/44_Paper.pdf","poster":"static/posters/INLG2023/44.pdf","session":"inlgoralsession2","sessions":[{"UID":"inlgoralsession2","calendarId":"inlgoral","category":"time","chair":"Gozde Gul Sahin","contents":[{"UID":"inlg9","abstract":"In this paper, we introduce a new beam search algorithm that improves the generalization of neural generators to unseen examples, especially in low-resource data-to-text settings. Our algorithm aims to reduce the number of omissions and hallucinations during the decoding process. For this purpose, it relies on two regression models to explicitly characterize factual errors. We explain how to create a new dataset to train these models given an original training set of less than a thousand data points. We apply our approach in the low-resource, legal setting using the French Plum2Text dataset, as well as in English using WebNLG. We observe in our experiment that this combination improves the faithfulness of pre-trained neural text generators using both human and automatic evaluation. Moreover, our approach offers a level of interpretability by predicting the number of omissions and hallucinations present in a given generation with respect to the input data. Finally, we visualize our algorithm's exploration of the hypothesis space at different steps during the decoding process.","authors":["Nicolas Garneau","Luc Lamontagne"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"9","paper":"static/papers/inlg/9_Paper.pdf","poster":"static/posters/INLG2023/9.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation"},{"UID":"inlg10","abstract":"Multiple business scenarios require an automated generation of descriptive human-readable text from structured input data. This has resulted into substantial work on fact-to-text generation systems recently. Unfortunately, previous work on fact-to-text (F2T) generation has focused primarily on English mainly due to the high availability of relevant datasets. Only recently, the problem of cross-lingual fact-to-text (XF2T) was proposed for generation across multiple languages alongwith a dataset, XAlign for eight languages. However, there has been no rigorous work on the actual XF2T generation problem. We extend XAlign dataset with annotated data for four more languages: Punjabi, Malayalam, Assamese and Oriya. We conduct an extensive study using popular Transformer-based text generation models on our extended multi-lingual dataset, which we call XAlignV2. Further, we investigate the performance of different text generation strategies: multiple variations of pretraining, fact-aware embeddings and structure-aware input encoding. Our extensive experiments show that a multi-lingual mT5 model which uses fact-aware embeddings with structure-aware input encoding leads to best results (30.90 BLEU, 55.12 METEOR and 59.17 chrF++) across the twelve languages. We make our code, dataset and model publicly available, and hope that this will help advance further research in this critical area.","authors":["Shivprasad Sagare","Tushar Abhishek","Bhavyajeet Singh","Anubhav Sharma","Manish Gupta","Vasudeva Varma"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"10","paper":"static/papers/inlg/10_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"XF2T: Cross-Lingual Fact-to-Text Generation for Low-Resource Languages"},{"UID":"inlg44","abstract":"Research in Multi-document Summarization (MDS) mostly focuses on the English language and depends on large MDS datasets that are not available for other languages. Some of these approaches concatenate the source documents, resulting in overlong model inputs. Existing transformer architectures are unable to process such long inputs entirely, omitting documents in the summarization process. Other solutions address this issue by implementing multi-stage approaches that also require changes in the model architecture. In this paper, we introduce various sampling approaches based on information entropy that allow us to perform MDS in a single stage. These approaches also consider all source documents without using MDS training data nor changing the model's architecture. Besides, we build a MDS test set of German news articles to assess the performance of our methods on abstractive multi-document summaries. Experimental results show that our entropy-based approaches outperform previous state-of-the-art on German MDS, while still remaining primarily abstractive. We release our code and MDS test set to encourage further research in German abstractive MDS.","authors":["Laura Mascarell","Ribin Chalumattu","Julien Heitmann"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"44","paper":"static/papers/inlg/44_Paper.pdf","poster":"static/posters/INLG2023/44.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Entropy-Based Sampling for Abstractive Multi-Document Summarization in Low-Resource Settings"},{"UID":"inlg80","abstract":"Text style transfer (TST) involves transforming a text into a desired style while approximately preserving its content. The biggest challenge in TST in the general lack of parallel data. Many existing approaches rely on complex models using substantial non-parallel data, with mixed results. In this paper, we leverage a pretrained BART language model with minimal parallel data and incorporate low-resource methods such as hyperparameter tuning, data augmentation, and self-training, which have not been explored in TST. We further include novel style-based rewards in the training loss. Through extensive experiments in sentiment transfer, a sub-task of TST, we demonstrate that our simple yet effective approaches achieve well-balanced results, surpassing non-parallel approaches and highlighting the usefulness of parallel data even in small amounts.","authors":["Sourabrata Mukherjee","Ondrej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"80","paper":"static/papers/inlg/80_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Leveraging Low-Resource Parallel Data for Text Style Transfer"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession2###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#inlgoralsession2","name":"INLG Oral Session 2: NLG for low-resourced settings","room":"Sun II","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"INLG Oral Session 2: NLG for low-resourced settings","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Entropy-Based Sampling for Abstractive Multi-Document Summarization in Low-Resource Settings"},{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg115","abstract":"Language-capable robots must be able to efficiently and naturally communicate about objects in the environment. A key part of communication is Referring Form Selection (RFS): the process of selecting a form like it, that, or the N to use when referring to an object. Recent cognitive status-informed computational RFS models have been evaluated in terms of goodness-of-fit to human data. But it is as yet unclear whether these models actually select referring forms that are any more natural than baseline alternatives, regardless of goodness-of-fit. Through a human subject study designed to assess this question, we show that even though cognitive status-informed referring selection models achieve good fit to human data, they do not (yet) produce concrete benefits in terms of naturality. On the other hand, our results show that human utterances also had high variability in perceived naturality, demonstrating the challenges of evaluating RFS naturality.","authors":["Gabriel Del Castillo","Grace Clark","Zhao Han","Tom Williams"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"115","paper":"static/papers/inlg/115_Paper.pdf","poster":"static/posters/INLG2023/115.pdf","session":"inlgoralsession4","sessions":[{"UID":"inlgoralsession4","calendarId":"inlgoral","category":"time","chair":"Albert Gatt","contents":[{"UID":"inlg30","abstract":"In recent years, many NLP studies have focused solely on performance improvement. In this work, we focus on the linguistic and scientific aspects of NLP. We use the task of generating referring expressions in context (REG-in-context) as a case study and start our analysis from GREC, a comprehensive set of shared tasks in English that addressed this topic over a decade ago. We ask what the performance of models would be if we assessed them (1) on more realistic datasets, and (2) using more advanced methods. We test the models using different evaluation metrics and feature selection experiments. We conclude that GREC can no longer be regarded as offering a reliable assessment of models' ability to mimic human reference production, because the results are highly impacted by the choice of corpus and evaluation metrics. Our results also suggest that pre-trained language models are less dependent on the choice of corpus than classic Machine Learning models, and therefore make more robust class predictions.","authors":["Fahime Same","Guanyi Chen","Kees van Deemter"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"30","paper":"static/papers/inlg/30_Paper.pdf","poster":"static/posters/INLG2023/30.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Models of Reference Production: How Do They Withstand the Test of Time?"},{"UID":"inlg57","abstract":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","authors":["Miriam Ansch\u00fctz","Diego Miguel Lozano","Georg Groh"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"57","paper":"static/papers/inlg/57_Paper.pdf","poster":"static/posters/INLG2023/57.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"This Is Not Correct! Negation-Aware Evaluation of Language Generation Systems"},{"UID":"inlg83","abstract":"Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.","authors":["Judith Sieker","Oliver Bott","Torgrim Solstad","Sina Zarrie\u00df"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"83","paper":"static/papers/inlg/83_Paper.pdf","poster":"static/posters/INLG2023/83.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models"},{"UID":"inlg115","abstract":"Language-capable robots must be able to efficiently and naturally communicate about objects in the environment. A key part of communication is Referring Form Selection (RFS): the process of selecting a form like it, that, or the N to use when referring to an object. Recent cognitive status-informed computational RFS models have been evaluated in terms of goodness-of-fit to human data. But it is as yet unclear whether these models actually select referring forms that are any more natural than baseline alternatives, regardless of goodness-of-fit. Through a human subject study designed to assess this question, we show that even though cognitive status-informed referring selection models achieve good fit to human data, they do not (yet) produce concrete benefits in terms of naturality. On the other hand, our results show that human utterances also had high variability in perceived naturality, demonstrating the challenges of evaluating RFS naturality.","authors":["Gabriel Del Castillo","Grace Clark","Zhao Han","Tom Williams"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"115","paper":"static/papers/inlg/115_Paper.pdf","poster":"static/posters/INLG2023/115.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Exploring the Naturalness of Cognitive Status-Informed Referring Form Selection Models"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession4###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#inlgoralsession4","name":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","room":"Sun II","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Exploring the Naturalness of Cognitive Status-Informed Referring Form Selection Models"},{"UID":"inlg15","abstract":"While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model's performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.","authors":["Mina Almasi","Anton Schi\u00f8nning"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"15","paper":"static/papers/inlg/15_Paper.pdf","poster":"static/posters/INLG2023/15.pdf","session":"inlgoralsession3","sessions":[{"UID":"inlgoralsession3","calendarId":"inlgoral","category":"time","chair":"Tom Williams","contents":[{"UID":"inlg15","abstract":"While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model's performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.","authors":["Mina Almasi","Anton Schi\u00f8nning"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"15","paper":"static/papers/inlg/15_Paper.pdf","poster":"static/posters/INLG2023/15.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Fine-Tuning GPT-3 for Synthetic Danish News Generation"},{"UID":"inlg56","abstract":"Large Language Models, and ChatGPT in particular, have recently grabbed the attention of the community and the media. Having reached high language proficiency, attention has been shifting toward its reasoning capabilities. In this paper, our main aim is to evaluate ChatGPT's question generation in a task where language production should be driven by an implicit reasoning process. To this end, we employ the 20-Questions game, traditionally used within the Cognitive Science community to inspect the information seeking-strategy's development.  This task requires a series of interconnected skills: asking informative questions, stepwise updating the hypothesis space, and stopping asking questions when enough information has been collected. We build hierarchical hypothesis spaces, exploiting feature norms collected from humans vs. ChatGPT itself, and we inspect the efficiency and informativeness of ChatGPT's strategy. Our results show that ChatGPT's performance gets closer to an optimal agent only when prompted to explicitly list the updated space stepwise.","authors":["Leonardo Bertolazzi","Davide Mazzaccara","Filippo Merlo","Raffaella Bernardi"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"56","paper":"static/papers/inlg/56_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"ChatGPT's Information Seeking Strategy: Insights From the 20-Questions Game"},{"UID":"inlg99","abstract":"In this paper, we present a system for augmenting virtual AI characters with long-term memory, enabling them to remember facts about themselves, their world, and past experiences. We propose a memory-creation pipeline that converts raw text into condensed memories and a memory-retrieval system that utilizes these memories to generate character responses. Using a fact-checking pipeline based on GPT-4, our evaluation demonstrates that the character responses are grounded in the retrieved memories and maintain factual accuracy. We discuss the implications of our system for creating engaging and consistent virtual characters and highlight areas for future research, including large language model (LLM) guardrailing and virtual character personality development.","authors":["Fabian Landwehr","Erika Varis Doggett","Romann M. Weber"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"99","paper":"static/papers/inlg/99_Paper.pdf","poster":"static/posters/INLG2023/99.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Memories for Virtual AI Characters"},{"UID":"inlg107","abstract":"In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behavior of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.","authors":["Subhadra Vadlamannati","G\u00f6zde \u015eahin"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"107","paper":"static/papers/inlg/107_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Metric-Based in-Context Learning: A Case Study in Text Simplification"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#inlgoralsession3","name":"INLG Oral Session 3: Leveraging Large Language Models for NLG","room":"Sun II","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"INLG Oral Session 3: Leveraging Large Language Models for NLG","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Fine-Tuning GPT-3 for Synthetic Danish News Generation"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg16","abstract":"In this work, we investigate Data Augmentation methods to improve the performance of state-of-the-art models for four different downstream tasks. Specifically, we propose Generative Adversarial Network using Language Models (GAN-LM) approach that combines a deep generative model with a pre-trained language model to produce diverse augmentations. We compare the GAN-LM to various conventional methods in non-contextual- and contextual-levels on four public datasets: ZESHEL for zero-shot entity linking, TREC for question classification, STS-B for sentence pairs semantic textual similarity (STS), and mSTS for multilingual sentence pairs STS. Additionally, we subsample these datasets to study the impact of such augmentations in low-resource settings where limited amounts of training data is available. Compared to the state-of-the-art methods in downstream tasks, we mostly achieve the best performance using GAN-LM approach. Finally, we investigate the way of combining the GAN-LM with other augmentation methods to complement our proposed approach. The developed code for reproducibility is included in the supplementary material.","authors":["Dae Yon Hwang","Yaroslav Nechaev","Cyprien de Lichy","Renxian Zhang"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"16","paper":"static/papers/inlg/16_Paper.pdf","poster":"static/posters/INLG2023/16.pdf","session":"inlgoralsession5","sessions":[{"UID":"inlgoralsession5","calendarId":"inlgoral","category":"time","chair":"Dimitra Gkatzia","contents":[{"UID":"inlg16","abstract":"In this work, we investigate Data Augmentation methods to improve the performance of state-of-the-art models for four different downstream tasks. Specifically, we propose Generative Adversarial Network using Language Models (GAN-LM) approach that combines a deep generative model with a pre-trained language model to produce diverse augmentations. We compare the GAN-LM to various conventional methods in non-contextual- and contextual-levels on four public datasets: ZESHEL for zero-shot entity linking, TREC for question classification, STS-B for sentence pairs semantic textual similarity (STS), and mSTS for multilingual sentence pairs STS. Additionally, we subsample these datasets to study the impact of such augmentations in low-resource settings where limited amounts of training data is available. Compared to the state-of-the-art methods in downstream tasks, we mostly achieve the best performance using GAN-LM approach. Finally, we investigate the way of combining the GAN-LM with other augmentation methods to complement our proposed approach. The developed code for reproducibility is included in the supplementary material.","authors":["Dae Yon Hwang","Yaroslav Nechaev","Cyprien de Lichy","Renxian Zhang"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"16","paper":"static/papers/inlg/16_Paper.pdf","poster":"static/posters/INLG2023/16.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"GAN-LM: Generative Adversarial Network Using Language Models for Downstream Applications"},{"UID":"inlg24","abstract":"Good figure captions help paper readers understand complex scientific figures. Unfortunately, even published papers often have poorly written captions. Automatic caption generation could aid paper writers by providing good starting captions that can be refined for better quality. Prior work often treated figure caption generation as a vision-to-language task. In this paper, we show that it can be more effectively tackled as a text summarization task in scientific documents. We fine-tuned PEGASUS, a pre-trained abstractive summarization model, to specifically summarize figure-referencing paragraphs (e.g., \"Figure 3 shows...\") into figure captions. Experiments on large-scale arXiv figures show that our method outperforms prior vision methods in both automatic and human evaluations. We further conducted an in-depth investigation focused on two key challenges: (i) the common presence of low-quality author-written captions and (ii) the lack of clear standards for good captions. Our code and data are available at: https://github.com/Crowd-AI-Lab/Generating-Figure-Captions-as-a-Text-Summarization-Task.","authors":["Chieh-Yang Huang","Ting-Yao Hsu","Ryan Rossi","Ani Nenkova","Sungchul Kim","Gromit Yeuk-Yin Chan","Eunyee Koh","C Lee Giles","Ting-Hao Huang"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"24","paper":"static/papers/inlg/24_Paper.pdf","poster":"static/posters/INLG2023/24.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Summaries as Captions: Generating Figure Captions for Scientific Documents With Automated Text Summarization"},{"UID":"inlg47","abstract":"An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often specifies claims with details, whereas it adds less evidence than humans do. Moreover, its capabilities generalize well to other domains, such as instructional texts.","authors":["Gabriella Skitalinskaya","Maximilian Splieth\u00f6ver","Henning Wachsmuth"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"47","paper":"static/papers/inlg/47_Paper.pdf","poster":"static/posters/INLG2023/47.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Claim Optimization in Computational Argumentation"},{"UID":"inlg71","abstract":"Prior art investigating task-oriented dialog and automatic generation of such dialogs have focused on single-user dialogs between a single user and an agent. However, there is limited study on adapting such AI agents to multi-user conversations (involving multiple users and an agent). Multi-user conversations are richer than single-user conversations containing social banter and collaborative decision making. The most significant challenge impeding such studies is the lack of suitable multi-user task-oriented dialogs with annotations of user belief states and system actions. One potential solution is multi-user dialog generation from single-user data. Many single-user dialogs datasets already contain dialog state information (intents, slots), thus making them suitable candidates. In this work, we propose a novel approach for expanding single-user task-oriented dialogs (e.g. MultiWOZ) to multi-user dialogs in a zero-shot setting.","authors":["Shiv Surya","Yohan Jo","Arijit Biswas","Alexandros Potamianos"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"71","paper":"static/papers/inlg/71_Paper.pdf","poster":"","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"A Zero-Shot Approach for Multi-User Task-Oriented Dialog Generation"}],"day":"Friday","discord":"https://discord.com/channels/###inlgoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#inlgoralsession5","name":"INLG Oral Session 5: NLG for real-world applications","room":"Sun II","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"INLG Oral Session 5: NLG for real-world applications","zoom":"https://zoom.us/j/###Sun II###"}],"title":"GAN-LM: Generative Adversarial Network Using Language Models for Downstream Applications"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg34","abstract":"Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.","authors":["Tahsina Hashem","Weiqing Wang","Derry Tanti Wijaya","Mohammed Eunus Ali","Yuan-Fang Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"34","paper":"static/papers/inlg/34_Paper.pdf","poster":"static/posters/INLG2023/34.pdf","session":"inlgoralsession1","sessions":[{"UID":"inlgoralsession1","calendarId":"inlgoral","category":"time","chair":"Ching-Chi-Chen","contents":[{"UID":"inlg12","abstract":"Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data and aids in the development of countermeasures. Many prior works---and some recently deployed defenses---focus on ``verbatim memorization'', defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense that _perfectly_ prevents all verbatim memorization.  And yet, we demonstrate that this ``perfect'' filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified ``style-transfer'' prompts---and in some cases even the non-modified original prompts---to extract memorized information. We conclude by discussing potential alternative definitions and why defining memorization is a difficult yet crucial open question for neural language models.","authors":["Daphne Ippolito","Florian Tramer","Milad Nasr","Chiyuan Zhang","Matthew Jagielski","Katherine Lee","Christopher Choquette Choo","Nicholas Carlini"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"12","paper":"static/papers/inlg/12_Paper.pdf","poster":"static/posters/INLG2023/12.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Preventing Generation of Verbatim Memorization in Language Models Gives a False Sense of Privacy"},{"UID":"inlg34","abstract":"Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.","authors":["Tahsina Hashem","Weiqing Wang","Derry Tanti Wijaya","Mohammed Eunus Ali","Yuan-Fang Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"34","paper":"static/papers/inlg/34_Paper.pdf","poster":"static/posters/INLG2023/34.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Generating Faithful Text From a Knowledge Graph With Noisy Reference Text"},{"UID":"inlg58","abstract":"Automatically summarizing radiology reports into a concise impression can reduce the manual burden of clinicians and improve the consistency of reporting. Previous work aimed to enhance content selection and factuality through guided abstractive summarization. However, two key issues persist. First, current methods heavily rely on domain-specific resources to extract the guidance signal, limiting their transferability to domains and languages where those resources are unavailable. Second, while automatic metrics like ROUGE show progress, we lack a good understanding of the errors and failure modes in this task. To bridge these gaps, we first propose a domain-agnostic guidance signal in form of variable-length extractive summaries. Our empirical results on two English benchmarks demonstrate that this guidance signal improves upon unguided summarization while being competitive with domain-specific methods. Additionally, we run an expert evaluation of four systems according to a taxonomy of 11 fine-grained errors. We find that the most pressing differences between automatic summaries and those of radiologists relate to content selection including omissions (up to 52%) and additions (up to 57%). We hypothesize that latent reporting factors and corpus-level inconsistencies may limit models to reliably learn content selection from the available data, presenting promising directions for future work.","authors":["Jan Trienes","Paul Youssef","J\u00f6rg Schl\u00f6tterer","Christin Seifert"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"58","paper":"static/papers/inlg/58_Paper.pdf","poster":"static/posters/INLG2023/58.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Guidance in Radiology Report Summarization: An Empirical Evaluation and Error Analysis"},{"UID":"inlg97","abstract":"Neural data-to-text systems lack the control and factual accuracy required to generate useful and insightful summaries of multidimensional data. We propose a solution in the form of data views, where each view describes an entity and its attributes along specific dimensions. A sequence of views can then be used as a high-level schema for document planning, with the neural model handling the complexities of micro-planning and surface realization. We show that our view-based system retains factual accuracy while offering high-level control of output that can be tailored based on user preference or other norms within the domain.","authors":["Craig Thomson","Clement Rebuffel","Ehud Reiter","Laure Soulier","Somayajulu Sripada","patrick Gallinari"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"97","paper":"static/papers/inlg/97_Paper.pdf","poster":"static/posters/INLG2023/97.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Enhancing Factualness and Controllability of Data-to-Text Generation via Data Views and Constraints"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#inlgoralsession1","name":"INLG Oral Session 1: Trustworthiness of NLG systems","room":"Sun II","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"INLG Oral Session 1: Trustworthiness of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Generating Faithful Text From a Knowledge Graph With Noisy Reference Text"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"sigdial80","abstract":"Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86&#92;% of the evaluated tasks were improved from a conversational suitability point of view.","authors":["Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"80","paper":"static/papers/sigdial/80_Paper.pdf","poster":"static/posters/SIGDIAL2023/80.pdf","session":"sigdialoralsession1","sessions":[{"UID":"sigdialoralsession1","calendarId":"sigdialoral","category":"time","chair":"Gabriel Skantze","contents":[{"UID":"sigdial86","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs.  Despite their prevalence, there currently lacks an accurate survey of dialogue noise,  nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise.  Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise.  Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","authors":["Derek Chen","Zhou Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"86","paper":"static/papers/sigdial/86_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Sources of Noise in Dialogue and How to Deal With Them"},{"UID":"sigdial14","abstract":"Discourse relations have different patterns of marking across different languages.  As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment.  The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.","authors":["Frances Yung","Merel Scholman","Ekaterina Lapshinova-Koltunski","Christina Pollkl\u00e4sener","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"14","paper":"static/papers/sigdial/14_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:05:00+02:00","title":"Investigating Explicitation of Discourse Connectives in Translation Using Automatic Annotations"},{"UID":"sigdial43","abstract":"Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.","authors":["Yang Janet Liu","Tatsuya Aoyama","Amir Zeldes"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"43","paper":"static/papers/sigdial/43_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:25:00+02:00","title":"What's Hard in English RST Parsing? Predictive Models for Error Analysis"},{"UID":"sigdial80","abstract":"Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86&#92;% of the evaluated tasks were improved from a conversational suitability point of view.","authors":["Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"80","paper":"static/papers/sigdial/80_Paper.pdf","poster":"static/posters/SIGDIAL2023/80.pdf","session":"sigdialoralsession1","start":"2023-09-13T11:45:00+02:00","title":"Grounded Complex Task Segmentation for Conversational Assistants"},{"UID":"sigdial91","abstract":"Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners' topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.","authors":["Grace Lawley","Peter A. Heeman","Jill K. Dolata","Eric Fombonne","Steven Bedrick"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"91","paper":"static/papers/sigdial/91_Paper.pdf","poster":"static/posters/SIGDIAL2023/91.pdf","session":"sigdialoralsession1","start":"2023-09-13T12:05:00+02:00","title":"A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#sigdialoralsession1","name":"Sigdial Oral Session 1: Analysis of discourse and dialogue","room":"Sun I","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"Sigdial Oral Session 1: Analysis of discourse and dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Grounded Complex Task Segmentation for Conversational Assistants"},{"UID":"sigdial34","abstract":"Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control.  We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.","authors":["Alexandru Coca","Bo-Hsiang Tseng","Jinghong Chen","Weizhe Lin","Weixuan Zhang","Tisha Anders","Bill Byrne"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"1","original_id":"34","paper":"static/papers/sigdial/34_Paper.pdf","poster":"","session":"sigdialoralsession4","sessions":[{"UID":"sigdialoralsession4","calendarId":"sigdialoral","category":"time","chair":"Tatsuya Kawahara","contents":[{"UID":"sigdial49","abstract":"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept.  In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation.  The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.","authors":["Qi Cheng","Mert Inan","Rahma Mbarki","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"49","paper":"static/papers/sigdial/49_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:10:00+02:00","title":"Learning Multimodal Cues of Children's Uncertainty"},{"UID":"sigdial34","abstract":"Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control.  We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.","authors":["Alexandru Coca","Bo-Hsiang Tseng","Jinghong Chen","Weizhe Lin","Weixuan Zhang","Tisha Anders","Bill Byrne"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"1","original_id":"34","paper":"static/papers/sigdial/34_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:30:00+02:00","title":"Grounding Description-Driven Dialogue State Trackers With Knowledge-Seeking Turns"},{"UID":"sigdial122","abstract":"Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.","authors":["Bram Willemsen","Livia Qian","Gabriel Skantze"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"122","paper":"static/papers/sigdial/122_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:50:00+02:00","title":"Resolving References in Visually-Grounded Dialogue via Text Generation"},{"UID":"sigdial5","abstract":"Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.","authors":["Hoang Nguyen","Chenwei Zhang","Ye Liu","Philip Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"3","original_id":"5","paper":"static/papers/sigdial/5_Paper.pdf","poster":"static/posters/SIGDIAL2023/5.pdf","session":"sigdialoralsession4","start":"2023-09-14T17:10:00+02:00","title":"Slot Induction via Pre-Trained Language Model Probing and Multi-Level Contrastive Learning"},{"UID":"sigdial19","abstract":"Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.","authors":["Andreas Liesenfeld","Alianda Lopez","Mark Dingemanse"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"4","original_id":"19","paper":"static/papers/sigdial/19_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T17:30:00+02:00","title":"The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession4###","end":"2023-09-14T17:50:00+02:00","end_time":"Thu, 14 Sep 2023 15:50:00 GMT","location":"#sigdialoralsession4","name":"Sigdial Oral Session 4: Language understanding and multimodality","room":"Sun I","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"Sigdial Oral Session 4: Language understanding and multimodality","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Grounding Description-Driven Dialogue State Trackers With Knowledge-Seeking Turns"},{"UID":"inlg58","abstract":"Automatically summarizing radiology reports into a concise impression can reduce the manual burden of clinicians and improve the consistency of reporting. Previous work aimed to enhance content selection and factuality through guided abstractive summarization. However, two key issues persist. First, current methods heavily rely on domain-specific resources to extract the guidance signal, limiting their transferability to domains and languages where those resources are unavailable. Second, while automatic metrics like ROUGE show progress, we lack a good understanding of the errors and failure modes in this task. To bridge these gaps, we first propose a domain-agnostic guidance signal in form of variable-length extractive summaries. Our empirical results on two English benchmarks demonstrate that this guidance signal improves upon unguided summarization while being competitive with domain-specific methods. Additionally, we run an expert evaluation of four systems according to a taxonomy of 11 fine-grained errors. We find that the most pressing differences between automatic summaries and those of radiologists relate to content selection including omissions (up to 52%) and additions (up to 57%). We hypothesize that latent reporting factors and corpus-level inconsistencies may limit models to reliably learn content selection from the available data, presenting promising directions for future work.","authors":["Jan Trienes","Paul Youssef","J\u00f6rg Schl\u00f6tterer","Christin Seifert"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"58","paper":"static/papers/inlg/58_Paper.pdf","poster":"static/posters/INLG2023/58.pdf","session":"inlgoralsession1","sessions":[{"UID":"inlgoralsession1","calendarId":"inlgoral","category":"time","chair":"Ching-Chi-Chen","contents":[{"UID":"inlg12","abstract":"Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data and aids in the development of countermeasures. Many prior works---and some recently deployed defenses---focus on ``verbatim memorization'', defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense that _perfectly_ prevents all verbatim memorization.  And yet, we demonstrate that this ``perfect'' filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified ``style-transfer'' prompts---and in some cases even the non-modified original prompts---to extract memorized information. We conclude by discussing potential alternative definitions and why defining memorization is a difficult yet crucial open question for neural language models.","authors":["Daphne Ippolito","Florian Tramer","Milad Nasr","Chiyuan Zhang","Matthew Jagielski","Katherine Lee","Christopher Choquette Choo","Nicholas Carlini"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"12","paper":"static/papers/inlg/12_Paper.pdf","poster":"static/posters/INLG2023/12.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Preventing Generation of Verbatim Memorization in Language Models Gives a False Sense of Privacy"},{"UID":"inlg34","abstract":"Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.","authors":["Tahsina Hashem","Weiqing Wang","Derry Tanti Wijaya","Mohammed Eunus Ali","Yuan-Fang Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"34","paper":"static/papers/inlg/34_Paper.pdf","poster":"static/posters/INLG2023/34.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Generating Faithful Text From a Knowledge Graph With Noisy Reference Text"},{"UID":"inlg58","abstract":"Automatically summarizing radiology reports into a concise impression can reduce the manual burden of clinicians and improve the consistency of reporting. Previous work aimed to enhance content selection and factuality through guided abstractive summarization. However, two key issues persist. First, current methods heavily rely on domain-specific resources to extract the guidance signal, limiting their transferability to domains and languages where those resources are unavailable. Second, while automatic metrics like ROUGE show progress, we lack a good understanding of the errors and failure modes in this task. To bridge these gaps, we first propose a domain-agnostic guidance signal in form of variable-length extractive summaries. Our empirical results on two English benchmarks demonstrate that this guidance signal improves upon unguided summarization while being competitive with domain-specific methods. Additionally, we run an expert evaluation of four systems according to a taxonomy of 11 fine-grained errors. We find that the most pressing differences between automatic summaries and those of radiologists relate to content selection including omissions (up to 52%) and additions (up to 57%). We hypothesize that latent reporting factors and corpus-level inconsistencies may limit models to reliably learn content selection from the available data, presenting promising directions for future work.","authors":["Jan Trienes","Paul Youssef","J\u00f6rg Schl\u00f6tterer","Christin Seifert"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"58","paper":"static/papers/inlg/58_Paper.pdf","poster":"static/posters/INLG2023/58.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Guidance in Radiology Report Summarization: An Empirical Evaluation and Error Analysis"},{"UID":"inlg97","abstract":"Neural data-to-text systems lack the control and factual accuracy required to generate useful and insightful summaries of multidimensional data. We propose a solution in the form of data views, where each view describes an entity and its attributes along specific dimensions. A sequence of views can then be used as a high-level schema for document planning, with the neural model handling the complexities of micro-planning and surface realization. We show that our view-based system retains factual accuracy while offering high-level control of output that can be tailored based on user preference or other norms within the domain.","authors":["Craig Thomson","Clement Rebuffel","Ehud Reiter","Laure Soulier","Somayajulu Sripada","patrick Gallinari"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"97","paper":"static/papers/inlg/97_Paper.pdf","poster":"static/posters/INLG2023/97.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Enhancing Factualness and Controllability of Data-to-Text Generation via Data Views and Constraints"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#inlgoralsession1","name":"INLG Oral Session 1: Trustworthiness of NLG systems","room":"Sun II","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"INLG Oral Session 1: Trustworthiness of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Guidance in Radiology Report Summarization: An Empirical Evaluation and Error Analysis"},{"UID":"inlg9","abstract":"In this paper, we introduce a new beam search algorithm that improves the generalization of neural generators to unseen examples, especially in low-resource data-to-text settings. Our algorithm aims to reduce the number of omissions and hallucinations during the decoding process. For this purpose, it relies on two regression models to explicitly characterize factual errors. We explain how to create a new dataset to train these models given an original training set of less than a thousand data points. We apply our approach in the low-resource, legal setting using the French Plum2Text dataset, as well as in English using WebNLG. We observe in our experiment that this combination improves the faithfulness of pre-trained neural text generators using both human and automatic evaluation. Moreover, our approach offers a level of interpretability by predicting the number of omissions and hallucinations present in a given generation with respect to the input data. Finally, we visualize our algorithm's exploration of the hypothesis space at different steps during the decoding process.","authors":["Nicolas Garneau","Luc Lamontagne"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"9","paper":"static/papers/inlg/9_Paper.pdf","poster":"static/posters/INLG2023/9.pdf","session":"inlgoralsession2","sessions":[{"UID":"inlgoralsession2","calendarId":"inlgoral","category":"time","chair":"Gozde Gul Sahin","contents":[{"UID":"inlg9","abstract":"In this paper, we introduce a new beam search algorithm that improves the generalization of neural generators to unseen examples, especially in low-resource data-to-text settings. Our algorithm aims to reduce the number of omissions and hallucinations during the decoding process. For this purpose, it relies on two regression models to explicitly characterize factual errors. We explain how to create a new dataset to train these models given an original training set of less than a thousand data points. We apply our approach in the low-resource, legal setting using the French Plum2Text dataset, as well as in English using WebNLG. We observe in our experiment that this combination improves the faithfulness of pre-trained neural text generators using both human and automatic evaluation. Moreover, our approach offers a level of interpretability by predicting the number of omissions and hallucinations present in a given generation with respect to the input data. Finally, we visualize our algorithm's exploration of the hypothesis space at different steps during the decoding process.","authors":["Nicolas Garneau","Luc Lamontagne"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"9","paper":"static/papers/inlg/9_Paper.pdf","poster":"static/posters/INLG2023/9.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation"},{"UID":"inlg10","abstract":"Multiple business scenarios require an automated generation of descriptive human-readable text from structured input data. This has resulted into substantial work on fact-to-text generation systems recently. Unfortunately, previous work on fact-to-text (F2T) generation has focused primarily on English mainly due to the high availability of relevant datasets. Only recently, the problem of cross-lingual fact-to-text (XF2T) was proposed for generation across multiple languages alongwith a dataset, XAlign for eight languages. However, there has been no rigorous work on the actual XF2T generation problem. We extend XAlign dataset with annotated data for four more languages: Punjabi, Malayalam, Assamese and Oriya. We conduct an extensive study using popular Transformer-based text generation models on our extended multi-lingual dataset, which we call XAlignV2. Further, we investigate the performance of different text generation strategies: multiple variations of pretraining, fact-aware embeddings and structure-aware input encoding. Our extensive experiments show that a multi-lingual mT5 model which uses fact-aware embeddings with structure-aware input encoding leads to best results (30.90 BLEU, 55.12 METEOR and 59.17 chrF++) across the twelve languages. We make our code, dataset and model publicly available, and hope that this will help advance further research in this critical area.","authors":["Shivprasad Sagare","Tushar Abhishek","Bhavyajeet Singh","Anubhav Sharma","Manish Gupta","Vasudeva Varma"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"10","paper":"static/papers/inlg/10_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"XF2T: Cross-Lingual Fact-to-Text Generation for Low-Resource Languages"},{"UID":"inlg44","abstract":"Research in Multi-document Summarization (MDS) mostly focuses on the English language and depends on large MDS datasets that are not available for other languages. Some of these approaches concatenate the source documents, resulting in overlong model inputs. Existing transformer architectures are unable to process such long inputs entirely, omitting documents in the summarization process. Other solutions address this issue by implementing multi-stage approaches that also require changes in the model architecture. In this paper, we introduce various sampling approaches based on information entropy that allow us to perform MDS in a single stage. These approaches also consider all source documents without using MDS training data nor changing the model's architecture. Besides, we build a MDS test set of German news articles to assess the performance of our methods on abstractive multi-document summaries. Experimental results show that our entropy-based approaches outperform previous state-of-the-art on German MDS, while still remaining primarily abstractive. We release our code and MDS test set to encourage further research in German abstractive MDS.","authors":["Laura Mascarell","Ribin Chalumattu","Julien Heitmann"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"44","paper":"static/papers/inlg/44_Paper.pdf","poster":"static/posters/INLG2023/44.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Entropy-Based Sampling for Abstractive Multi-Document Summarization in Low-Resource Settings"},{"UID":"inlg80","abstract":"Text style transfer (TST) involves transforming a text into a desired style while approximately preserving its content. The biggest challenge in TST in the general lack of parallel data. Many existing approaches rely on complex models using substantial non-parallel data, with mixed results. In this paper, we leverage a pretrained BART language model with minimal parallel data and incorporate low-resource methods such as hyperparameter tuning, data augmentation, and self-training, which have not been explored in TST. We further include novel style-based rewards in the training loss. Through extensive experiments in sentiment transfer, a sub-task of TST, we demonstrate that our simple yet effective approaches achieve well-balanced results, surpassing non-parallel approaches and highlighting the usefulness of parallel data even in small amounts.","authors":["Sourabrata Mukherjee","Ondrej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"80","paper":"static/papers/inlg/80_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Leveraging Low-Resource Parallel Data for Text Style Transfer"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession2###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#inlgoralsession2","name":"INLG Oral Session 2: NLG for low-resourced settings","room":"Sun II","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"INLG Oral Session 2: NLG for low-resourced settings","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial14","abstract":"Discourse relations have different patterns of marking across different languages.  As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment.  The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.","authors":["Frances Yung","Merel Scholman","Ekaterina Lapshinova-Koltunski","Christina Pollkl\u00e4sener","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"14","paper":"static/papers/sigdial/14_Paper.pdf","poster":"","session":"sigdialoralsession1","sessions":[{"UID":"sigdialoralsession1","calendarId":"sigdialoral","category":"time","chair":"Gabriel Skantze","contents":[{"UID":"sigdial86","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs.  Despite their prevalence, there currently lacks an accurate survey of dialogue noise,  nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise.  Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise.  Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","authors":["Derek Chen","Zhou Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"86","paper":"static/papers/sigdial/86_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Sources of Noise in Dialogue and How to Deal With Them"},{"UID":"sigdial14","abstract":"Discourse relations have different patterns of marking across different languages.  As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment.  The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.","authors":["Frances Yung","Merel Scholman","Ekaterina Lapshinova-Koltunski","Christina Pollkl\u00e4sener","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"14","paper":"static/papers/sigdial/14_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:05:00+02:00","title":"Investigating Explicitation of Discourse Connectives in Translation Using Automatic Annotations"},{"UID":"sigdial43","abstract":"Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.","authors":["Yang Janet Liu","Tatsuya Aoyama","Amir Zeldes"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"43","paper":"static/papers/sigdial/43_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:25:00+02:00","title":"What's Hard in English RST Parsing? Predictive Models for Error Analysis"},{"UID":"sigdial80","abstract":"Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86&#92;% of the evaluated tasks were improved from a conversational suitability point of view.","authors":["Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"80","paper":"static/papers/sigdial/80_Paper.pdf","poster":"static/posters/SIGDIAL2023/80.pdf","session":"sigdialoralsession1","start":"2023-09-13T11:45:00+02:00","title":"Grounded Complex Task Segmentation for Conversational Assistants"},{"UID":"sigdial91","abstract":"Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners' topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.","authors":["Grace Lawley","Peter A. Heeman","Jill K. Dolata","Eric Fombonne","Steven Bedrick"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"91","paper":"static/papers/sigdial/91_Paper.pdf","poster":"static/posters/SIGDIAL2023/91.pdf","session":"sigdialoralsession1","start":"2023-09-13T12:05:00+02:00","title":"A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#sigdialoralsession1","name":"Sigdial Oral Session 1: Analysis of discourse and dialogue","room":"Sun I","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"Sigdial Oral Session 1: Analysis of discourse and dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Investigating Explicitation of Discourse Connectives in Translation Using Automatic Annotations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"sigdial49","abstract":"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept.  In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation.  The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.","authors":["Qi Cheng","Mert Inan","Rahma Mbarki","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"49","paper":"static/papers/sigdial/49_Paper.pdf","poster":"","session":"sigdialoralsession4","sessions":[{"UID":"sigdialoralsession4","calendarId":"sigdialoral","category":"time","chair":"Tatsuya Kawahara","contents":[{"UID":"sigdial49","abstract":"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept.  In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation.  The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.","authors":["Qi Cheng","Mert Inan","Rahma Mbarki","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"49","paper":"static/papers/sigdial/49_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:10:00+02:00","title":"Learning Multimodal Cues of Children's Uncertainty"},{"UID":"sigdial34","abstract":"Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control.  We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.","authors":["Alexandru Coca","Bo-Hsiang Tseng","Jinghong Chen","Weizhe Lin","Weixuan Zhang","Tisha Anders","Bill Byrne"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"1","original_id":"34","paper":"static/papers/sigdial/34_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:30:00+02:00","title":"Grounding Description-Driven Dialogue State Trackers With Knowledge-Seeking Turns"},{"UID":"sigdial122","abstract":"Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.","authors":["Bram Willemsen","Livia Qian","Gabriel Skantze"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"122","paper":"static/papers/sigdial/122_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:50:00+02:00","title":"Resolving References in Visually-Grounded Dialogue via Text Generation"},{"UID":"sigdial5","abstract":"Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.","authors":["Hoang Nguyen","Chenwei Zhang","Ye Liu","Philip Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"3","original_id":"5","paper":"static/papers/sigdial/5_Paper.pdf","poster":"static/posters/SIGDIAL2023/5.pdf","session":"sigdialoralsession4","start":"2023-09-14T17:10:00+02:00","title":"Slot Induction via Pre-Trained Language Model Probing and Multi-Level Contrastive Learning"},{"UID":"sigdial19","abstract":"Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.","authors":["Andreas Liesenfeld","Alianda Lopez","Mark Dingemanse"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"4","original_id":"19","paper":"static/papers/sigdial/19_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T17:30:00+02:00","title":"The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession4###","end":"2023-09-14T17:50:00+02:00","end_time":"Thu, 14 Sep 2023 15:50:00 GMT","location":"#sigdialoralsession4","name":"Sigdial Oral Session 4: Language understanding and multimodality","room":"Sun I","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"Sigdial Oral Session 4: Language understanding and multimodality","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Learning Multimodal Cues of Children's Uncertainty"},{"UID":"sigdial106","abstract":"Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses.  However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.","authors":["Sarah E. Finch","Ellie S. Paek","Jinho D. Choi"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"106","paper":"static/papers/sigdial/106_Paper.pdf","poster":"static/posters/SIGDIAL2023/106.pdf","session":"sigdialoralsession2","sessions":[{"UID":"sigdialoralsession2","calendarId":"sigdialoral","category":"time","chair":"Dilek Hakkani-Tur","contents":[{"UID":"sigdial106","abstract":"Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses.  However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.","authors":["Sarah E. Finch","Ellie S. Paek","Jinho D. Choi"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"106","paper":"static/papers/sigdial/106_Paper.pdf","poster":"static/posters/SIGDIAL2023/106.pdf","session":"sigdialoralsession2","start":"2023-09-13T15:40:00+02:00","title":"Leveraging Large Language Models for Automated Dialogue Analysis"},{"UID":"sigdial25","abstract":"Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples.","authors":["Vojt\u011bch Hude\u010dek","Ondrej Du\u0161ek"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"25","paper":"static/papers/sigdial/25_Paper.pdf","poster":"static/posters/SIGDIAL2023/25.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:00:00+02:00","title":"Are Large Language Models All You Need for Task-Oriented Dialogue?"},{"UID":"sigdial109","abstract":"This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The 'reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A 'story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.","authors":["Angus Addlesee","Weronika Siei\u0144ska","Nancie Gunson","Daniel Hernandez Garcia","Christian Dondrup","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"109","paper":"static/papers/sigdial/109_Paper.pdf","poster":"static/posters/SIGDIAL2023/109.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:20:00+02:00","title":"Multi-Party Goal Tracking With LLMs: Comparing Pre-Training, Fine-Tuning, and Prompt Engineering"},{"UID":"sigdial156","abstract":"This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.","authors":["Lidiia Ostyakova","Veronika Smilga","Kseniia Petukhova","Maria Molchanova","Daniel Kornev"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"156","paper":"static/papers/sigdial/156_Paper.pdf","poster":"static/posters/SIGDIAL2023/156.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:40:00+02:00","title":"ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations With Speech Functions"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession2###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#sigdialoralsession2","name":"Sigdial Oral Session 2: LLM for dialogue","room":"Sun I","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"Sigdial Oral Session 2: LLM for dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Leveraging Large Language Models for Automated Dialogue Analysis"},{"UID":"inlg80","abstract":"Text style transfer (TST) involves transforming a text into a desired style while approximately preserving its content. The biggest challenge in TST in the general lack of parallel data. Many existing approaches rely on complex models using substantial non-parallel data, with mixed results. In this paper, we leverage a pretrained BART language model with minimal parallel data and incorporate low-resource methods such as hyperparameter tuning, data augmentation, and self-training, which have not been explored in TST. We further include novel style-based rewards in the training loss. Through extensive experiments in sentiment transfer, a sub-task of TST, we demonstrate that our simple yet effective approaches achieve well-balanced results, surpassing non-parallel approaches and highlighting the usefulness of parallel data even in small amounts.","authors":["Sourabrata Mukherjee","Ondrej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"80","paper":"static/papers/inlg/80_Paper.pdf","poster":"","session":"inlgoralsession2","sessions":[{"UID":"inlgoralsession2","calendarId":"inlgoral","category":"time","chair":"Gozde Gul Sahin","contents":[{"UID":"inlg9","abstract":"In this paper, we introduce a new beam search algorithm that improves the generalization of neural generators to unseen examples, especially in low-resource data-to-text settings. Our algorithm aims to reduce the number of omissions and hallucinations during the decoding process. For this purpose, it relies on two regression models to explicitly characterize factual errors. We explain how to create a new dataset to train these models given an original training set of less than a thousand data points. We apply our approach in the low-resource, legal setting using the French Plum2Text dataset, as well as in English using WebNLG. We observe in our experiment that this combination improves the faithfulness of pre-trained neural text generators using both human and automatic evaluation. Moreover, our approach offers a level of interpretability by predicting the number of omissions and hallucinations present in a given generation with respect to the input data. Finally, we visualize our algorithm's exploration of the hypothesis space at different steps during the decoding process.","authors":["Nicolas Garneau","Luc Lamontagne"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"9","paper":"static/papers/inlg/9_Paper.pdf","poster":"static/posters/INLG2023/9.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation"},{"UID":"inlg10","abstract":"Multiple business scenarios require an automated generation of descriptive human-readable text from structured input data. This has resulted into substantial work on fact-to-text generation systems recently. Unfortunately, previous work on fact-to-text (F2T) generation has focused primarily on English mainly due to the high availability of relevant datasets. Only recently, the problem of cross-lingual fact-to-text (XF2T) was proposed for generation across multiple languages alongwith a dataset, XAlign for eight languages. However, there has been no rigorous work on the actual XF2T generation problem. We extend XAlign dataset with annotated data for four more languages: Punjabi, Malayalam, Assamese and Oriya. We conduct an extensive study using popular Transformer-based text generation models on our extended multi-lingual dataset, which we call XAlignV2. Further, we investigate the performance of different text generation strategies: multiple variations of pretraining, fact-aware embeddings and structure-aware input encoding. Our extensive experiments show that a multi-lingual mT5 model which uses fact-aware embeddings with structure-aware input encoding leads to best results (30.90 BLEU, 55.12 METEOR and 59.17 chrF++) across the twelve languages. We make our code, dataset and model publicly available, and hope that this will help advance further research in this critical area.","authors":["Shivprasad Sagare","Tushar Abhishek","Bhavyajeet Singh","Anubhav Sharma","Manish Gupta","Vasudeva Varma"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"10","paper":"static/papers/inlg/10_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"XF2T: Cross-Lingual Fact-to-Text Generation for Low-Resource Languages"},{"UID":"inlg44","abstract":"Research in Multi-document Summarization (MDS) mostly focuses on the English language and depends on large MDS datasets that are not available for other languages. Some of these approaches concatenate the source documents, resulting in overlong model inputs. Existing transformer architectures are unable to process such long inputs entirely, omitting documents in the summarization process. Other solutions address this issue by implementing multi-stage approaches that also require changes in the model architecture. In this paper, we introduce various sampling approaches based on information entropy that allow us to perform MDS in a single stage. These approaches also consider all source documents without using MDS training data nor changing the model's architecture. Besides, we build a MDS test set of German news articles to assess the performance of our methods on abstractive multi-document summaries. Experimental results show that our entropy-based approaches outperform previous state-of-the-art on German MDS, while still remaining primarily abstractive. We release our code and MDS test set to encourage further research in German abstractive MDS.","authors":["Laura Mascarell","Ribin Chalumattu","Julien Heitmann"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"44","paper":"static/papers/inlg/44_Paper.pdf","poster":"static/posters/INLG2023/44.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Entropy-Based Sampling for Abstractive Multi-Document Summarization in Low-Resource Settings"},{"UID":"inlg80","abstract":"Text style transfer (TST) involves transforming a text into a desired style while approximately preserving its content. The biggest challenge in TST in the general lack of parallel data. Many existing approaches rely on complex models using substantial non-parallel data, with mixed results. In this paper, we leverage a pretrained BART language model with minimal parallel data and incorporate low-resource methods such as hyperparameter tuning, data augmentation, and self-training, which have not been explored in TST. We further include novel style-based rewards in the training loss. Through extensive experiments in sentiment transfer, a sub-task of TST, we demonstrate that our simple yet effective approaches achieve well-balanced results, surpassing non-parallel approaches and highlighting the usefulness of parallel data even in small amounts.","authors":["Sourabrata Mukherjee","Ondrej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"80","paper":"static/papers/inlg/80_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Leveraging Low-Resource Parallel Data for Text Style Transfer"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession2###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#inlgoralsession2","name":"INLG Oral Session 2: NLG for low-resourced settings","room":"Sun II","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"INLG Oral Session 2: NLG for low-resourced settings","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Leveraging Low-Resource Parallel Data for Text Style Transfer"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Long Story Generation Challenge"},{"UID":"sigdial130","abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models' performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics' unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.","authors":["Sarik Ghazarian","Behnam Hedayatnia","Di Jin","Sijia Liu","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"130","paper":"static/papers/sigdial/130_Paper.pdf","poster":"","session":"sigdialoralsession5","sessions":[{"UID":"sigdialoralsession5","calendarId":"sigdialoral","category":"time","chair":"Mike White","contents":[{"UID":"sigdial29","abstract":"Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These \"self-imposed filter bubbles\" (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand.  <p>To address this issue, we develop a strategy for overcoming users' SFB within the course of the interaction. By continuously modeling the user's position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users' SFBs and promoting a more reflective and comprehensive discussion of the topic.","authors":["Annalena Aicher","Daniel Kornmueller","Yuki Matsuda","Stefan Ultes","Wolfgang Minker","Keiichi Yasumoto"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"29","paper":"static/papers/sigdial/29_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Towards Breaking the Self-Imposed Filter Bubble in Argumentative Dialogues"},{"UID":"sigdial81","abstract":"There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The \"openness\" of the dialogue is expected to be  maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to \"just chat about anything\" results in a very narrow form of dialogue, which we refer to as the \"open-domain paradox\". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.","authors":["Gabriel Skantze","A. Seza Do\u011fru\u00f6z"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"81","paper":"static/papers/sigdial/81_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:50:00+02:00","title":"The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue"},{"UID":"sigdial130","abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models' performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics' unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.","authors":["Sarik Ghazarian","Behnam Hedayatnia","Di Jin","Sijia Liu","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"130","paper":"static/papers/sigdial/130_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:10:00+02:00","title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems"},{"UID":"sigdial27","abstract":"AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains \u22481.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.","authors":["Anuradha Welivita","Chun-Hung Yeh","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"27","paper":"static/papers/sigdial/27_Paper.pdf","poster":"static/posters/SIGDIAL2023/27.pdf","session":"sigdialoralsession5","start":"2023-09-15T12:30:00+02:00","title":"Empathetic Response Generation for Distress Support"},{"UID":"sigdial73","abstract":"Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.","authors":["Yahui Fu","Koji Inoue","Chenhui Chu","Tatsuya Kawahara"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"73","paper":"static/papers/sigdial/73_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:50:00+02:00","title":"Reasoning Before Responding: Integrating Commonsense-Based Causality Explanation for Empathetic Response Generation"}],"day":"Friday","discord":"https://discord.com/channels/###sigdialoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#sigdialoralsession5","name":"Sigdial Oral Session 5: Topics in open-domain dialogue","room":"Sun I","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"Sigdial Oral Session 5: Topics in open-domain dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems"},{"UID":"inlg99","abstract":"In this paper, we present a system for augmenting virtual AI characters with long-term memory, enabling them to remember facts about themselves, their world, and past experiences. We propose a memory-creation pipeline that converts raw text into condensed memories and a memory-retrieval system that utilizes these memories to generate character responses. Using a fact-checking pipeline based on GPT-4, our evaluation demonstrates that the character responses are grounded in the retrieved memories and maintain factual accuracy. We discuss the implications of our system for creating engaging and consistent virtual characters and highlight areas for future research, including large language model (LLM) guardrailing and virtual character personality development.","authors":["Fabian Landwehr","Erika Varis Doggett","Romann M. Weber"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"99","paper":"static/papers/inlg/99_Paper.pdf","poster":"static/posters/INLG2023/99.pdf","session":"inlgoralsession3","sessions":[{"UID":"inlgoralsession3","calendarId":"inlgoral","category":"time","chair":"Tom Williams","contents":[{"UID":"inlg15","abstract":"While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model's performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.","authors":["Mina Almasi","Anton Schi\u00f8nning"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"15","paper":"static/papers/inlg/15_Paper.pdf","poster":"static/posters/INLG2023/15.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Fine-Tuning GPT-3 for Synthetic Danish News Generation"},{"UID":"inlg56","abstract":"Large Language Models, and ChatGPT in particular, have recently grabbed the attention of the community and the media. Having reached high language proficiency, attention has been shifting toward its reasoning capabilities. In this paper, our main aim is to evaluate ChatGPT's question generation in a task where language production should be driven by an implicit reasoning process. To this end, we employ the 20-Questions game, traditionally used within the Cognitive Science community to inspect the information seeking-strategy's development.  This task requires a series of interconnected skills: asking informative questions, stepwise updating the hypothesis space, and stopping asking questions when enough information has been collected. We build hierarchical hypothesis spaces, exploiting feature norms collected from humans vs. ChatGPT itself, and we inspect the efficiency and informativeness of ChatGPT's strategy. Our results show that ChatGPT's performance gets closer to an optimal agent only when prompted to explicitly list the updated space stepwise.","authors":["Leonardo Bertolazzi","Davide Mazzaccara","Filippo Merlo","Raffaella Bernardi"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"56","paper":"static/papers/inlg/56_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"ChatGPT's Information Seeking Strategy: Insights From the 20-Questions Game"},{"UID":"inlg99","abstract":"In this paper, we present a system for augmenting virtual AI characters with long-term memory, enabling them to remember facts about themselves, their world, and past experiences. We propose a memory-creation pipeline that converts raw text into condensed memories and a memory-retrieval system that utilizes these memories to generate character responses. Using a fact-checking pipeline based on GPT-4, our evaluation demonstrates that the character responses are grounded in the retrieved memories and maintain factual accuracy. We discuss the implications of our system for creating engaging and consistent virtual characters and highlight areas for future research, including large language model (LLM) guardrailing and virtual character personality development.","authors":["Fabian Landwehr","Erika Varis Doggett","Romann M. Weber"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"99","paper":"static/papers/inlg/99_Paper.pdf","poster":"static/posters/INLG2023/99.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Memories for Virtual AI Characters"},{"UID":"inlg107","abstract":"In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behavior of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.","authors":["Subhadra Vadlamannati","G\u00f6zde \u015eahin"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"107","paper":"static/papers/inlg/107_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Metric-Based in-Context Learning: A Case Study in Text Simplification"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#inlgoralsession3","name":"INLG Oral Session 3: Leveraging Large Language Models for NLG","room":"Sun II","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"INLG Oral Session 3: Leveraging Large Language Models for NLG","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Memories for Virtual AI Characters"},{"UID":"inlg107","abstract":"In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behavior of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.","authors":["Subhadra Vadlamannati","G\u00f6zde \u015eahin"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"107","paper":"static/papers/inlg/107_Paper.pdf","poster":"","session":"inlgoralsession3","sessions":[{"UID":"inlgoralsession3","calendarId":"inlgoral","category":"time","chair":"Tom Williams","contents":[{"UID":"inlg15","abstract":"While GPT-3 has garnered significant attention for its capabilities in natural language generation, research on its use outside of English is still relatively limited. We focus on how GPT-3 can be fine-tuned for generating synthetic news articles in a low-resource language, namely Danish. The model's performance is evaluated on the dimensions of human and machine detection in two separate experiments. When presented with either a real or GPT-3 generated news article, human participants achieve a 58.1% classification accuracy. Contrarily, a fine-tuned BERT classifier obtains a 92.7% accuracy on the same task. This discrepancy likely pertains to the fine-tuned GPT-3 model oversampling high-likelihood tokens in its text generation. Although this is undetectable to the human eye, it leaves a statistical discrepancy for machine classifiers to detect. We address how decisions in the experimental design favoured the machine classifiers over the human evaluators, and whether the produced synthetic articles are applicable in a real-world context.","authors":["Mina Almasi","Anton Schi\u00f8nning"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"15","paper":"static/papers/inlg/15_Paper.pdf","poster":"static/posters/INLG2023/15.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Fine-Tuning GPT-3 for Synthetic Danish News Generation"},{"UID":"inlg56","abstract":"Large Language Models, and ChatGPT in particular, have recently grabbed the attention of the community and the media. Having reached high language proficiency, attention has been shifting toward its reasoning capabilities. In this paper, our main aim is to evaluate ChatGPT's question generation in a task where language production should be driven by an implicit reasoning process. To this end, we employ the 20-Questions game, traditionally used within the Cognitive Science community to inspect the information seeking-strategy's development.  This task requires a series of interconnected skills: asking informative questions, stepwise updating the hypothesis space, and stopping asking questions when enough information has been collected. We build hierarchical hypothesis spaces, exploiting feature norms collected from humans vs. ChatGPT itself, and we inspect the efficiency and informativeness of ChatGPT's strategy. Our results show that ChatGPT's performance gets closer to an optimal agent only when prompted to explicitly list the updated space stepwise.","authors":["Leonardo Bertolazzi","Davide Mazzaccara","Filippo Merlo","Raffaella Bernardi"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"56","paper":"static/papers/inlg/56_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"ChatGPT's Information Seeking Strategy: Insights From the 20-Questions Game"},{"UID":"inlg99","abstract":"In this paper, we present a system for augmenting virtual AI characters with long-term memory, enabling them to remember facts about themselves, their world, and past experiences. We propose a memory-creation pipeline that converts raw text into condensed memories and a memory-retrieval system that utilizes these memories to generate character responses. Using a fact-checking pipeline based on GPT-4, our evaluation demonstrates that the character responses are grounded in the retrieved memories and maintain factual accuracy. We discuss the implications of our system for creating engaging and consistent virtual characters and highlight areas for future research, including large language model (LLM) guardrailing and virtual character personality development.","authors":["Fabian Landwehr","Erika Varis Doggett","Romann M. Weber"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"99","paper":"static/papers/inlg/99_Paper.pdf","poster":"static/posters/INLG2023/99.pdf","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Memories for Virtual AI Characters"},{"UID":"inlg107","abstract":"In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behavior of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.","authors":["Subhadra Vadlamannati","G\u00f6zde \u015eahin"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"107","paper":"static/papers/inlg/107_Paper.pdf","poster":"","session":"inlgoralsession3","start":"2023-09-14T10:30:00+02:00","title":"Metric-Based in-Context Learning: A Case Study in Text Simplification"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#inlgoralsession3","name":"INLG Oral Session 3: Leveraging Large Language Models for NLG","room":"Sun II","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"INLG Oral Session 3: Leveraging Large Language Models for NLG","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Metric-Based in-Context Learning: A Case Study in Text Simplification"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"},{"UID":"inlg30","abstract":"In recent years, many NLP studies have focused solely on performance improvement. In this work, we focus on the linguistic and scientific aspects of NLP. We use the task of generating referring expressions in context (REG-in-context) as a case study and start our analysis from GREC, a comprehensive set of shared tasks in English that addressed this topic over a decade ago. We ask what the performance of models would be if we assessed them (1) on more realistic datasets, and (2) using more advanced methods. We test the models using different evaluation metrics and feature selection experiments. We conclude that GREC can no longer be regarded as offering a reliable assessment of models' ability to mimic human reference production, because the results are highly impacted by the choice of corpus and evaluation metrics. Our results also suggest that pre-trained language models are less dependent on the choice of corpus than classic Machine Learning models, and therefore make more robust class predictions.","authors":["Fahime Same","Guanyi Chen","Kees van Deemter"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"30","paper":"static/papers/inlg/30_Paper.pdf","poster":"static/posters/INLG2023/30.pdf","session":"inlgoralsession4","sessions":[{"UID":"inlgoralsession4","calendarId":"inlgoral","category":"time","chair":"Albert Gatt","contents":[{"UID":"inlg30","abstract":"In recent years, many NLP studies have focused solely on performance improvement. In this work, we focus on the linguistic and scientific aspects of NLP. We use the task of generating referring expressions in context (REG-in-context) as a case study and start our analysis from GREC, a comprehensive set of shared tasks in English that addressed this topic over a decade ago. We ask what the performance of models would be if we assessed them (1) on more realistic datasets, and (2) using more advanced methods. We test the models using different evaluation metrics and feature selection experiments. We conclude that GREC can no longer be regarded as offering a reliable assessment of models' ability to mimic human reference production, because the results are highly impacted by the choice of corpus and evaluation metrics. Our results also suggest that pre-trained language models are less dependent on the choice of corpus than classic Machine Learning models, and therefore make more robust class predictions.","authors":["Fahime Same","Guanyi Chen","Kees van Deemter"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"30","paper":"static/papers/inlg/30_Paper.pdf","poster":"static/posters/INLG2023/30.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Models of Reference Production: How Do They Withstand the Test of Time?"},{"UID":"inlg57","abstract":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","authors":["Miriam Ansch\u00fctz","Diego Miguel Lozano","Georg Groh"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"57","paper":"static/papers/inlg/57_Paper.pdf","poster":"static/posters/INLG2023/57.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"This Is Not Correct! Negation-Aware Evaluation of Language Generation Systems"},{"UID":"inlg83","abstract":"Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.","authors":["Judith Sieker","Oliver Bott","Torgrim Solstad","Sina Zarrie\u00df"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"83","paper":"static/papers/inlg/83_Paper.pdf","poster":"static/posters/INLG2023/83.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models"},{"UID":"inlg115","abstract":"Language-capable robots must be able to efficiently and naturally communicate about objects in the environment. A key part of communication is Referring Form Selection (RFS): the process of selecting a form like it, that, or the N to use when referring to an object. Recent cognitive status-informed computational RFS models have been evaluated in terms of goodness-of-fit to human data. But it is as yet unclear whether these models actually select referring forms that are any more natural than baseline alternatives, regardless of goodness-of-fit. Through a human subject study designed to assess this question, we show that even though cognitive status-informed referring selection models achieve good fit to human data, they do not (yet) produce concrete benefits in terms of naturality. On the other hand, our results show that human utterances also had high variability in perceived naturality, demonstrating the challenges of evaluating RFS naturality.","authors":["Gabriel Del Castillo","Grace Clark","Zhao Han","Tom Williams"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"115","paper":"static/papers/inlg/115_Paper.pdf","poster":"static/posters/INLG2023/115.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Exploring the Naturalness of Cognitive Status-Informed Referring Form Selection Models"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession4###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#inlgoralsession4","name":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","room":"Sun II","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Models of Reference Production: How Do They Withstand the Test of Time?"},{"UID":"sigdial109","abstract":"This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The 'reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A 'story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.","authors":["Angus Addlesee","Weronika Siei\u0144ska","Nancie Gunson","Daniel Hernandez Garcia","Christian Dondrup","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"109","paper":"static/papers/sigdial/109_Paper.pdf","poster":"static/posters/SIGDIAL2023/109.pdf","session":"sigdialoralsession2","sessions":[{"UID":"sigdialoralsession2","calendarId":"sigdialoral","category":"time","chair":"Dilek Hakkani-Tur","contents":[{"UID":"sigdial106","abstract":"Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses.  However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.","authors":["Sarah E. Finch","Ellie S. Paek","Jinho D. Choi"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"106","paper":"static/papers/sigdial/106_Paper.pdf","poster":"static/posters/SIGDIAL2023/106.pdf","session":"sigdialoralsession2","start":"2023-09-13T15:40:00+02:00","title":"Leveraging Large Language Models for Automated Dialogue Analysis"},{"UID":"sigdial25","abstract":"Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples.","authors":["Vojt\u011bch Hude\u010dek","Ondrej Du\u0161ek"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"25","paper":"static/papers/sigdial/25_Paper.pdf","poster":"static/posters/SIGDIAL2023/25.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:00:00+02:00","title":"Are Large Language Models All You Need for Task-Oriented Dialogue?"},{"UID":"sigdial109","abstract":"This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The 'reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A 'story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.","authors":["Angus Addlesee","Weronika Siei\u0144ska","Nancie Gunson","Daniel Hernandez Garcia","Christian Dondrup","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"109","paper":"static/papers/sigdial/109_Paper.pdf","poster":"static/posters/SIGDIAL2023/109.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:20:00+02:00","title":"Multi-Party Goal Tracking With LLMs: Comparing Pre-Training, Fine-Tuning, and Prompt Engineering"},{"UID":"sigdial156","abstract":"This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.","authors":["Lidiia Ostyakova","Veronika Smilga","Kseniia Petukhova","Maria Molchanova","Daniel Kornev"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"156","paper":"static/papers/sigdial/156_Paper.pdf","poster":"static/posters/SIGDIAL2023/156.pdf","session":"sigdialoralsession2","start":"2023-09-13T16:40:00+02:00","title":"ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations With Speech Functions"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession2###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#sigdialoralsession2","name":"Sigdial Oral Session 2: LLM for dialogue","room":"Sun I","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"Sigdial Oral Session 2: LLM for dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Multi-Party Goal Tracking With LLMs: Comparing Pre-Training, Fine-Tuning, and Prompt Engineering"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"inlg12","abstract":"Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data and aids in the development of countermeasures. Many prior works---and some recently deployed defenses---focus on ``verbatim memorization'', defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense that _perfectly_ prevents all verbatim memorization.  And yet, we demonstrate that this ``perfect'' filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified ``style-transfer'' prompts---and in some cases even the non-modified original prompts---to extract memorized information. We conclude by discussing potential alternative definitions and why defining memorization is a difficult yet crucial open question for neural language models.","authors":["Daphne Ippolito","Florian Tramer","Milad Nasr","Chiyuan Zhang","Matthew Jagielski","Katherine Lee","Christopher Choquette Choo","Nicholas Carlini"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"12","paper":"static/papers/inlg/12_Paper.pdf","poster":"static/posters/INLG2023/12.pdf","session":"inlgoralsession1","sessions":[{"UID":"inlgoralsession1","calendarId":"inlgoral","category":"time","chair":"Ching-Chi-Chen","contents":[{"UID":"inlg12","abstract":"Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data and aids in the development of countermeasures. Many prior works---and some recently deployed defenses---focus on ``verbatim memorization'', defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense that _perfectly_ prevents all verbatim memorization.  And yet, we demonstrate that this ``perfect'' filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified ``style-transfer'' prompts---and in some cases even the non-modified original prompts---to extract memorized information. We conclude by discussing potential alternative definitions and why defining memorization is a difficult yet crucial open question for neural language models.","authors":["Daphne Ippolito","Florian Tramer","Milad Nasr","Chiyuan Zhang","Matthew Jagielski","Katherine Lee","Christopher Choquette Choo","Nicholas Carlini"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"12","paper":"static/papers/inlg/12_Paper.pdf","poster":"static/posters/INLG2023/12.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Preventing Generation of Verbatim Memorization in Language Models Gives a False Sense of Privacy"},{"UID":"inlg34","abstract":"Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.","authors":["Tahsina Hashem","Weiqing Wang","Derry Tanti Wijaya","Mohammed Eunus Ali","Yuan-Fang Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"34","paper":"static/papers/inlg/34_Paper.pdf","poster":"static/posters/INLG2023/34.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Generating Faithful Text From a Knowledge Graph With Noisy Reference Text"},{"UID":"inlg58","abstract":"Automatically summarizing radiology reports into a concise impression can reduce the manual burden of clinicians and improve the consistency of reporting. Previous work aimed to enhance content selection and factuality through guided abstractive summarization. However, two key issues persist. First, current methods heavily rely on domain-specific resources to extract the guidance signal, limiting their transferability to domains and languages where those resources are unavailable. Second, while automatic metrics like ROUGE show progress, we lack a good understanding of the errors and failure modes in this task. To bridge these gaps, we first propose a domain-agnostic guidance signal in form of variable-length extractive summaries. Our empirical results on two English benchmarks demonstrate that this guidance signal improves upon unguided summarization while being competitive with domain-specific methods. Additionally, we run an expert evaluation of four systems according to a taxonomy of 11 fine-grained errors. We find that the most pressing differences between automatic summaries and those of radiologists relate to content selection including omissions (up to 52%) and additions (up to 57%). We hypothesize that latent reporting factors and corpus-level inconsistencies may limit models to reliably learn content selection from the available data, presenting promising directions for future work.","authors":["Jan Trienes","Paul Youssef","J\u00f6rg Schl\u00f6tterer","Christin Seifert"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"58","paper":"static/papers/inlg/58_Paper.pdf","poster":"static/posters/INLG2023/58.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Guidance in Radiology Report Summarization: An Empirical Evaluation and Error Analysis"},{"UID":"inlg97","abstract":"Neural data-to-text systems lack the control and factual accuracy required to generate useful and insightful summaries of multidimensional data. We propose a solution in the form of data views, where each view describes an entity and its attributes along specific dimensions. A sequence of views can then be used as a high-level schema for document planning, with the neural model handling the complexities of micro-planning and surface realization. We show that our view-based system retains factual accuracy while offering high-level control of output that can be tailored based on user preference or other norms within the domain.","authors":["Craig Thomson","Clement Rebuffel","Ehud Reiter","Laure Soulier","Somayajulu Sripada","patrick Gallinari"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"97","paper":"static/papers/inlg/97_Paper.pdf","poster":"static/posters/INLG2023/97.pdf","session":"inlgoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Enhancing Factualness and Controllability of Data-to-Text Generation via Data Views and Constraints"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#inlgoralsession1","name":"INLG Oral Session 1: Trustworthiness of NLG systems","room":"Sun II","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"INLG Oral Session 1: Trustworthiness of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Preventing Generation of Verbatim Memorization in Language Models Gives a False Sense of Privacy"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial73","abstract":"Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.","authors":["Yahui Fu","Koji Inoue","Chenhui Chu","Tatsuya Kawahara"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"73","paper":"static/papers/sigdial/73_Paper.pdf","poster":"","session":"sigdialoralsession5","sessions":[{"UID":"sigdialoralsession5","calendarId":"sigdialoral","category":"time","chair":"Mike White","contents":[{"UID":"sigdial29","abstract":"Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These \"self-imposed filter bubbles\" (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand.  <p>To address this issue, we develop a strategy for overcoming users' SFB within the course of the interaction. By continuously modeling the user's position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users' SFBs and promoting a more reflective and comprehensive discussion of the topic.","authors":["Annalena Aicher","Daniel Kornmueller","Yuki Matsuda","Stefan Ultes","Wolfgang Minker","Keiichi Yasumoto"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"29","paper":"static/papers/sigdial/29_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Towards Breaking the Self-Imposed Filter Bubble in Argumentative Dialogues"},{"UID":"sigdial81","abstract":"There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The \"openness\" of the dialogue is expected to be  maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to \"just chat about anything\" results in a very narrow form of dialogue, which we refer to as the \"open-domain paradox\". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.","authors":["Gabriel Skantze","A. Seza Do\u011fru\u00f6z"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"81","paper":"static/papers/sigdial/81_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:50:00+02:00","title":"The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue"},{"UID":"sigdial130","abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models' performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics' unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.","authors":["Sarik Ghazarian","Behnam Hedayatnia","Di Jin","Sijia Liu","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"130","paper":"static/papers/sigdial/130_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:10:00+02:00","title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems"},{"UID":"sigdial27","abstract":"AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains \u22481.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.","authors":["Anuradha Welivita","Chun-Hung Yeh","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"27","paper":"static/papers/sigdial/27_Paper.pdf","poster":"static/posters/SIGDIAL2023/27.pdf","session":"sigdialoralsession5","start":"2023-09-15T12:30:00+02:00","title":"Empathetic Response Generation for Distress Support"},{"UID":"sigdial73","abstract":"Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.","authors":["Yahui Fu","Koji Inoue","Chenhui Chu","Tatsuya Kawahara"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"73","paper":"static/papers/sigdial/73_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:50:00+02:00","title":"Reasoning Before Responding: Integrating Commonsense-Based Causality Explanation for Empathetic Response Generation"}],"day":"Friday","discord":"https://discord.com/channels/###sigdialoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#sigdialoralsession5","name":"Sigdial Oral Session 5: Topics in open-domain dialogue","room":"Sun I","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"Sigdial Oral Session 5: Topics in open-domain dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Reasoning Before Responding: Integrating Commonsense-Based Causality Explanation for Empathetic Response Generation"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial122","abstract":"Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.","authors":["Bram Willemsen","Livia Qian","Gabriel Skantze"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"122","paper":"static/papers/sigdial/122_Paper.pdf","poster":"","session":"sigdialoralsession4","sessions":[{"UID":"sigdialoralsession4","calendarId":"sigdialoral","category":"time","chair":"Tatsuya Kawahara","contents":[{"UID":"sigdial49","abstract":"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept.  In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation.  The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.","authors":["Qi Cheng","Mert Inan","Rahma Mbarki","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"49","paper":"static/papers/sigdial/49_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:10:00+02:00","title":"Learning Multimodal Cues of Children's Uncertainty"},{"UID":"sigdial34","abstract":"Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control.  We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.","authors":["Alexandru Coca","Bo-Hsiang Tseng","Jinghong Chen","Weizhe Lin","Weixuan Zhang","Tisha Anders","Bill Byrne"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"1","original_id":"34","paper":"static/papers/sigdial/34_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:30:00+02:00","title":"Grounding Description-Driven Dialogue State Trackers With Knowledge-Seeking Turns"},{"UID":"sigdial122","abstract":"Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.","authors":["Bram Willemsen","Livia Qian","Gabriel Skantze"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"122","paper":"static/papers/sigdial/122_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:50:00+02:00","title":"Resolving References in Visually-Grounded Dialogue via Text Generation"},{"UID":"sigdial5","abstract":"Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.","authors":["Hoang Nguyen","Chenwei Zhang","Ye Liu","Philip Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"3","original_id":"5","paper":"static/papers/sigdial/5_Paper.pdf","poster":"static/posters/SIGDIAL2023/5.pdf","session":"sigdialoralsession4","start":"2023-09-14T17:10:00+02:00","title":"Slot Induction via Pre-Trained Language Model Probing and Multi-Level Contrastive Learning"},{"UID":"sigdial19","abstract":"Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.","authors":["Andreas Liesenfeld","Alianda Lopez","Mark Dingemanse"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"4","original_id":"19","paper":"static/papers/sigdial/19_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T17:30:00+02:00","title":"The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession4###","end":"2023-09-14T17:50:00+02:00","end_time":"Thu, 14 Sep 2023 15:50:00 GMT","location":"#sigdialoralsession4","name":"Sigdial Oral Session 4: Language understanding and multimodality","room":"Sun I","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"Sigdial Oral Session 4: Language understanding and multimodality","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Resolving References in Visually-Grounded Dialogue via Text Generation"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"},{"UID":"sigdial5","abstract":"Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.","authors":["Hoang Nguyen","Chenwei Zhang","Ye Liu","Philip Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"3","original_id":"5","paper":"static/papers/sigdial/5_Paper.pdf","poster":"static/posters/SIGDIAL2023/5.pdf","session":"sigdialoralsession4","sessions":[{"UID":"sigdialoralsession4","calendarId":"sigdialoral","category":"time","chair":"Tatsuya Kawahara","contents":[{"UID":"sigdial49","abstract":"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept.  In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation.  The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.","authors":["Qi Cheng","Mert Inan","Rahma Mbarki","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"49","paper":"static/papers/sigdial/49_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:10:00+02:00","title":"Learning Multimodal Cues of Children's Uncertainty"},{"UID":"sigdial34","abstract":"Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control.  We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.","authors":["Alexandru Coca","Bo-Hsiang Tseng","Jinghong Chen","Weizhe Lin","Weixuan Zhang","Tisha Anders","Bill Byrne"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"1","original_id":"34","paper":"static/papers/sigdial/34_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:30:00+02:00","title":"Grounding Description-Driven Dialogue State Trackers With Knowledge-Seeking Turns"},{"UID":"sigdial122","abstract":"Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.","authors":["Bram Willemsen","Livia Qian","Gabriel Skantze"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"122","paper":"static/papers/sigdial/122_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:50:00+02:00","title":"Resolving References in Visually-Grounded Dialogue via Text Generation"},{"UID":"sigdial5","abstract":"Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.","authors":["Hoang Nguyen","Chenwei Zhang","Ye Liu","Philip Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"3","original_id":"5","paper":"static/papers/sigdial/5_Paper.pdf","poster":"static/posters/SIGDIAL2023/5.pdf","session":"sigdialoralsession4","start":"2023-09-14T17:10:00+02:00","title":"Slot Induction via Pre-Trained Language Model Probing and Multi-Level Contrastive Learning"},{"UID":"sigdial19","abstract":"Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.","authors":["Andreas Liesenfeld","Alianda Lopez","Mark Dingemanse"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"4","original_id":"19","paper":"static/papers/sigdial/19_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T17:30:00+02:00","title":"The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession4###","end":"2023-09-14T17:50:00+02:00","end_time":"Thu, 14 Sep 2023 15:50:00 GMT","location":"#sigdialoralsession4","name":"Sigdial Oral Session 4: Language understanding and multimodality","room":"Sun I","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"Sigdial Oral Session 4: Language understanding and multimodality","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Slot Induction via Pre-Trained Language Model Probing and Multi-Level Contrastive Learning"},{"UID":"sigdial86","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs.  Despite their prevalence, there currently lacks an accurate survey of dialogue noise,  nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise.  Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise.  Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","authors":["Derek Chen","Zhou Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"86","paper":"static/papers/sigdial/86_Paper.pdf","poster":"","session":"sigdialoralsession1","sessions":[{"UID":"sigdialoralsession1","calendarId":"sigdialoral","category":"time","chair":"Gabriel Skantze","contents":[{"UID":"sigdial86","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs.  Despite their prevalence, there currently lacks an accurate survey of dialogue noise,  nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise.  Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise.  Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","authors":["Derek Chen","Zhou Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"86","paper":"static/papers/sigdial/86_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Sources of Noise in Dialogue and How to Deal With Them"},{"UID":"sigdial14","abstract":"Discourse relations have different patterns of marking across different languages.  As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment.  The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.","authors":["Frances Yung","Merel Scholman","Ekaterina Lapshinova-Koltunski","Christina Pollkl\u00e4sener","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"14","paper":"static/papers/sigdial/14_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:05:00+02:00","title":"Investigating Explicitation of Discourse Connectives in Translation Using Automatic Annotations"},{"UID":"sigdial43","abstract":"Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.","authors":["Yang Janet Liu","Tatsuya Aoyama","Amir Zeldes"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"43","paper":"static/papers/sigdial/43_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:25:00+02:00","title":"What's Hard in English RST Parsing? Predictive Models for Error Analysis"},{"UID":"sigdial80","abstract":"Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86&#92;% of the evaluated tasks were improved from a conversational suitability point of view.","authors":["Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"80","paper":"static/papers/sigdial/80_Paper.pdf","poster":"static/posters/SIGDIAL2023/80.pdf","session":"sigdialoralsession1","start":"2023-09-13T11:45:00+02:00","title":"Grounded Complex Task Segmentation for Conversational Assistants"},{"UID":"sigdial91","abstract":"Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners' topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.","authors":["Grace Lawley","Peter A. Heeman","Jill K. Dolata","Eric Fombonne","Steven Bedrick"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"91","paper":"static/papers/sigdial/91_Paper.pdf","poster":"static/posters/SIGDIAL2023/91.pdf","session":"sigdialoralsession1","start":"2023-09-13T12:05:00+02:00","title":"A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#sigdialoralsession1","name":"Sigdial Oral Session 1: Analysis of discourse and dialogue","room":"Sun I","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"Sigdial Oral Session 1: Analysis of discourse and dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Sources of Noise in Dialogue and How to Deal With Them"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"inlg24","abstract":"Good figure captions help paper readers understand complex scientific figures. Unfortunately, even published papers often have poorly written captions. Automatic caption generation could aid paper writers by providing good starting captions that can be refined for better quality. Prior work often treated figure caption generation as a vision-to-language task. In this paper, we show that it can be more effectively tackled as a text summarization task in scientific documents. We fine-tuned PEGASUS, a pre-trained abstractive summarization model, to specifically summarize figure-referencing paragraphs (e.g., \"Figure 3 shows...\") into figure captions. Experiments on large-scale arXiv figures show that our method outperforms prior vision methods in both automatic and human evaluations. We further conducted an in-depth investigation focused on two key challenges: (i) the common presence of low-quality author-written captions and (ii) the lack of clear standards for good captions. Our code and data are available at: https://github.com/Crowd-AI-Lab/Generating-Figure-Captions-as-a-Text-Summarization-Task.","authors":["Chieh-Yang Huang","Ting-Yao Hsu","Ryan Rossi","Ani Nenkova","Sungchul Kim","Gromit Yeuk-Yin Chan","Eunyee Koh","C Lee Giles","Ting-Hao Huang"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"24","paper":"static/papers/inlg/24_Paper.pdf","poster":"static/posters/INLG2023/24.pdf","session":"inlgoralsession5","sessions":[{"UID":"inlgoralsession5","calendarId":"inlgoral","category":"time","chair":"Dimitra Gkatzia","contents":[{"UID":"inlg16","abstract":"In this work, we investigate Data Augmentation methods to improve the performance of state-of-the-art models for four different downstream tasks. Specifically, we propose Generative Adversarial Network using Language Models (GAN-LM) approach that combines a deep generative model with a pre-trained language model to produce diverse augmentations. We compare the GAN-LM to various conventional methods in non-contextual- and contextual-levels on four public datasets: ZESHEL for zero-shot entity linking, TREC for question classification, STS-B for sentence pairs semantic textual similarity (STS), and mSTS for multilingual sentence pairs STS. Additionally, we subsample these datasets to study the impact of such augmentations in low-resource settings where limited amounts of training data is available. Compared to the state-of-the-art methods in downstream tasks, we mostly achieve the best performance using GAN-LM approach. Finally, we investigate the way of combining the GAN-LM with other augmentation methods to complement our proposed approach. The developed code for reproducibility is included in the supplementary material.","authors":["Dae Yon Hwang","Yaroslav Nechaev","Cyprien de Lichy","Renxian Zhang"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"16","paper":"static/papers/inlg/16_Paper.pdf","poster":"static/posters/INLG2023/16.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"GAN-LM: Generative Adversarial Network Using Language Models for Downstream Applications"},{"UID":"inlg24","abstract":"Good figure captions help paper readers understand complex scientific figures. Unfortunately, even published papers often have poorly written captions. Automatic caption generation could aid paper writers by providing good starting captions that can be refined for better quality. Prior work often treated figure caption generation as a vision-to-language task. In this paper, we show that it can be more effectively tackled as a text summarization task in scientific documents. We fine-tuned PEGASUS, a pre-trained abstractive summarization model, to specifically summarize figure-referencing paragraphs (e.g., \"Figure 3 shows...\") into figure captions. Experiments on large-scale arXiv figures show that our method outperforms prior vision methods in both automatic and human evaluations. We further conducted an in-depth investigation focused on two key challenges: (i) the common presence of low-quality author-written captions and (ii) the lack of clear standards for good captions. Our code and data are available at: https://github.com/Crowd-AI-Lab/Generating-Figure-Captions-as-a-Text-Summarization-Task.","authors":["Chieh-Yang Huang","Ting-Yao Hsu","Ryan Rossi","Ani Nenkova","Sungchul Kim","Gromit Yeuk-Yin Chan","Eunyee Koh","C Lee Giles","Ting-Hao Huang"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"24","paper":"static/papers/inlg/24_Paper.pdf","poster":"static/posters/INLG2023/24.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Summaries as Captions: Generating Figure Captions for Scientific Documents With Automated Text Summarization"},{"UID":"inlg47","abstract":"An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often specifies claims with details, whereas it adds less evidence than humans do. Moreover, its capabilities generalize well to other domains, such as instructional texts.","authors":["Gabriella Skitalinskaya","Maximilian Splieth\u00f6ver","Henning Wachsmuth"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"47","paper":"static/papers/inlg/47_Paper.pdf","poster":"static/posters/INLG2023/47.pdf","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Claim Optimization in Computational Argumentation"},{"UID":"inlg71","abstract":"Prior art investigating task-oriented dialog and automatic generation of such dialogs have focused on single-user dialogs between a single user and an agent. However, there is limited study on adapting such AI agents to multi-user conversations (involving multiple users and an agent). Multi-user conversations are richer than single-user conversations containing social banter and collaborative decision making. The most significant challenge impeding such studies is the lack of suitable multi-user task-oriented dialogs with annotations of user belief states and system actions. One potential solution is multi-user dialog generation from single-user data. Many single-user dialogs datasets already contain dialog state information (intents, slots), thus making them suitable candidates. In this work, we propose a novel approach for expanding single-user task-oriented dialogs (e.g. MultiWOZ) to multi-user dialogs in a zero-shot setting.","authors":["Shiv Surya","Yohan Jo","Arijit Biswas","Alexandros Potamianos"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"71","paper":"static/papers/inlg/71_Paper.pdf","poster":"","session":"inlgoralsession5","start":"2023-09-15T11:30:00+02:00","title":"A Zero-Shot Approach for Multi-User Task-Oriented Dialog Generation"}],"day":"Friday","discord":"https://discord.com/channels/###inlgoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#inlgoralsession5","name":"INLG Oral Session 5: NLG for real-world applications","room":"Sun II","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"INLG Oral Session 5: NLG for real-world applications","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Summaries as Captions: Generating Figure Captions for Scientific Documents With Automated Text Summarization"},{"UID":"sigdial129","abstract":"Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce &#92;textsc{Syndicom} - a method for improving commonsense in dialogue response generation. &#92;textsc{Syndicom} consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.  <p>&#92;textsc{Syndicom} is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. &#92;textsc{Syndicom} achieves a relative improvement of 53&#92;% over ChatGPT on ROUGE-1, and human evaluators prefer &#92;textsc{Syndicom} over ChatGPT 57&#92;% of the time. We will publicly release the code and the full dataset.","authors":["Christopher Richardson","Larry Heck"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"129","paper":"static/papers/sigdial/129_Paper.pdf","poster":"","session":"sigdialoralsession3","sessions":[{"UID":"sigdialoralsession3","calendarId":"sigdialoral","category":"time","chair":"Frederic Bechet","contents":[{"UID":"sigdial79","abstract":"Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.","authors":["Qingyang Wu","James Gung","Raphael Shu","Yi Zhang"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"79","paper":"static/papers/sigdial/79_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:30:00+02:00","title":"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"},{"UID":"sigdial15","abstract":"With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.","authors":["Ekaterina Svikhnushina","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"15","paper":"static/papers/sigdial/15_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T10:50:00+02:00","title":"Approximating Online Human Evaluation of Social Chatbots With Prompting"},{"UID":"sigdial12","abstract":"Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.","authors":["Ayaka Ueyama","Yoshinobu Kano"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"12","paper":"static/papers/sigdial/12_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:10:00+02:00","title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution"},{"UID":"sigdial129","abstract":"Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce &#92;textsc{Syndicom} - a method for improving commonsense in dialogue response generation. &#92;textsc{Syndicom} consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.  <p>&#92;textsc{Syndicom} is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. &#92;textsc{Syndicom} achieves a relative improvement of 53&#92;% over ChatGPT on ROUGE-1, and human evaluators prefer &#92;textsc{Syndicom} over ChatGPT 57&#92;% of the time. We will publicly release the code and the full dataset.","authors":["Christopher Richardson","Larry Heck"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"129","paper":"static/papers/sigdial/129_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:30:00+02:00","title":"Syndicom: Improving Conversational Commonsense With Error-Injection and Natural Language Feedback"},{"UID":"sigdial163","abstract":"Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,\"Is the WIFI reliable?\" or \"Does the restaurant have a good atmosphere?\"). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.","authors":["Chao Zhao","Spandana Gella","Seokhwan Kim","Di Jin","Devamanyu Hazarika","Alexandros Papangelis","Behnam Hedayatnia","Mahdi Namazifar","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"163","paper":"static/papers/sigdial/163_Paper.pdf","poster":"","session":"sigdialoralsession3","start":"2023-09-14T11:50:00+02:00","title":"\"What Do Others Think?\": Task-Oriented Conversational Modeling With Subjective Knowledge"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession3###","end":"2023-09-14T12:10:00+02:00","end_time":"Thu, 14 Sep 2023 10:10:00 GMT","location":"#sigdialoralsession3","name":"Sigdial Oral Session 3: Dialogue modeling and evaluation","room":"Sun I","start":"2023-09-14T10:30:00+02:00","start_time":"Thu, 14 Sep 2023 08:30:00 GMT","title":"Sigdial Oral Session 3: Dialogue modeling and evaluation","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Syndicom: Improving Conversational Commonsense With Error-Injection and Natural Language Feedback"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial81","abstract":"There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The \"openness\" of the dialogue is expected to be  maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to \"just chat about anything\" results in a very narrow form of dialogue, which we refer to as the \"open-domain paradox\". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.","authors":["Gabriel Skantze","A. Seza Do\u011fru\u00f6z"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"81","paper":"static/papers/sigdial/81_Paper.pdf","poster":"","session":"sigdialoralsession5","sessions":[{"UID":"sigdialoralsession5","calendarId":"sigdialoral","category":"time","chair":"Mike White","contents":[{"UID":"sigdial29","abstract":"Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These \"self-imposed filter bubbles\" (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand.  <p>To address this issue, we develop a strategy for overcoming users' SFB within the course of the interaction. By continuously modeling the user's position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users' SFBs and promoting a more reflective and comprehensive discussion of the topic.","authors":["Annalena Aicher","Daniel Kornmueller","Yuki Matsuda","Stefan Ultes","Wolfgang Minker","Keiichi Yasumoto"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"29","paper":"static/papers/sigdial/29_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Towards Breaking the Self-Imposed Filter Bubble in Argumentative Dialogues"},{"UID":"sigdial81","abstract":"There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The \"openness\" of the dialogue is expected to be  maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to \"just chat about anything\" results in a very narrow form of dialogue, which we refer to as the \"open-domain paradox\". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.","authors":["Gabriel Skantze","A. Seza Do\u011fru\u00f6z"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"81","paper":"static/papers/sigdial/81_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:50:00+02:00","title":"The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue"},{"UID":"sigdial130","abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models' performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics' unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.","authors":["Sarik Ghazarian","Behnam Hedayatnia","Di Jin","Sijia Liu","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"130","paper":"static/papers/sigdial/130_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:10:00+02:00","title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems"},{"UID":"sigdial27","abstract":"AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains \u22481.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.","authors":["Anuradha Welivita","Chun-Hung Yeh","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"27","paper":"static/papers/sigdial/27_Paper.pdf","poster":"static/posters/SIGDIAL2023/27.pdf","session":"sigdialoralsession5","start":"2023-09-15T12:30:00+02:00","title":"Empathetic Response Generation for Distress Support"},{"UID":"sigdial73","abstract":"Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.","authors":["Yahui Fu","Koji Inoue","Chenhui Chu","Tatsuya Kawahara"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"73","paper":"static/papers/sigdial/73_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:50:00+02:00","title":"Reasoning Before Responding: Integrating Commonsense-Based Causality Explanation for Empathetic Response Generation"}],"day":"Friday","discord":"https://discord.com/channels/###sigdialoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#sigdialoralsession5","name":"Sigdial Oral Session 5: Topics in open-domain dialogue","room":"Sun I","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"Sigdial Oral Session 5: Topics in open-domain dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial19","abstract":"Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.","authors":["Andreas Liesenfeld","Alianda Lopez","Mark Dingemanse"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"4","original_id":"19","paper":"static/papers/sigdial/19_Paper.pdf","poster":"","session":"sigdialoralsession4","sessions":[{"UID":"sigdialoralsession4","calendarId":"sigdialoral","category":"time","chair":"Tatsuya Kawahara","contents":[{"UID":"sigdial49","abstract":"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept.  In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation.  The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.","authors":["Qi Cheng","Mert Inan","Rahma Mbarki","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"49","paper":"static/papers/sigdial/49_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:10:00+02:00","title":"Learning Multimodal Cues of Children's Uncertainty"},{"UID":"sigdial34","abstract":"Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control.  We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.","authors":["Alexandru Coca","Bo-Hsiang Tseng","Jinghong Chen","Weizhe Lin","Weixuan Zhang","Tisha Anders","Bill Byrne"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"1","original_id":"34","paper":"static/papers/sigdial/34_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:30:00+02:00","title":"Grounding Description-Driven Dialogue State Trackers With Knowledge-Seeking Turns"},{"UID":"sigdial122","abstract":"Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.","authors":["Bram Willemsen","Livia Qian","Gabriel Skantze"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"122","paper":"static/papers/sigdial/122_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T16:50:00+02:00","title":"Resolving References in Visually-Grounded Dialogue via Text Generation"},{"UID":"sigdial5","abstract":"Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.","authors":["Hoang Nguyen","Chenwei Zhang","Ye Liu","Philip Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"3","original_id":"5","paper":"static/papers/sigdial/5_Paper.pdf","poster":"static/posters/SIGDIAL2023/5.pdf","session":"sigdialoralsession4","start":"2023-09-14T17:10:00+02:00","title":"Slot Induction via Pre-Trained Language Model Probing and Multi-Level Contrastive Learning"},{"UID":"sigdial19","abstract":"Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.","authors":["Andreas Liesenfeld","Alianda Lopez","Mark Dingemanse"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"4","original_id":"19","paper":"static/papers/sigdial/19_Paper.pdf","poster":"","session":"sigdialoralsession4","start":"2023-09-14T17:30:00+02:00","title":"The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialoralsession4###","end":"2023-09-14T17:50:00+02:00","end_time":"Thu, 14 Sep 2023 15:50:00 GMT","location":"#sigdialoralsession4","name":"Sigdial Oral Session 4: Language understanding and multimodality","room":"Sun I","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"Sigdial Oral Session 4: Language understanding and multimodality","zoom":"https://zoom.us/j/###Sun I###"}],"title":"The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"inlg57","abstract":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","authors":["Miriam Ansch\u00fctz","Diego Miguel Lozano","Georg Groh"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"57","paper":"static/papers/inlg/57_Paper.pdf","poster":"static/posters/INLG2023/57.pdf","session":"inlgoralsession4","sessions":[{"UID":"inlgoralsession4","calendarId":"inlgoral","category":"time","chair":"Albert Gatt","contents":[{"UID":"inlg30","abstract":"In recent years, many NLP studies have focused solely on performance improvement. In this work, we focus on the linguistic and scientific aspects of NLP. We use the task of generating referring expressions in context (REG-in-context) as a case study and start our analysis from GREC, a comprehensive set of shared tasks in English that addressed this topic over a decade ago. We ask what the performance of models would be if we assessed them (1) on more realistic datasets, and (2) using more advanced methods. We test the models using different evaluation metrics and feature selection experiments. We conclude that GREC can no longer be regarded as offering a reliable assessment of models' ability to mimic human reference production, because the results are highly impacted by the choice of corpus and evaluation metrics. Our results also suggest that pre-trained language models are less dependent on the choice of corpus than classic Machine Learning models, and therefore make more robust class predictions.","authors":["Fahime Same","Guanyi Chen","Kees van Deemter"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"30","paper":"static/papers/inlg/30_Paper.pdf","poster":"static/posters/INLG2023/30.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Models of Reference Production: How Do They Withstand the Test of Time?"},{"UID":"inlg57","abstract":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","authors":["Miriam Ansch\u00fctz","Diego Miguel Lozano","Georg Groh"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"57","paper":"static/papers/inlg/57_Paper.pdf","poster":"static/posters/INLG2023/57.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"This Is Not Correct! Negation-Aware Evaluation of Language Generation Systems"},{"UID":"inlg83","abstract":"Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.","authors":["Judith Sieker","Oliver Bott","Torgrim Solstad","Sina Zarrie\u00df"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"83","paper":"static/papers/inlg/83_Paper.pdf","poster":"static/posters/INLG2023/83.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models"},{"UID":"inlg115","abstract":"Language-capable robots must be able to efficiently and naturally communicate about objects in the environment. A key part of communication is Referring Form Selection (RFS): the process of selecting a form like it, that, or the N to use when referring to an object. Recent cognitive status-informed computational RFS models have been evaluated in terms of goodness-of-fit to human data. But it is as yet unclear whether these models actually select referring forms that are any more natural than baseline alternatives, regardless of goodness-of-fit. Through a human subject study designed to assess this question, we show that even though cognitive status-informed referring selection models achieve good fit to human data, they do not (yet) produce concrete benefits in terms of naturality. On the other hand, our results show that human utterances also had high variability in perceived naturality, demonstrating the challenges of evaluating RFS naturality.","authors":["Gabriel Del Castillo","Grace Clark","Zhao Han","Tom Williams"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"115","paper":"static/papers/inlg/115_Paper.pdf","poster":"static/posters/INLG2023/115.pdf","session":"inlgoralsession4","start":"2023-09-14T14:00:00+02:00","title":"Exploring the Naturalness of Cognitive Status-Informed Referring Form Selection Models"}],"day":"Thursday","discord":"https://discord.com/channels/###inlgoralsession4###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#inlgoralsession4","name":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","room":"Sun II","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"INLG Oral Session 4: Evaluation and linguistic analysis of NLG systems","zoom":"https://zoom.us/j/###Sun II###"}],"title":"This Is Not Correct! Negation-Aware Evaluation of Language Generation Systems"},{"UID":"sigdial29","abstract":"Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These \"self-imposed filter bubbles\" (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand.  <p>To address this issue, we develop a strategy for overcoming users' SFB within the course of the interaction. By continuously modeling the user's position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users' SFBs and promoting a more reflective and comprehensive discussion of the topic.","authors":["Annalena Aicher","Daniel Kornmueller","Yuki Matsuda","Stefan Ultes","Wolfgang Minker","Keiichi Yasumoto"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"29","paper":"static/papers/sigdial/29_Paper.pdf","poster":"","session":"sigdialoralsession5","sessions":[{"UID":"sigdialoralsession5","calendarId":"sigdialoral","category":"time","chair":"Mike White","contents":[{"UID":"sigdial29","abstract":"Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These \"self-imposed filter bubbles\" (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand.  <p>To address this issue, we develop a strategy for overcoming users' SFB within the course of the interaction. By continuously modeling the user's position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users' SFBs and promoting a more reflective and comprehensive discussion of the topic.","authors":["Annalena Aicher","Daniel Kornmueller","Yuki Matsuda","Stefan Ultes","Wolfgang Minker","Keiichi Yasumoto"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"29","paper":"static/papers/sigdial/29_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:30:00+02:00","title":"Towards Breaking the Self-Imposed Filter Bubble in Argumentative Dialogues"},{"UID":"sigdial81","abstract":"There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The \"openness\" of the dialogue is expected to be  maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to \"just chat about anything\" results in a very narrow form of dialogue, which we refer to as the \"open-domain paradox\". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.","authors":["Gabriel Skantze","A. Seza Do\u011fru\u00f6z"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"81","paper":"static/papers/sigdial/81_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T11:50:00+02:00","title":"The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue"},{"UID":"sigdial130","abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models' performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics' unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.","authors":["Sarik Ghazarian","Behnam Hedayatnia","Di Jin","Sijia Liu","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"2","original_id":"130","paper":"static/papers/sigdial/130_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:10:00+02:00","title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems"},{"UID":"sigdial27","abstract":"AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains \u22481.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.","authors":["Anuradha Welivita","Chun-Hung Yeh","Pearl Pu"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"27","paper":"static/papers/sigdial/27_Paper.pdf","poster":"static/posters/SIGDIAL2023/27.pdf","session":"sigdialoralsession5","start":"2023-09-15T12:30:00+02:00","title":"Empathetic Response Generation for Distress Support"},{"UID":"sigdial73","abstract":"Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.","authors":["Yahui Fu","Koji Inoue","Chenhui Chu","Tatsuya Kawahara"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"73","paper":"static/papers/sigdial/73_Paper.pdf","poster":"","session":"sigdialoralsession5","start":"2023-09-15T12:50:00+02:00","title":"Reasoning Before Responding: Integrating Commonsense-Based Causality Explanation for Empathetic Response Generation"}],"day":"Friday","discord":"https://discord.com/channels/###sigdialoralsession5###","end":"2023-09-15T13:10:00+02:00","end_time":"Fri, 15 Sep 2023 11:10:00 GMT","location":"#sigdialoralsession5","name":"Sigdial Oral Session 5: Topics in open-domain dialogue","room":"Sun I","start":"2023-09-15T11:30:00+02:00","start_time":"Fri, 15 Sep 2023 09:30:00 GMT","title":"Sigdial Oral Session 5: Topics in open-domain dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"Towards Breaking the Self-Imposed Filter Bubble in Argumentative Dialogues"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","sessions":[{"UID":"inlgpostersession+flash","calendarId":"inlgposter","category":"time","chair":"Ehud Reiter","contents":[{"UID":"inlg8","abstract":"In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a \\emph{transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a \\emph{transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain (``train'' in Figure \\ref{fig: system-initiated transition from chit-chat to task-oriented.}), then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.","authors":["Ye Liu","Stefan Ultes","Wolfgang Minker","Wolfgang Maier"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"8","paper":"static/papers/inlg/8_Paper.pdf","poster":"static/posters/INLG2023/8.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"System-Initiated Transitions From Chit-Chat to Task-Oriented Dialogues With Transition Info Extractor and Transition Sentence Generator"},{"UID":"inlg13","abstract":"Current captioning datasets focus on object-centric captions, describing the visible objects in the image, often ending up stating the obvious (for humans), e.g. \"people eating food in a park\". Although these datasets are useful to evaluate the ability of Vision & Language models to recognize and describe visual content, they do not support controlled experiments involving model testing or fine-tuning, with more high-level captions, which humans find easy and natural to produce. For example, people often describe images based on the type of scene they depict (\"people at a holiday resort\") and the actions they perform (\"people having a picnic\"). Such concepts are based on personal experience and contribute to forming common sense assumptions. We present the High-Level Dataset, a dataset extending 14997 images from the COCO dataset, aligned with a new set of 134,973 human-annotated (high-level) captions collected along three axes: scenes, actions and rationales. We further extend this dataset with confidence scores collected from an independent set of readers, as well as a set of narrative captions generated synthetically, by combining each of the three axes. We describe this dataset and analyse it extensively. We also present baseline results for the High-Level Captioning task.","authors":["Michele Cafagna","Kees van Deemter","Albert Gatt"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"13","paper":"static/papers/inlg/13_Paper.pdf","poster":"static/posters/INLG2023/13.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"HL Dataset: Visually-Grounded Description of Scenes, Actions and Rationales"},{"UID":"inlg28","abstract":"Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories.","authors":["Prabin Bhandari","Hannah Brennan"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"28","paper":"static/papers/inlg/28_Paper.pdf","poster":"static/posters/INLG2023/28.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"inlg50","abstract":"Text Style Transfer (TST) is performable through approaches such as latent space disentanglement, cycle-consistency losses, prototype editing etc. The prototype editing approach, which is known to be quite successful in TST, involves two key phases a) Masking of source style-associated tokens and b) Reconstruction of this source-style masked sentence conditioned with the target style. We follow a similar transduction method, in which we transpose the more difficult direct source to target TST task to a simpler Style-Masked Language Model (SMLM) Task, wherein, similar to BERT \\cite{bert}, the goal of our model is now to reconstruct the source sentence from its style-masked version. We arrive at the SMLM mechanism naturally by formulating prototype editing/ transduction methods in a probabilistic framework, where TST resolves into estimating a hypothetical parallel dataset from a partially observed parallel dataset, wherein each domain is assumed to have a common latent style-masked prior. To generate this style-masked prior, we use \"Explainable Attention\" as our choice of attribution for a more precise style-masking step and also introduce a cost-effective and accurate \"Attribution-Surplus\" method of determining the position of masks from any arbitrary attribution model in O(1) time. We empirically show that this non-generational approach well suites the \"content preserving\" criteria for a task like TST, even for a complex style like Discourse Manipulation. Our model, the Style MLM, outperforms strong TST baselines and is on par with state-of-the-art TST models, which use complex architectures and orders of more parameters.","authors":["Sharan Narasimhan","Pooja H","Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"50","paper":"static/papers/inlg/50_Paper.pdf","poster":"static/posters/INLG2023/50.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"On Text Style Transfer via Style-Aware Masked Language Models"},{"UID":"inlg121","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.''). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.'') does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.  Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","authors":["Yarik Menchaca Resendiz","Roman Klinger"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"121","paper":"static/papers/inlg/121_Paper.pdf","poster":"static/posters/INLG2023/121.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Affective Natural Language Generation of Event Descriptions Through Fine-Grained Appraisal Conditions"},{"UID":"inlg3","abstract":"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).","authors":["Daphne Ippolito","Nicholas Carlini","Katherine Lee","Milad Nasr","Yun William Yu"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/inlg/3_Paper.pdf","poster":"static/posters/INLG2023/3.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"},{"UID":"inlg14","abstract":"One of the challenges in text generation is to control text generation as intended by the user. Previous studies proposed specifying the keywords that should be included in the generated text. However, this approach is insufficient to generate text that reflect the user's intent. For example, placing an important keyword at the beginning of the text would help attract the reader's attention; however, existing methods do not enable such flexible control. In this paper, we tackle a novel task of controlling not only keywords but also the position of each keyword in the text generation. To this end, we propose a task-independent method that uses special tokens to control the relative position of keywords. Experimental results on summarization and story generation tasks show that the proposed method can control keywords and their positions. The experimental results also demonstrate that controlling the keyword positions can generate summary texts that are closer to the user's intent than baseline.","authors":["Yuichi Sasazawa","Terufumi Morishita","Hiroaki Ozaki","Osamu Imaichi","Yasuhiro Sogawa"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"14","paper":"static/papers/inlg/14_Paper.pdf","poster":"static/posters/INLG2023/14.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Controlling Keywords and Their Positions in Text Generation"},{"UID":"inlg26","abstract":"Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations.  We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.","authors":["Saad Obaid ul Islam","Iza \u0160krjanec","Ondrej Du\u0161ek","Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"26","paper":"static/papers/inlg/26_Paper.pdf","poster":"static/posters/INLG2023/26.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Tackling Hallucinations in Neural Chart Summarization"},{"UID":"inlg41","abstract":"The positive text reframing (PTR) task which generates a text giving a positive perspective with preserving the sense of the input text, has attracted considerable attention as one of the NLP applications. Due to the significant representation capability of the pre-trained language model (PLM), a beneficial baseline can be easily obtained by just fine-tuning the PLM. However, how to interpret a diversity of contexts to give a positive perspective is still an open problem. Especially, it is more serious when the size of the training data is limited. In this paper, we present a PTR framework, that learns representations where the meaning and style of text are structurally disentangled. The method utilizes pseudo-positive reframing datasets which are generated with two augmentation strategies. A simple but effective multi-task learning-based model is learned to fuse the generation capabilities from these datasets. Experimental results on Positive Psychology Frames (PPF) dataset, show that our approach outperforms the baselines, BART by five and T5 by six evaluation metrics. Our source codes and data are available online.","authors":["Xu Sheng","Fumiyo Fukumoto","Jiyi Li","Go Kentaro","Yoshimi Suzuki"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"41","paper":"static/papers/inlg/41_Paper.pdf","poster":"static/posters/INLG2023/41.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Learning Disentangled Meaning and Style Representations for Positive Text Reframing"},{"UID":"inlg59","abstract":"Clickbait posts are a widespread problem in the webspace. The generation of spoilers, i.e. short texts that neutralize clickbait by providing information that makes it uninteresting, is one of the proposed solutions to the problem. Current state-of-the-art methods are based on passage retrieval or question answering approaches and are limited to generating spoilers only in the form of a phrase or a passage. In this work, we propose an ensemble of fine-tuned large language models for clickbait spoiler generation. Our approach is not limited to phrase or passage spoilers, but is also able to generate multipart spoilers that refer to several non-consecutive parts of text. Experimental evaluation demonstrates that the proposed ensemble model outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.","authors":["Mateusz Wo\u017any","Mateusz Lango"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"59","paper":"static/papers/inlg/59_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Clickbait Spoilers With an Ensemble of Large Language Models"},{"UID":"inlg79","abstract":"The faithfulness of abstractive text summarization at the named entities level is the focus of this study. We propose to add a new criterion to the summary selection method based on the \"risk\" of generating entities that do not belong to the source document. This method is based on the assumption that Out-Of-Document entities are more likely to be hallucinations. This assumption was verified by a manual annotation of the entities occurring in a set of generated summaries on the CNN/DM corpus. This study showed that only 29% of the entities outside the source document were inferrable by the annotators, leading to 71% of hallucinations among OOD entities. We test our selection method on the CNN/DM corpus and show that it significantly reduces the hallucination risk on named entities while maintaining competitive results with respect to automatic evaluation metrics like ROUGE.","authors":["Eunice Akani","Benoit Favre","Frederic Bechet","Romain GEMIGNANI"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"79","paper":"static/papers/inlg/79_Paper.pdf","poster":"static/posters/INLG2023/79.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Reducing Named Entity Hallucination Risk to Ensure Faithful Summary Generation"},{"UID":"inlg82","abstract":"G\u00e0idhlig (Scottish Gaelic; gd) is spoken by about 57k people in Scotland, but remains an under-resourced language with respect to natural language processing in general and natural language generation (NLG) in particular. To address this gap, we developed the first datasets for Scottish Gaelic NLG, collecting both conversational and summarisation data in a single setting. Our task setup involves dialogues between a pair of speakers discussing museum exhibits, grounding the conversation in images and texts. Then, both interlocutors summarise the dialogue resulting in a secondary dialogue summarisation dataset. This paper presents the dialogue and summarisation corpora, as well as the software used for data collection. The corpus consists of 43 conversations (13.7k words) and 61 summaries (2.0k words), and will be released along with the data collection interface.","authors":["David M. Howcroft","William Lamb","Anna Groundwater","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"Best Paper Nominee","order":"0","original_id":"82","paper":"static/papers/inlg/82_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Building a Dual Dataset of Text- And Image-Grounded Conversations and Summarisation in G\u00e0idhlig (Scottish Gaelic)"},{"UID":"inlg94","abstract":"In various scenarios, such as conference oral presentations, company managers' talks, and politicians' speeches, individuals often contemplate the potential questions that may arise from their presentations. This common practice prompts the research question addressed in this study: to what extent can models generate multiple questions based on a given presentation transcript? To investigate this, we conduct pilot explorations using earnings conference call transcripts, which serve as regular meetings between professional investors and company managers. We experiment with different task settings and methods and evaluate the results from various perspectives. Our findings highlight that incorporating key points retrieval techniques enhances the accuracy and diversity of the generated questions.","authors":["Yining Juan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"94","paper":"static/papers/inlg/94_Paper.pdf","poster":"","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Generating Multiple Questions From Presentation Transcripts: A Pilot Study on Earnings Conference Calls"},{"UID":"inlg100","abstract":"Rule-based text generators lack the coverage and fluency of their neural counterparts, but have two big advantages over them: (i) they are entirely controllable and do not hallucinate; and (ii) they can fully explain how an output was generated from an input. In this paper we leverage these two advantages to create large and reliable synthetic datasets with multiple human-intelligible intermediate representations. We present the Modular Data-to-Text (Mod-D2T) Dataset which incorporates ten intermediate-level representations between input triple sets and output text; the mappings from one level to the next can broadly be interpreted as the traditional modular tasks of an NLG pipeline. We describe the Mod-D2T dataset, evaluate its quality via manual validation and discuss its applications and limitations. Data, code and documentation are available at https://github.com/mille-s/Mod-D2T.","authors":["Simon Mille","Francois Lareau","Anya Belz","Stamatia Dasiopoulou"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"100","paper":"static/papers/inlg/100_Paper.pdf","poster":"static/posters/INLG2023/100.pdf","session":"inlgpostersession+flash","start":"2023-09-13T15:40:00+02:00","title":"Mod-D2t: A Multi-Layer Dataset for Modular Data-to-Text Generation"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgpostersession+flash###","end":"2023-09-13T17:00:00+02:00","end_time":"Wed, 13 Sep 2023 15:00:00 GMT","location":"#inlgpostersession+flash","name":"INLG Poster session +flash","room":"Foyer","start":"2023-09-13T15:40:00+02:00","start_time":"Wed, 13 Sep 2023 13:40:00 GMT","title":"INLG Poster session +flash","zoom":null}],"title":"Trustworthiness of Children Stories Generated by Large Language Models"},{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","sessions":[{"UID":"sigdialpostersession2","calendarId":"sigdialposter","category":"time","chair":"Kazunori Komatani","contents":[{"UID":"sigdial104","abstract":"In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.","authors":["Mai Omura","Hiroshi Matsuda","Masayuki Asahara","Aya Wakasa"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"104","paper":"static/papers/sigdial/104_Paper.pdf","poster":"static/posters/SIGDIAL2023/104.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"UD_Japanese-CEJC: Dependency Relation Annotation on Corpus of Everyday Japanese Conversation"},{"UID":"sigdial154","abstract":"Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.","authors":["Zulipiye Yusupujiang","Jonathan Ginzburg"],"conference":"sigdial","full_video":"","notes":"","order":"10","original_id":"154","paper":"static/papers/sigdial/154_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"sigdial153","abstract":"Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.","authors":["Khalid Al Khatib","Michael V\u00f6lske","Anh Le","Shahbaz Syed","Martin Potthast","Benno Stein"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"153","paper":"static/papers/sigdial/153_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"A New Dataset for Causality Identification in Argumentative Texts"},{"UID":"sigdial125","abstract":"Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from  a domain-specific  DA and  its semantic attributes to an output utterance.  Recent work shows that  pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning.  Here we develop a novel few-shot overgenerate-and-rank  approach that achieves the controlled generation of DAs.  We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references  using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness,  we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA.  Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.","authors":["Angela Ramirez","Kartik Agarwal","Juraj Juraska","Utkarsh Garg","Marilyn Walker"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"125","paper":"static/papers/sigdial/125_Paper.pdf","poster":"static/posters/SIGDIAL2023/125.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"},{"UID":"sigdial117","abstract":"In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.","authors":["Abari Bhattacharya","Abhinav Kumar","Barbara Di Eugenio","Roderick Tabalba","Jillian Aurisano","Veronica Grosso","Andrew Johnson","Jason Leigh","Moira Zellner"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"117","paper":"static/papers/sigdial/117_Paper.pdf","poster":"static/posters/SIGDIAL2023/117.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions With a Conversational Assistant"},{"UID":"sigdial148","abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER","authors":["Chao-Wei Huang","Chen-Yu Hsu","Tsu-Yuan Hsu","Chen-An Li","Yun-Nung Chen"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"148","paper":"static/papers/sigdial/148_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"CONVERSER: Few-Shot Conversational Dense Retrieval With Synthetic Data Generation"},{"UID":"sigdial123","abstract":"This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent's opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.","authors":["Minh-Quoc Nghiem","Nichola Roberts","Dmitry Sityaev"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"123","paper":"static/papers/sigdial/123_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Speaker Role Identification in Call Center Dialogues: Leveraging Opening Sentences and Large Language Models"},{"UID":"sigdial146","abstract":"Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.","authors":["Shilin Gao","Matthew P. Aylett","David A. Braude","Catherine Lai"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"146","paper":"static/papers/sigdial/146_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Synthesising Personality With Neural Speech Synthesis"},{"UID":"sigdial121","abstract":"Task-oriented dialogue systems need to generate appropriate responses to help fulfill users' requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications.  Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.","authors":["Gon\u00e7alo Raposo","Luisa Coheur","Bruno Martins"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"121","paper":"static/papers/sigdial/121_Paper.pdf","poster":"static/posters/SIGDIAL2023/121.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Prompting, Retrieval, Training: An Exploration of Different Approaches for Task-Oriented Dialogue Generation"},{"UID":"sigdial132","abstract":"Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets.  We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies.  This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing.  Our study suggests large language models  (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models' ability to do temporal reasoning struggle to provide accurate responses.  A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.","authors":["Pulkit Arya","Madeleine Bloomquist","SUBHANKAR CHAKRABORTY","Andrew Perrault","William Schuler","Eric Fosler-Lussier","Michael White"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"132","paper":"static/papers/sigdial/132_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bootstrapping a Conversational Guide for Colonoscopy Prep"},{"UID":"sigdial155","abstract":"While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user's task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.","authors":["Ryu Hirai","Ao Guo","Ryuichiro Higashinaka"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"155","paper":"static/papers/sigdial/155_Paper.pdf","poster":"static/posters/SIGDIAL2023/155.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Applying Item Response Theory to Task-Oriented Dialogue Systems for Accurately Determining User's Task Success Ability"},{"UID":"sigdial70","abstract":"With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.","authors":["Takato Yamazaki","Tomoya Mizumoto","Katsumasa Yoshikawa","Masaya Ohagi","Toshiki Kawamoto","Toshinori Sato"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"70","paper":"static/papers/sigdial/70_Paper.pdf","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"An Open-Domain Avatar Chatbot by Exploiting a Large Language Model"},{"UID":"sigdialD&D1","abstract":"","authors":["Utku Norman","Tanvi Dinkar","Barbara Bruno","Chlo\u00e9 Clavel"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"D&D1","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Studying Alignment in a Collaborative Learning Activity via Automatic Methods: The Link Between What We Say and Do"},{"UID":"sigdialD&D2","abstract":"","authors":["Marian Marchal","Saarland University","Merel C.J. Scholman","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"D&D2","paper":"","poster":"","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"The Effect of Domain Knowledge on Discourse Relation Inferences: Relation Marking and Interpretation Strategies"},{"UID":"sigdialD&D3","abstract":"","authors":["Oliver Deck"],"conference":"sigdial","full_video":"","notes":"","order":"14","original_id":"D&D3","paper":"","poster":"static/posters/SIGDIAL2023/D&D_Deck.pdf","session":"sigdialpostersession2","start":"2023-09-14T14:00:00+02:00","title":"Bullshit, Pragmatic Deception, and Natural Language Processing"}],"day":"Thursday","discord":"https://discord.com/channels/###sigdialpostersession2###","end":"2023-09-14T15:40:00+02:00","end_time":"Thu, 14 Sep 2023 13:40:00 GMT","location":"#sigdialpostersession2","name":"Sigdial Poster Session 2","room":"Foyer","start":"2023-09-14T14:00:00+02:00","start_time":"Thu, 14 Sep 2023 12:00:00 GMT","title":"Sigdial Poster Session 2","zoom":null}],"title":"Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","sessions":[{"UID":"genchalpostersession+demos","calendarId":"inlgposter","category":"time","contents":[{"UID":"inlg124","abstract":"Over the past decade, a variety of neural architectures for data-to-text generation (NLG) have been proposed. However, each system typically has its own approach to pre- and post-processing and other implementation details. Diversity in implementations is desirable, but it also confounds attempts to compare model performance: are the differences due to the proposed architectures or are they a byproduct of the libraries used or a result of pre- and post-processing decisions made? To improve reproducibility, we re-implement several pre-Transformer neural models for data-to-text NLG within a single framework to facilitate direct comparisons of the models themselves and better understand the contributions of other design choices. We release our library at https://github.com/NapierNLP/enunlg to serve as a baseline for ongoing work in this area including research on NLG for low-resource languages where transformers might not be optimal.","authors":["David M. Howcroft","Dimitra Gkatzia"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"124","paper":"static/papers/inlg/124_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Enunlg: A Python Library for Reproducible Neural Data-to-Text Experimentation"},{"UID":"inlg125","abstract":"VisuaLLM is a Python library that enables interactive visualization of common tasks in natural language generation with pretrained language models (using HuggingFace's model API), with tight integration of benchmark datasets and fine-grained generation control. The system runs as a local generation backend server and features a web-based frontend, allowing simple interface configuration by minimal Python code. The currently implemented views include data visualization, next-token prediction with probability distributions, and decoding parameter control, with simple extension to additional tasks.","authors":["Franti\u0161ek Trebu\u0148a","Ond\u0159ej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"125","paper":"static/papers/inlg/125_Paper.pdf","poster":"static/posters/INLG2023/125.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg126","abstract":"Live commentaries are essential for enhancing spectators' enjoyment and understanding during sports events or e-sports streams. We introduce a live audio commentator system designed specifically for a racing game, driven by the high demand in the e-sports field. While a player is playing a racing game, our system tracks real-time user play data including speed and steer rotations, and generates commentary to accompany the live stream. Human evaluation suggested that generated commentary enhances enjoyment and understanding of races compared to streams without commentary. Incorporating additional modules to improve diversity and detect irregular events, such as course-outs and collisions, further increases the preference for the output commentaries.","authors":["Tatsuya Ishigaki","Goran Topi\u0107","Yumi Hamazono","Ichiro Kobayashi","Yusuke Miyao","Hiroya Takamura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"126","paper":"static/papers/inlg/126_Paper.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Audio Commentary System for Real-Time Racing Game Play"},{"UID":"inlg132","abstract":"","authors":["Mana Ihori, Hiroshi Sato, Tomohiro Tanaka and Ryo Masumura"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"132","paper":"static/papers/genchal/132.pdf","poster":"static/posters/INLG2023/132.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Retrieval, Masking, and Generation: Feedback Comment Generation Using Masked Comment Examples"},{"UID":"inlg138","abstract":"","authors":["Krist\u00fdna Klesnilov\u00e1 and Michelle Elizabeth"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"138","paper":"static/papers/genchal/138.pdf","poster":"static/posters/INLG2023/138.pdf","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Synapse @ AutoMin 2023: Leveraging BART-Based Models for Automatic Meeting Minuting"},{"UID":"inlg139","abstract":"","authors":["Franti\u0161ek Kmje\u010d and Ond\u0159ej Bojar"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"139","paper":"static/papers/genchal/139.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Team Iterate @ AutoMin 2023 - Experiments With Iterative Minuting"},{"UID":"inlg140","abstract":"","authors":["Isma\u00ebl Rousseau, Lo\u00efc Fosse, Youness Dkhissi, Geraldine Damnati and Gw\u00e9nol\u00e9 Lecorv\u00e9"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"140","paper":"static/papers/genchal/140.pdf","poster":"","session":"genchalpostersession+demos","start":"2023-09-14T17:35:00+02:00","title":"Darbarer@AutoMin2023: Transcription Simplification for Concise Minute Generation From Multi-Party Conversations"}],"day":"Thursday","discord":"https://discord.com/channels/###genchalpostersession+demos###","end":"2023-09-14T18:30:00+02:00","end_time":"Thu, 14 Sep 2023 16:30:00 GMT","location":"#genchalpostersession+demos","name":"GenChal Poster Session + demos, Simon Mille","room":"Foyer","start":"2023-09-14T17:35:00+02:00","start_time":"Thu, 14 Sep 2023 15:35:00 GMT","title":"GenChal Poster Session + demos, Simon Mille","zoom":null}],"title":"VisuaLLM: Easy Web-Based Visualization for Neural Language Generation"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","sessions":[{"UID":"inlggenchalpresentation","calendarId":"inlgoral","category":"time","contents":[{"UID":"inlg130","abstract":"","authors":["Ryo Nagata, Masato Hagiwara, Kazuaki Hanawa and Masato Mita"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"130","paper":"static/papers/genchal/130.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:10:00+02:00","title":"A Report on FCG GenChal 2022: Shared Task on Feedback Comment Generation for Language Learners"},{"UID":"inlg136","abstract":"","authors":["Yoshinobu Kano, Neo Watanabe, Kaito Kagaminuma, Claus Aranha, Jaewon Lee, Benedek Hauer, Hisaichi Shibata, Soichiro Miki, Yuta Nakamura and Takuya Okubo"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"136","paper":"static/papers/genchal/136.pdf","poster":"static/posters/INLG2023/136.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:25:00+02:00","title":"AIWolfDial 2023: Summary of Natural Language Division of 5th International AIWolf Contest"},{"UID":"inlg142","abstract":"","authors":["Tirthankar Ghosal, Ond\u0159ej Bojar, Marie Hled\u00edkov\u00e1, Tom Kocmi and Anna Nedoluzhko"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"142","paper":"static/papers/genchal/142.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T16:40:00+02:00","title":"Overview of the Second Shared Task on Automatic Minuting (AutoMin) at INLG 2023"},{"UID":"inlg116","abstract":"","authors":["Khyathi Raghavi Chandu, David M. Howcroft, Dimitra Gkatzia, Yi-ling Chung, Yufang Hou, Chris Chinenye Emezue, Pawan Rajpoot and Tosin Adewumi"],"conference":"inlg","full_video":"","notes":"","order":"3","original_id":"116","paper":"static/papers/genchal/116.pdf","poster":"static/posters/INLG2023/116.pdf","session":"inlggenchalpresentation","start":"2023-09-14T16:55:00+02:00","title":"LOWRECORP: The Low-Resource NLG Corpus Building Challenge"},{"UID":"inlg117","abstract":"","authors":["Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"4","original_id":"117","paper":"static/papers/genchal/117.pdf","poster":"static/posters/INLG2023/117.pdf","session":"inlggenchalpresentation","start":"2023-09-14T17:10:00+02:00","title":"Long Story Generation Challenge"},{"UID":"inlg119","abstract":"","authors":["Xudong Hong, Khushboo Mehra, Asad Sayeed and Vera Demberg"],"conference":"inlg","full_video":"","notes":"","order":"5","original_id":"119","paper":"static/papers/genchal/119.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:25:00+02:00","title":"Visually Grounded Story Generation Challenge"},{"UID":"inlg120","abstract":"","authors":["Nikolai Ilinykh and Simon Dobnik"],"conference":"inlg","full_video":"","notes":"","order":"6","original_id":"120","paper":"static/papers/genchal/120.pdf","poster":"","session":"inlggenchalpresentation","start":"2023-09-14T17:40:00+02:00","title":"The VDG Challenge: Response Generation and Evaluation in Collaborative Visual Dialogue"}],"day":"Thursday","discord":"https://discord.com/channels/###inlggenchalpresentation###","end":"2023-09-14T17:35:00+02:00","end_time":"Thu, 14 Sep 2023 15:35:00 GMT","location":"#inlggenchalpresentation","name":"INLG genChal presentation, Simon Mille","room":"Sun II","start":"2023-09-14T16:10:00+02:00","start_time":"Thu, 14 Sep 2023 14:10:00 GMT","title":"INLG genChal presentation, Simon Mille","zoom":"https://zoom.us/j/###Sun II###"}],"title":"Visually Grounded Story Generation Challenge"},{"UID":"sigdial43","abstract":"Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.","authors":["Yang Janet Liu","Tatsuya Aoyama","Amir Zeldes"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"43","paper":"static/papers/sigdial/43_Paper.pdf","poster":"","session":"sigdialoralsession1","sessions":[{"UID":"sigdialoralsession1","calendarId":"sigdialoral","category":"time","chair":"Gabriel Skantze","contents":[{"UID":"sigdial86","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs.  Despite their prevalence, there currently lacks an accurate survey of dialogue noise,  nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise.  Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise.  Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","authors":["Derek Chen","Zhou Yu"],"conference":"sigdial","full_video":"","notes":"REMOTE","order":"0","original_id":"86","paper":"static/papers/sigdial/86_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T10:45:00+02:00","title":"Sources of Noise in Dialogue and How to Deal With Them"},{"UID":"sigdial14","abstract":"Discourse relations have different patterns of marking across different languages.  As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment.  The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.","authors":["Frances Yung","Merel Scholman","Ekaterina Lapshinova-Koltunski","Christina Pollkl\u00e4sener","Vera Demberg"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"14","paper":"static/papers/sigdial/14_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:05:00+02:00","title":"Investigating Explicitation of Discourse Connectives in Translation Using Automatic Annotations"},{"UID":"sigdial43","abstract":"Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.","authors":["Yang Janet Liu","Tatsuya Aoyama","Amir Zeldes"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"43","paper":"static/papers/sigdial/43_Paper.pdf","poster":"","session":"sigdialoralsession1","start":"2023-09-13T11:25:00+02:00","title":"What's Hard in English RST Parsing? Predictive Models for Error Analysis"},{"UID":"sigdial80","abstract":"Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86&#92;% of the evaluated tasks were improved from a conversational suitability point of view.","authors":["Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"80","paper":"static/papers/sigdial/80_Paper.pdf","poster":"static/posters/SIGDIAL2023/80.pdf","session":"sigdialoralsession1","start":"2023-09-13T11:45:00+02:00","title":"Grounded Complex Task Segmentation for Conversational Assistants"},{"UID":"sigdial91","abstract":"Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners' topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.","authors":["Grace Lawley","Peter A. Heeman","Jill K. Dolata","Eric Fombonne","Steven Bedrick"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"91","paper":"static/papers/sigdial/91_Paper.pdf","poster":"static/posters/SIGDIAL2023/91.pdf","session":"sigdialoralsession1","start":"2023-09-13T12:05:00+02:00","title":"A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialoralsession1###","end":"2023-09-13T12:30:00+02:00","end_time":"Wed, 13 Sep 2023 10:30:00 GMT","location":"#sigdialoralsession1","name":"Sigdial Oral Session 1: Analysis of discourse and dialogue","room":"Sun I","start":"2023-09-13T10:45:00+02:00","start_time":"Wed, 13 Sep 2023 08:45:00 GMT","title":"Sigdial Oral Session 1: Analysis of discourse and dialogue","zoom":"https://zoom.us/j/###Sun I###"}],"title":"What's Hard in English RST Parsing? Predictive Models for Error Analysis"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","sessions":[{"UID":"virtualpostersession","calendarId":"sigdialposter","category":"time","chair":"Kees van Deemter","contents":[{"UID":"inlg123","abstract":"This demo paper presents a brief introduction of MiReportor, a computer-aided medical imaging report generator, which leverages a unified framework of medical image understanding and generation to predict readable descriptions for medical images, and assists radiologists in imaging reports writing.","authors":["Xuwen Wang","Hetong Ma","Zhen Guo","Jiao Li"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"123","paper":"static/papers/inlg/123_Paper.pdf","poster":"static/posters/INLG2023/123.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Overview of MiReportor: Generating Reports for Multimodal Medical Images"},{"UID":"inlg25","abstract":"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings.  In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader's expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","authors":["Maurice Langner","Ralf Klabunde"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"25","paper":"static/papers/inlg/25_Paper.pdf","poster":"static/posters/INLG2023/25.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Validating Predictive Models of Evaluative Language for Controllable Data2Text Generation"},{"UID":"inlg27","abstract":"To enhance the quality of generated stories, recent story generation models have been investigating the utilization of higher-level attributes like plots or commonsense knowledge. The application of prompt-based learning with large language models (LLMs), exemplified by GPT-3, has exhibited remarkable performance in diverse natural language processing (NLP) tasks. This paper conducts a comprehensive investigation, utilizing both automatic and human evaluation, to compare the story generation capacity of LLMs with recent models across three  datasets with variations in style, register, and length of stories. The results demonstrate that LLMs generate stories of significantly higher quality compared to other story generation models. Moreover, they exhibit a level of performance that competes with human authors, albeit with the preliminary observation that they tend to replicate real stories in situations involving world knowledge, resembling a form of plagiarism.","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"27","paper":"static/papers/inlg/27_Paper.pdf","poster":"static/posters/INLG2023/27.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"The Next Chapter: A Study of Large Language Models in Storytelling"},{"UID":"sigdial54","abstract":"The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu (Drew) Zhang"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"54","paper":"static/papers/sigdial/54_Paper.pdf","poster":"static/posters/SIGDIAL2023/54.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Enhancing Task Bot Engagement With Synthesized Open-Domain Dialog"},{"UID":"sigdial46","abstract":"Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.","authors":["Alexander Chernyavskiy","Dmitry Ilvovsky"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"46","paper":"static/papers/sigdial/46_Paper.pdf","poster":"static/posters/SIGDIAL2023/46.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Transformer-Based Multi-Party Conversation Generation Using Dialogue Discourse Acts Planning"},{"UID":"sigdial128","abstract":"Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators' uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of  confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators' uncertainty about discourse relation labels.","authors":["S. Magal\u00ed L\u00f3pez Cortez","Cassandra L. Jacobs"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"128","paper":"static/papers/sigdial/128_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Incorporating Annotators' Uncertainty to Discourse Relations Representations"},{"UID":"sigdial30","abstract":"The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks---knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances.  Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.","authors":["Vishakh Padmakumar","Behnam Hedayatnia","Di Jin","Patrick Lange","Seokhwan Kim","Nanyun Peng","Yang Liu","Dilek Hakkani-Tur"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"30","paper":"static/papers/sigdial/30_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Investigating the Representation of Open Domain Dialogue Context for Transformer Models"},{"UID":"sigdial42","abstract":"Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.","authors":["Hung Le","Nancy Chen","Steven C.H. Hoi"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"42","paper":"static/papers/sigdial/42_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"C3: Compositional Counterfactual Constrastive Learning for Video-Grounded Dialogues"},{"UID":"sigdial59","abstract":"The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.","authors":["Vevake Balaraman","Arash Eshghi","Ioannis Konstas","Ioannis Papaioannou"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"59","paper":"static/papers/sigdial/59_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"No That's Not What I Meant: Handling Third Position Repair in Conversational Question Answering"},{"UID":"sigdial138","abstract":"End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios.  Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.","authors":["Jianguo Zhang","Stephen Roller","Kun Qian","Zhiwei Liu","Rui Meng","Shelby Heinecke","Huan Wang","silvio savarese","Caiming Xiong"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"138","paper":"static/papers/sigdial/138_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Improve Zero-Shot Performance on Unseen Dialog Domains With Retrieval-Augmented Task-Oriented Systems"},{"UID":"sigdial147","abstract":"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.","authors":["Alafate Abulimiti","Chlo\u00e9 Clavel","Justine Cassell"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"147","paper":"static/papers/sigdial/147_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"sigdial45","abstract":"The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present &#92;emph{PaperPersiChat}, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.","authors":["Alexander Chernyavskiy","Max Bregeda","Maria Nikiforova"],"conference":"sigdial","full_video":"","notes":"","order":"6","original_id":"45","paper":"static/papers/sigdial/45_Paper.pdf","poster":"static/posters/SIGDIAL2023/45.pdf","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"PaperPersiChat: Scientific Paper Discussion Chatbot Using Transformers and Discourse Flow Management"},{"UID":"sigdial103","abstract":"We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of  open and closed-domain dialogue along with facial expressions, by  using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.","authors":["Neeraj Cherakara","Finny Varghese","Sheena Shabana","Nivan Nelson","Abhiram Karukayil","Rohith Kulothungan","Mohammed Afil Farhan","Birthe Nesset","Meriam Moujahid","Tanvi Dinkar","Verena Rieser","Oliver Lemon"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"103","paper":"static/papers/sigdial/103_Paper.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"FurChat: An Embodied Conversational Agent Using LLMs, Combining Open and Closed-Domain Dialogue With Facial Expressions"},{"UID":"inlg133","abstract":"","authors":["Naoya Ueda and Mamoru Komachi"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"133","paper":"static/papers/genchal/133.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"TMU Feedback Comment Generation System Using Pretrained Sequence-to-Sequence Language Models"},{"UID":"inlg137","abstract":"","authors":["Felix Schneider and Marco Turchi"],"conference":"inlg","full_video":"","notes":"","order":"1","original_id":"137","paper":"static/papers/genchal/137.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team Zoom @ AutoMin 2023: Utilizing Topic Segmentation and LLM Data Augmentation for Long-Form Meeting Summarization"},{"UID":"inlg141","abstract":"","authors":["Eugene Borisov and Nikolay Mikhaylovskiy"],"conference":"inlg","full_video":"","notes":"","order":"2","original_id":"141","paper":"static/papers/genchal/141.pdf","poster":"","session":"virtualpostersession","start":"2023-09-15T09:00:00+02:00","title":"Team NTR @ AutoMin 2023: Dolly LLM Improves Minuting Performance, Semantic Segmentation Doesn\u2019t"}],"day":"Friday","discord":"https://discord.com/channels/###virtualpostersession###","end":"2023-09-15T10:00:00+02:00","end_time":"Fri, 15 Sep 2023 08:00:00 GMT","location":"#virtualpostersession","name":"Virtual Poster Session","room":"Sun I","start":"2023-09-15T09:00:00+02:00","start_time":"Fri, 15 Sep 2023 07:00:00 GMT","title":"Virtual Poster Session","zoom":null}],"title":"When to Generate Hedge in Peer Tutoring Interaction?"},{"UID":"inlg10","abstract":"Multiple business scenarios require an automated generation of descriptive human-readable text from structured input data. This has resulted into substantial work on fact-to-text generation systems recently. Unfortunately, previous work on fact-to-text (F2T) generation has focused primarily on English mainly due to the high availability of relevant datasets. Only recently, the problem of cross-lingual fact-to-text (XF2T) was proposed for generation across multiple languages alongwith a dataset, XAlign for eight languages. However, there has been no rigorous work on the actual XF2T generation problem. We extend XAlign dataset with annotated data for four more languages: Punjabi, Malayalam, Assamese and Oriya. We conduct an extensive study using popular Transformer-based text generation models on our extended multi-lingual dataset, which we call XAlignV2. Further, we investigate the performance of different text generation strategies: multiple variations of pretraining, fact-aware embeddings and structure-aware input encoding. Our extensive experiments show that a multi-lingual mT5 model which uses fact-aware embeddings with structure-aware input encoding leads to best results (30.90 BLEU, 55.12 METEOR and 59.17 chrF++) across the twelve languages. We make our code, dataset and model publicly available, and hope that this will help advance further research in this critical area.","authors":["Shivprasad Sagare","Tushar Abhishek","Bhavyajeet Singh","Anubhav Sharma","Manish Gupta","Vasudeva Varma"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"10","paper":"static/papers/inlg/10_Paper.pdf","poster":"","session":"inlgoralsession2","sessions":[{"UID":"inlgoralsession2","calendarId":"inlgoral","category":"time","chair":"Gozde Gul Sahin","contents":[{"UID":"inlg9","abstract":"In this paper, we introduce a new beam search algorithm that improves the generalization of neural generators to unseen examples, especially in low-resource data-to-text settings. Our algorithm aims to reduce the number of omissions and hallucinations during the decoding process. For this purpose, it relies on two regression models to explicitly characterize factual errors. We explain how to create a new dataset to train these models given an original training set of less than a thousand data points. We apply our approach in the low-resource, legal setting using the French Plum2Text dataset, as well as in English using WebNLG. We observe in our experiment that this combination improves the faithfulness of pre-trained neural text generators using both human and automatic evaluation. Moreover, our approach offers a level of interpretability by predicting the number of omissions and hallucinations present in a given generation with respect to the input data. Finally, we visualize our algorithm's exploration of the hypothesis space at different steps during the decoding process.","authors":["Nicolas Garneau","Luc Lamontagne"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"9","paper":"static/papers/inlg/9_Paper.pdf","poster":"static/posters/INLG2023/9.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation"},{"UID":"inlg10","abstract":"Multiple business scenarios require an automated generation of descriptive human-readable text from structured input data. This has resulted into substantial work on fact-to-text generation systems recently. Unfortunately, previous work on fact-to-text (F2T) generation has focused primarily on English mainly due to the high availability of relevant datasets. Only recently, the problem of cross-lingual fact-to-text (XF2T) was proposed for generation across multiple languages alongwith a dataset, XAlign for eight languages. However, there has been no rigorous work on the actual XF2T generation problem. We extend XAlign dataset with annotated data for four more languages: Punjabi, Malayalam, Assamese and Oriya. We conduct an extensive study using popular Transformer-based text generation models on our extended multi-lingual dataset, which we call XAlignV2. Further, we investigate the performance of different text generation strategies: multiple variations of pretraining, fact-aware embeddings and structure-aware input encoding. Our extensive experiments show that a multi-lingual mT5 model which uses fact-aware embeddings with structure-aware input encoding leads to best results (30.90 BLEU, 55.12 METEOR and 59.17 chrF++) across the twelve languages. We make our code, dataset and model publicly available, and hope that this will help advance further research in this critical area.","authors":["Shivprasad Sagare","Tushar Abhishek","Bhavyajeet Singh","Anubhav Sharma","Manish Gupta","Vasudeva Varma"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"10","paper":"static/papers/inlg/10_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"XF2T: Cross-Lingual Fact-to-Text Generation for Low-Resource Languages"},{"UID":"inlg44","abstract":"Research in Multi-document Summarization (MDS) mostly focuses on the English language and depends on large MDS datasets that are not available for other languages. Some of these approaches concatenate the source documents, resulting in overlong model inputs. Existing transformer architectures are unable to process such long inputs entirely, omitting documents in the summarization process. Other solutions address this issue by implementing multi-stage approaches that also require changes in the model architecture. In this paper, we introduce various sampling approaches based on information entropy that allow us to perform MDS in a single stage. These approaches also consider all source documents without using MDS training data nor changing the model's architecture. Besides, we build a MDS test set of German news articles to assess the performance of our methods on abstractive multi-document summaries. Experimental results show that our entropy-based approaches outperform previous state-of-the-art on German MDS, while still remaining primarily abstractive. We release our code and MDS test set to encourage further research in German abstractive MDS.","authors":["Laura Mascarell","Ribin Chalumattu","Julien Heitmann"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"44","paper":"static/papers/inlg/44_Paper.pdf","poster":"static/posters/INLG2023/44.pdf","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Entropy-Based Sampling for Abstractive Multi-Document Summarization in Low-Resource Settings"},{"UID":"inlg80","abstract":"Text style transfer (TST) involves transforming a text into a desired style while approximately preserving its content. The biggest challenge in TST in the general lack of parallel data. Many existing approaches rely on complex models using substantial non-parallel data, with mixed results. In this paper, we leverage a pretrained BART language model with minimal parallel data and incorporate low-resource methods such as hyperparameter tuning, data augmentation, and self-training, which have not been explored in TST. We further include novel style-based rewards in the training loss. Through extensive experiments in sentiment transfer, a sub-task of TST, we demonstrate that our simple yet effective approaches achieve well-balanced results, surpassing non-parallel approaches and highlighting the usefulness of parallel data even in small amounts.","authors":["Sourabrata Mukherjee","Ondrej Du\u0161ek"],"conference":"inlg","full_video":"","notes":"","order":"0","original_id":"80","paper":"static/papers/inlg/80_Paper.pdf","poster":"","session":"inlgoralsession2","start":"2023-09-13T13:30:00+02:00","title":"Leveraging Low-Resource Parallel Data for Text Style Transfer"}],"day":"Wednesday","discord":"https://discord.com/channels/###inlgoralsession2###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#inlgoralsession2","name":"INLG Oral Session 2: NLG for low-resourced settings","room":"Sun II","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"INLG Oral Session 2: NLG for low-resourced settings","zoom":"https://zoom.us/j/###Sun II###"}],"title":"XF2T: Cross-Lingual Fact-to-Text Generation for Low-Resource Languages"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","sessions":[{"UID":"sigdialpostersession1","calendarId":"sigdialposter","category":"time","chair":"David Schlangen","contents":[{"UID":"sigdial74","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.","authors":["Vahid Sadiri Javadi","Martin Potthast","Lucie Flek"],"conference":"sigdial","full_video":"","notes":"","order":"11","original_id":"74","paper":"static/papers/sigdial/74_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"OpinionConv: Conversational Product Search With Grounded Opinions"},{"UID":"sigdial97","abstract":"In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"10","original_id":"97","paper":"static/papers/sigdial/97_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dial-M: A Masking-Based Framework for Dialogue Evaluation"},{"UID":"sigdial90","abstract":"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.","authors":["Shutong Feng","Nurul Lubis","Benjamin Ruppik","Christian Geishauser","Michael Heck","Hsien-chin Lin","Carel van Niekerk","Renato Vukovic","Milica Gasic"],"conference":"sigdial","full_video":"","notes":"","order":"13","original_id":"90","paper":"static/papers/sigdial/90_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-Oriented Dialogue"},{"UID":"sigdial56","abstract":"Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant's sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.","authors":["Kazunori Komatani","Ryu Takeda","Shogo Okada"],"conference":"sigdial","full_video":"","notes":"","order":"7","original_id":"56","paper":"static/papers/sigdial/56_Paper.pdf","poster":"static/posters/SIGDIAL2023/56.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Analyzing Differences in Subjective Annotations by Participants and Third-Party Annotators in Multimodal Dialogue Corpus"},{"UID":"sigdial67","abstract":"Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are  <p>(1) relevant to a frame of interest,  <p>(2) relevant to the topic under discussion, and  <p>(3) informative to the reader.   <p>Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100~controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.","authors":["Shahbaz Syed","Timon Ziegenbein","Philipp Heinisch","Henning Wachsmuth","Martin Potthast"],"conference":"sigdial","full_video":"","notes":"","order":"9","original_id":"67","paper":"static/papers/sigdial/67_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Frame-Oriented Summarization of Argumentative Discussions"},{"UID":"sigdial20","abstract":"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","authors":["John Mendonca","Alon Lavie","Isabel Trancoso"],"conference":"sigdial","full_video":"","notes":"","order":"2","original_id":"20","paper":"static/papers/sigdial/20_Paper.pdf","poster":"static/posters/SIGDIAL2023/20.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Towards Multilingual Automatic Open-Domain Dialogue Evaluation"},{"UID":"sigdial40","abstract":"Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action.  However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.","authors":["Huimin Wang","Wai Chung Kwan","Kam-Fai Wong"],"conference":"sigdial","full_video":"","notes":"","order":"4","original_id":"40","paper":"static/papers/sigdial/40_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Dialog Action-Aware Transformer for Dialog Policy Learning"},{"UID":"sigdial75","abstract":"Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users' perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.","authors":["Frederico Vicente","Rafael Ferreira","David Semedo","Joao Magalhaes"],"conference":"sigdial","full_video":"","notes":"","order":"12","original_id":"75","paper":"static/papers/sigdial/75_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Wizard of Curiosities: Enriching Dialogues With Epistemic Fun-Facts"},{"UID":"sigdial35","abstract":"Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.","authors":["Brielen Madureira","Patrick Kahardipraja","David Schlangen"],"conference":"sigdial","full_video":"","notes":"","order":"3","original_id":"35","paper":"static/papers/sigdial/35_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Road to Quality Is Paved With Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"},{"UID":"sigdial4","abstract":"Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers' traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.","authors":["Bogdan Ludusan","Petra Wagner"],"conference":"sigdial","full_video":"","notes":"","order":"1","original_id":"4","paper":"static/papers/sigdial/4_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"The Effect of Conversation Type on Entrainment: Evidence From Laughter"},{"UID":"sigdial50","abstract":"Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi","Helen Hastie"],"conference":"sigdial","full_video":"","notes":"Best Paper Nominee","order":"6","original_id":"50","paper":"static/papers/sigdial/50_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"},{"UID":"sigdial3","abstract":"Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.","authors":["Rui Ribeiro","Joao Paulo Carvalho","Luisa Coheur"],"conference":"sigdial","full_video":"","notes":"","order":"0","original_id":"3","paper":"static/papers/sigdial/3_Paper.pdf","poster":"static/posters/SIGDIAL2023/3.pdf","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"PGTask: Introducing the Task of Profile Generation From Dialogues"},{"UID":"sigdial61","abstract":"To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users' food preferences.  The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees' food preferences.","authors":["Jie Zeng","Yukiko Nakano","Tatsuya Sakato"],"conference":"sigdial","full_video":"","notes":"","order":"8","original_id":"61","paper":"static/papers/sigdial/61_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Question Generation to Elicit Users' Food Preferences by Considering the Semantic Content"},{"UID":"sigdial48","abstract":"We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.","authors":["Lingbo Mo","Shijie Chen","Ziru Chen","Xiang Deng","Ashley Lewis","Sunit Singh","Samuel Stevens","Chang-You Tai","Zhen Wang","Xiang Yue","Tianshu Zhang","Yu Su","Huan Sun"],"conference":"sigdial","full_video":"","notes":"","order":"5","original_id":"48","paper":"static/papers/sigdial/48_Paper.pdf","poster":"","session":"sigdialpostersession1","start":"2023-09-13T13:30:00+02:00","title":"Roll Up Your Sleeves: Working With a Collaborative and Engaging Task-Oriented Dialogue System"}],"day":"Wednesday","discord":"https://discord.com/channels/###sigdialpostersession1###","end":"2023-09-13T15:10:00+02:00","end_time":"Wed, 13 Sep 2023 13:10:00 GMT","location":"#sigdialpostersession1","name":"Sigdial Poster Session 1","room":"Foyer","start":"2023-09-13T13:30:00+02:00","start_time":"Wed, 13 Sep 2023 11:30:00 GMT","title":"Sigdial Poster Session 1","zoom":null}],"title":"\u2018What Are You Referring To?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"}]
